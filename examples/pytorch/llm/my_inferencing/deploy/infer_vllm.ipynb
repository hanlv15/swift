{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 17:11:37,511 - modelscope - INFO - PyTorch version 2.1.2 Found.\n",
      "2024-03-30 17:11:37,514 - modelscope - INFO - Loading ast index from /home/hanlv/.cache/modelscope/ast_indexer\n",
      "2024-03-30 17:11:37,553 - modelscope - INFO - Loading done! Current index file version is 1.13.1, with md5 ad87f4a589251d86333765b92ab59e41 and a total number of 972 components indexed\n",
      "[INFO:swift] Loading the model using model_dir: /home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\n",
      "[INFO:swift] Setting torch_dtype: torch.bfloat16\n",
      "[INFO:swift] model_config: MixtralConfig {\n",
      "  \"_name_or_path\": \"/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\",\n",
      "  \"architectures\": [\n",
      "    \"MixtralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mixtral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts_per_tok\": 2,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_local_experts\": 8,\n",
      "  \"output_router_logits\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"bits\": 4,\n",
      "    \"damp_percent\": 0.1,\n",
      "    \"desc_act\": true,\n",
      "    \"group_size\": 32,\n",
      "    \"model_file_base_name\": \"model\",\n",
      "    \"model_name_or_path\": null,\n",
      "    \"modules_in_block_to_quantize\": [\n",
      "      [\n",
      "        \"self_attn.k_proj\",\n",
      "        \"self_attn.v_proj\",\n",
      "        \"self_attn.q_proj\"\n",
      "      ],\n",
      "      [\n",
      "        \"self_attn.o_proj\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.0.w1\",\n",
      "        \"block_sparse_moe.experts.0.w2\",\n",
      "        \"block_sparse_moe.experts.0.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.1.w1\",\n",
      "        \"block_sparse_moe.experts.1.w2\",\n",
      "        \"block_sparse_moe.experts.1.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.2.w1\",\n",
      "        \"block_sparse_moe.experts.2.w2\",\n",
      "        \"block_sparse_moe.experts.2.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.3.w1\",\n",
      "        \"block_sparse_moe.experts.3.w2\",\n",
      "        \"block_sparse_moe.experts.3.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.4.w1\",\n",
      "        \"block_sparse_moe.experts.4.w2\",\n",
      "        \"block_sparse_moe.experts.4.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.5.w1\",\n",
      "        \"block_sparse_moe.experts.5.w2\",\n",
      "        \"block_sparse_moe.experts.5.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.6.w1\",\n",
      "        \"block_sparse_moe.experts.6.w2\",\n",
      "        \"block_sparse_moe.experts.6.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.7.w1\",\n",
      "        \"block_sparse_moe.experts.7.w2\",\n",
      "        \"block_sparse_moe.experts.7.w3\"\n",
      "      ]\n",
      "    ],\n",
      "    \"quant_method\": \"gptq\",\n",
      "    \"sym\": true,\n",
      "    \"true_sequential\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"router_aux_loss_coef\": 0.02,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-30 17:11:38 config.py:618] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 03-30 17:11:38 config.py:193] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 03-30 17:11:38 llm_engine.py:87] Initializing an LLM engine with config: model='/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4', tokenizer='/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=200, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=42)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 358.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomModelType, CustomTemplateType\n\u001b[1;32m     17\u001b[0m model_type \u001b[38;5;241m=\u001b[39m CustomModelType\u001b[38;5;241m.\u001b[39mmixtral_moe_7b_instruct_gptq_int4\n\u001b[0;32m---> 18\u001b[0m llm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mget_vllm_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 检查正确的数据类型！！！！\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_model_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menforce_eager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_num_seqs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m template_type \u001b[38;5;241m=\u001b[39m get_default_template_type(model_type)\n\u001b[1;32m     32\u001b[0m template \u001b[38;5;241m=\u001b[39m get_template(template_type, llm_engine\u001b[38;5;241m.\u001b[39mhf_tokenizer)\n",
      "File \u001b[0;32m~/workspace/code/research/infodemic/LLM/swift/swift/llm/utils/vllm_utils.py:98\u001b[0m, in \u001b[0;36mget_vllm_engine\u001b[0;34m(model_type, torch_dtype, model_id_or_path, gpu_memory_utilization, tensor_parallel_size, max_model_len, engine_kwargs, use_async, enable_lora, max_loras, max_lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# fix HTTPError bug (use model_dir)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVLLM_USE_MODELSCOPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 98\u001b[0m llm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mllm_engine_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m llm_engine\u001b[38;5;241m.\u001b[39mengine_args \u001b[38;5;241m=\u001b[39m engine_args\n\u001b[1;32m    100\u001b[0m llm_engine\u001b[38;5;241m.\u001b[39mmodel_dir \u001b[38;5;241m=\u001b[39m model_dir\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:391\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args)\u001b[0m\n\u001b[1;32m    389\u001b[0m placement_group \u001b[38;5;241m=\u001b[39m initialize_cluster(parallel_config)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m             \u001b[49m\u001b[43mplacement_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m             \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:128\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, lora_config, placement_group, log_stats)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_workers_ray(placement_group)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Profile the memory usage and initialize the cache.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_cache()\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:181\u001b[0m, in \u001b[0;36mLLMEngine._init_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m Worker(\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m     is_driver_worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_workers(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:1041\u001b[0m, in \u001b[0;36mLLMEngine._run_workers\u001b[0;34m(self, method, driver_args, driver_kwargs, max_concurrent_workers, use_ray_compiled_dag, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     driver_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# Start the driver worker after all the ray workers.\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m driver_worker_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdriver_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdriver_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;66;03m# Get the results of the ray workers.\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers:\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/worker/worker.py:100\u001b[0m, in \u001b[0;36mWorker.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/worker/model_runner.py:88\u001b[0m, in \u001b[0;36mModelRunner.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_config:\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/utils.py:52\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, device_config, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m imported_model_loader \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvllm.model_executor.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_loader_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m get_model_fn \u001b[38;5;241m=\u001b[39m imported_model_loader\u001b[38;5;241m.\u001b[39mget_model\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_model_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/model_loader.py:79\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, device_config, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support LoRA, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut LoRA is enabled. Support for this model may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe added in the future. If this is important to you, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease open an issue on github.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mload_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# NOTE(woosuk): For accurate performance evaluation, we assign\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# random values to the weights.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     initialize_dummy_weights(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:345\u001b[0m, in \u001b[0;36mMixtralForCausalLM.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_method \u001b[38;5;241m=\u001b[39m linear_method\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mMixtralModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m ParallelLMHead(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;241m=\u001b[39m Sampler(config\u001b[38;5;241m.\u001b[39mvocab_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:311\u001b[0m, in \u001b[0;36mMixtralModel.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m VocabParallelEmbedding(\n\u001b[1;32m    308\u001b[0m     config\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    309\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m    312\u001b[0m     MixtralDecoderLayer(config, linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    314\u001b[0m ])\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:312\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m VocabParallelEmbedding(\n\u001b[1;32m    308\u001b[0m     config\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    309\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    310\u001b[0m )\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m--> 312\u001b[0m     \u001b[43mMixtralDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    314\u001b[0m ])\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:260\u001b[0m, in \u001b[0;36mMixtralDecoderLayer.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    251\u001b[0m rope_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_theta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m MixtralAttention(\n\u001b[1;32m    253\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    254\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_attention_heads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     sliding_window\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39msliding_window,\n\u001b[1;32m    259\u001b[0m     linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_sparse_moe \u001b[38;5;241m=\u001b[39m \u001b[43mMixtralMoE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    263\u001b[0m                                eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    265\u001b[0m                                         eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:120\u001b[0m, in \u001b[0;36mMixtralMoE.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no experts assigned to it.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m    121\u001b[0m     MixtralMLP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts,\n\u001b[1;32m    122\u001b[0m                config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    123\u001b[0m                config\u001b[38;5;241m.\u001b[39mintermediate_size,\n\u001b[1;32m    124\u001b[0m                linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts)\n\u001b[1;32m    127\u001b[0m ])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate \u001b[38;5;241m=\u001b[39m ReplicatedLinear(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    129\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts,\n\u001b[1;32m    130\u001b[0m                              bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    131\u001b[0m                              linear_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:121\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no experts assigned to it.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mMixtralMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_total_experts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m               \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m               \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m               \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts)\n\u001b[1;32m    127\u001b[0m ])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate \u001b[38;5;241m=\u001b[39m ReplicatedLinear(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    129\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts,\n\u001b[1;32m    130\u001b[0m                              bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    131\u001b[0m                              linear_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:75\u001b[0m, in \u001b[0;36mMixtralMLP.__init__\u001b[0;34m(self, num_experts, hidden_size, intermediate_size, linear_method)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim \u001b[38;5;241m=\u001b[39m hidden_size\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1 \u001b[38;5;241m=\u001b[39m ReplicatedLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim,\n\u001b[1;32m     72\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_dim,\n\u001b[1;32m     73\u001b[0m                            bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     74\u001b[0m                            linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2 \u001b[38;5;241m=\u001b[39m \u001b[43mReplicatedLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3 \u001b[38;5;241m=\u001b[39m ReplicatedLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim,\n\u001b[1;32m     80\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_dim,\n\u001b[1;32m     81\u001b[0m                            bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m                            linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# TODO: Use vllm's SiluAndMul\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py:115\u001b[0m, in \u001b[0;36mReplicatedLinear.__init__\u001b[0;34m(self, input_size, output_size, bias, skip_bias_add, params_dtype, linear_method)\u001b[0m\n\u001b[1;32m    113\u001b[0m     linear_method \u001b[38;5;241m=\u001b[39m UnquantizedLinearMethod()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_method \u001b[38;5;241m=\u001b[39m linear_method\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_weights\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weight, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/gptq.py:127\u001b[0m, in \u001b[0;36mGPTQLinearMethod.create_weights\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    123\u001b[0m         scale_and_zero_size \u001b[38;5;241m=\u001b[39m input_size_per_partition \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m group_size\n\u001b[1;32m    124\u001b[0m         scale_and_zero_input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    126\u001b[0m qweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    132\u001b[0m     requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m set_weight_attrs(\n\u001b[1;32m    135\u001b[0m     qweight, {\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpack_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mpack_factor,\n\u001b[1;32m    140\u001b[0m     })\n\u001b[1;32m    141\u001b[0m g_idx \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m    142\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    143\u001b[0m         [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 358.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "dirs = [\"../..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "\n",
    "from swift.llm import (\n",
    "    ModelType, get_vllm_engine, get_default_template_type,\n",
    "    get_template, inference_vllm, VllmGenerationConfig\n",
    ")\n",
    "from custom import CustomModelType, CustomTemplateType\n",
    "\n",
    "model_type = CustomModelType.mixtral_moe_7b_instruct_gptq_int4\n",
    "llm_engine = get_vllm_engine(\n",
    "    model_type, \n",
    "    torch_dtype=torch.float16,  # 检查正确的数据类型！！！！\n",
    "    tensor_parallel_size=1,\n",
    "    # max_model_len=8192,\n",
    "    # gpu_memory_utilization=1,\n",
    "    engine_kwargs = {\n",
    "        # \"enforce_eager\": True,\n",
    "        \"max_num_seqs\": 32,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "template_type = get_default_template_type(model_type)\n",
    "template = get_template(template_type, llm_engine.hf_tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAIM: Publication date: 2020-08-13, Content: Illinois Strengthens Face Mask Rules in Businesses\n",
      "\n",
      "To accurately classify this claim, we need to analyze the relevant information provided. \n",
      "\n",
      "Information 1: This is from 2013 and is not directly related to the claim about Illinois strengthening face mask rules in businesses in 2020. It provides general information about COVID-19 symptoms, risk factors, and prevention.\n",
      "\n",
      "Information 2: This information confirms that Illinois lifted its indoor mask requirement on February 28, 2022, except where required by specific laws, rules, and regulations. It also mentions that the state was optimistic about this decision due to the decreasing trends of COVID-19 cases. The information does not directly contradict the claim about strengthening face mask rules in 2020, but it provides context about the situation in 2021-2022.\n",
      "\n",
      "Information 3: This information reveals that on September 3, 2021, the Governor of Illinois signed an Executive Order requiring face coverings for individuals over the age of 2 in indoor public places. It also mandated vaccination for specific groups. This information supports the claim that Illinois strengthened face mask rules in businesses in 2020, as the Executive Order was issued in September 2021, which falls within the timeframe of the claim.\n",
      "\n",
      "Information 4: This information provides guidance for businesses regarding the use of face coverings during the COVID-19 pandemic. It explains the definition of a face covering, exceptions for medical conditions or disabilities, and situations where masks are still required. This information does not directly contradict the claim but provides additional context about the implementation of face mask rules in businesses.\n",
      "\n",
      "Information 5: This information is a list of statewide orders regarding face masks, but it is important to note that it was last updated on November 10, 2022, and the claim is about 2020. However, it does highlight the efforts of governors and public health officials to contain the spread of COVID-19 through stringent mitigation measures.\n",
      "\n",
      "In conclusion, based on the available information, particularly Information 3, which confirms the implementation of stricter face mask rules in businesses in Illinois in September 2021, we can reasonably infer that the claim about Illinois strengthening face mask rules in businesses in 2020 is TRUE. However, it is essential to note that the specific action mentioned in the claim might not have occurred in 2020 but rather in 2021.\n"
     ]
    }
   ],
   "source": [
    "x = \"CLAIM: Publication date: 2020-08-13, Content: Illinois Strengthens Face Mask Rules in Businesses\\n\\nTo accurately classify this claim, we need to analyze the relevant information provided. \\n\\nInformation 1: This is from 2013 and is not directly related to the claim about Illinois strengthening face mask rules in businesses in 2020. It provides general information about COVID-19 symptoms, risk factors, and prevention.\\n\\nInformation 2: This information confirms that Illinois lifted its indoor mask requirement on February 28, 2022, except where required by specific laws, rules, and regulations. It also mentions that the state was optimistic about this decision due to the decreasing trends of COVID-19 cases. The information does not directly contradict the claim about strengthening face mask rules in 2020, but it provides context about the situation in 2021-2022.\\n\\nInformation 3: This information reveals that on September 3, 2021, the Governor of Illinois signed an Executive Order requiring face coverings for individuals over the age of 2 in indoor public places. It also mandated vaccination for specific groups. This information supports the claim that Illinois strengthened face mask rules in businesses in 2020, as the Executive Order was issued in September 2021, which falls within the timeframe of the claim.\\n\\nInformation 4: This information provides guidance for businesses regarding the use of face coverings during the COVID-19 pandemic. It explains the definition of a face covering, exceptions for medical conditions or disabilities, and situations where masks are still required. This information does not directly contradict the claim but provides additional context about the implementation of face mask rules in businesses.\\n\\nInformation 5: This information is a list of statewide orders regarding face masks, but it is important to note that it was last updated on November 10, 2022, and the claim is about 2020. However, it does highlight the efforts of governors and public health officials to contain the spread of COVID-19 through stringent mitigation measures.\\n\\nIn conclusion, based on the available information, particularly Information 3, which confirms the implementation of stricter face mask rules in businesses in Illinois in September 2021, we can reasonably infer that the claim about Illinois strengthening face mask rules in businesses in 2020 is TRUE. However, it is essential to note that the specific action mentioned in the claim might not have occurred in 2020 but rather in 2021.\"\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:\n",
      "Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\n",
      "\n",
      "CLAIM:\n",
      "Publication date: 2020-08-13\n",
      "Content: Illinois Strengthens Face Mask Rules in Businesses\n",
      "\n",
      "INFORMATION:\n",
      "Information 1:\n",
      "Publication date: 2013-08-06\n",
      "Title: Illinois Strengthens Face Mask Rules in Businesses - WebMD\n",
      "Content:\n",
      "COVID-19 is a new type of coronavirus that causes mild to severe cases. Here’s a quick guide on how to spot symptoms, risk factors, prevent spread of the disease, and find out what to do if you think you have it.\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: press-release\n",
      "Content:\n",
      "Illinoisans can resume activities without wearing a mask indoors on February 28th except where required by federal, state, local, tribal, or territorial laws, rules, and regulations, including local business and workplace guidance. Federal requirements, in effect through at least March 18, include all transportation systems such as airports, planes, trains, and buses. \"Preparing to repeal statewide masking mandates at the end of the month is aggressive and optimistic but reasonable,\" said Dr.\n",
      "\"Broad mandates are not about individuals. They are put in place to help protect communities, businesses, and healthcare access. Repealing the mask mandate allows people to choose the mitigation layers that are best for them and I have no doubt that many should and will choose to keep mask rules.\"\n",
      "If these trends continue — and we expect them to —then on Monday, February 28th, we will lift the indoor mask requirement for the State of Illinois,\" said Governor JB Pritzker. \"I want to be clear: Many local jurisdictions, businesses and organizations have their own mask requirements and other mitigations that must be respected.\n",
      "Seth Trueger, a Northwestern emergency physician who is also immunocompromised. \"Masking has helped slow the spread even in the face of omicron's transmissibility. We can and must use this time to further increase vaccination uptake & outreach, especially among children and other populations with low vaccination rates, so when the next wave comes, we will be even better prepared.\"\n",
      "Information 3:\n",
      "Publication date: None\n",
      "Title: Mask and Vaccine Requirements FAQ's\n",
      "Content:\n",
      "On September 3, 2021, the Governor signed Executive Order 21-22 which requires all individuals over the age of 2 and who can medically tolerate a face covering to wear a face covering when in indoor public places. The Executive Order also requires health care workers, school personnel, higher education personnel and students, and employees and contractors of state-owned or operated congregate facilities to be fully vaccinated, as described in the Order\n",
      "Information 4:\n",
      "Publication date: None\n",
      "Title: FAQ for Businesses Concerning Use of Face-Coverings During COVID-19\n",
      "Content:\n",
      "A: Businesses reserve the right to refuse service to persons unable to comply with the requirement to wear a face covering, but they are required to provide a reasonable accommodation if it does not cause an undue hardship. Businesses are encouraged to inform customers there are exceptions to the requirement that all individuals must wear a mask.\n",
      "These frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. A: A face covering is a mask or cloth face covering that covers your nose and mouth.\n",
      "Exceptions may be made for individuals with medical conditions or disabilities that prevent them from safely wearing a face covering. For more information, refer to the questions on reasonable accommodations. A: Masks still must be worn by everyone on planes, buses, trains, and other forms of public transportation; in transportation hubs, such as airports and train and bus stations; in health care settings; and in congregate facilities, such as correctional facilities and homeless shelters.\n",
      "These frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. When Face Coverings are Required Q: What does it mean to wear a face covering?\n",
      "Information 5:\n",
      "Publication date: 2020-04-22\n",
      "Title: Facing Your Face Mask Duties – A List of Statewide Orders | Littler ...\n",
      "Content:\n",
      "********************************************************NOTE: Given the reduction in activity on this topic,THIS POST WILL NO LONGER BE UPDATED, as of November 10, 2022.********************************************************Governors and public health officials across the country implemented stringent mitigation measures to help contain the spread of COVID-19.\n",
      "\n",
      "\n",
      "response:\n",
      "Information Summary:\n",
      "\n",
      "Information 1, published on 2013-08-06, provides general information about COVID-19, its symptoms, risk factors, and ways to prevent its spread. It does not contain any information about face mask rules in Illinois businesses.\n",
      "\n",
      "Information 2, with no specific publication date, is a press release about Illinois lifting its statewide mask mandate on February 28, 2022, except where required by federal, state, local, tribal, or territorial laws, rules, and regulations. Businesses and workplaces can choose their own mitigation layers. The press release also emphasizes the importance of increasing vaccination rates.\n",
      "\n",
      "Information 3, with no specific publication date, is an FAQ about mask and vaccine requirements in Illinois. It states that Executive Order 21-22 requires individuals over the age of 2 to wear a face covering in indoor public places and that health care workers, school personnel, higher education personnel, and employees and contractors of state-owned or operated congregate facilities must be fully vaccinated.\n",
      "\n",
      "Information 4, with no specific publication date, is a FAQ for businesses concerning the use of face-coverings during COVID-19. It explains that businesses must require face coverings for all individuals, with exceptions for medical conditions or disabilities. Businesses can refuse service to those unable to comply with the face covering requirement but must provide reasonable accommodations. Masks are still required on public transportation, in transportation hubs, health care settings, and congregate facilities.\n",
      "\n",
      "Information 5, published on 2020-04-22, is a post about statewide face mask orders across the country. It states that governors and public health officials implemented measures to contain the spread of COVID-19, but this post will no longer be updated as of November 10, 2022.\n",
      "\n",
      "Claim Veracity:\n",
      "\n",
      "The claim, published on 2020-08-13, states that \"Illinois Strengthens Face Mask Rules in Businesses.\" However, the available information suggests that Illinois actually lifted its statewide mask mandate on February 28, 2022, except where required by federal, state, local, tribal, or territorial laws, rules, and regulations. Businesses and workplaces can choose their own mitigation layers. Therefore, the claim is FALSE based on the available information and current situation in Illinois.\n"
     ]
    }
   ],
   "source": [
    "generation_config = VllmGenerationConfig(\n",
    "    max_new_tokens=4096,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "request_list = [\n",
    "    {'query': 'Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\\n",
    "\\n\\nCLAIM:\\nPublication date: 2020-08-13\\nContent: Illinois Strengthens Face Mask Rules in Businesses\\n\\nINFORMATION:\\nInformation 1:\\nPublication date: 2013-08-06\\nTitle: Illinois Strengthens Face Mask Rules in Businesses - WebMD\\nContent:\\nCOVID-19 is a new type of coronavirus that causes mild to severe cases. Here’s a quick guide on how to spot symptoms, risk factors, prevent spread of the disease, and find out what to do if you think you have it.\\nInformation 2:\\nPublication date: None\\nTitle: press-release\\nContent:\\nIllinoisans can resume activities without wearing a mask indoors on February 28th except where required by federal, state, local, tribal, or territorial laws, rules, and regulations, including local business and workplace guidance. Federal requirements, in effect through at least March 18, include all transportation systems such as airports, planes, trains, and buses. \"Preparing to repeal statewide masking mandates at the end of the month is aggressive and optimistic but reasonable,\" said Dr.\\n\"Broad mandates are not about individuals. They are put in place to help protect communities, businesses, and healthcare access. Repealing the mask mandate allows people to choose the mitigation layers that are best for them and I have no doubt that many should and will choose to keep mask rules.\"\\nIf these trends continue — and we expect them to —then on Monday, February 28th, we will lift the indoor mask requirement for the State of Illinois,\" said Governor JB Pritzker. \"I want to be clear: Many local jurisdictions, businesses and organizations have their own mask requirements and other mitigations that must be respected.\\nSeth Trueger, a Northwestern emergency physician who is also immunocompromised. \"Masking has helped slow the spread even in the face of omicron\\'s transmissibility. We can and must use this time to further increase vaccination uptake & outreach, especially among children and other populations with low vaccination rates, so when the next wave comes, we will be even better prepared.\"\\nInformation 3:\\nPublication date: None\\nTitle: Mask and Vaccine Requirements FAQ\\'s\\nContent:\\nOn September 3, 2021, the Governor signed Executive Order 21-22 which requires all individuals over the age of 2 and who can medically tolerate a face covering to wear a face covering when in indoor public places. The Executive Order also requires health care workers, school personnel, higher education personnel and students, and employees and contractors of state-owned or operated congregate facilities to be fully vaccinated, as described in the Order\\nInformation 4:\\nPublication date: None\\nTitle: FAQ for Businesses Concerning Use of Face-Coverings During COVID-19\\nContent:\\nA: Businesses reserve the right to refuse service to persons unable to comply with the requirement to wear a face covering, but they are required to provide a reasonable accommodation if it does not cause an undue hardship. Businesses are encouraged to inform customers there are exceptions to the requirement that all individuals must wear a mask.\\nThese frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. A: A face covering is a mask or cloth face covering that covers your nose and mouth.\\nExceptions may be made for individuals with medical conditions or disabilities that prevent them from safely wearing a face covering. For more information, refer to the questions on reasonable accommodations. A: Masks still must be worn by everyone on planes, buses, trains, and other forms of public transportation; in transportation hubs, such as airports and train and bus stations; in health care settings; and in congregate facilities, such as correctional facilities and homeless shelters.\\nThese frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. When Face Coverings are Required Q: What does it mean to wear a face covering?\\nInformation 5:\\nPublication date: 2020-04-22\\nTitle: Facing Your Face Mask Duties – A List of Statewide Orders | Littler ...\\nContent:\\n********************************************************NOTE: Given the reduction in activity on this topic,THIS POST WILL NO LONGER BE UPDATED, as of November 10, 2022.********************************************************Governors and public health officials across the country implemented stringent mitigation measures to help contain the spread of COVID-19.\\n'},\n",
    "    # {'query': \"1+1=?\"},\n",
    "]\n",
    "\n",
    "\n",
    "resp_list = inference_vllm(\n",
    "    llm_engine, template, request_list, generation_config=generation_config, \n",
    "    # use_tqdm=True,\n",
    "    # verbose=True, prompt_prefix=\"\", output_prefix=\"\"\n",
    ")\n",
    "\n",
    "for request, resp in zip(request_list, resp_list):\n",
    "    print(f\"query:\\n{request['query']}\")\n",
    "    print()\n",
    "    print(f\"response:\\n{resp['response']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
