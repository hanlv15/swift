{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 23:29:27,101 - modelscope - INFO - PyTorch version 2.3.0 Found.\n",
      "2024-07-02 23:29:27,103 - modelscope - INFO - Loading ast index from /home/hanlv/.cache/modelscope/ast_indexer\n",
      "2024-07-02 23:29:27,137 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 21bc0b9ccf26bcf3f4ca2e675ec8875d and a total number of 980 components indexed\n",
      "[INFO:swift] Successfully registered `/home/hanlv/workspace/code/research/infodemic/LLM/swift/swift/llm/data/dataset_info.json`\n",
      "[INFO:swift] Loading the model using model_dir: /home/css/models/Mixtral-8x7B-Instruct-v0.1-AWQ\n",
      "[INFO:swift] model_config: MixtralConfig {\n",
      "  \"_name_or_path\": \"/home/css/models/Mixtral-8x7B-Instruct-v0.1-AWQ\",\n",
      "  \"architectures\": [\n",
      "    \"MixtralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mixtral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts_per_tok\": 2,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_local_experts\": 8,\n",
      "  \"output_router_logits\": false,\n",
      "  \"quantization_config\": {\n",
      "    \"bits\": 4,\n",
      "    \"group_size\": 128,\n",
      "    \"modules_to_not_convert\": [\n",
      "      \"gate\"\n",
      "    ],\n",
      "    \"quant_method\": \"awq\",\n",
      "    \"version\": \"gemm\",\n",
      "    \"zero_point\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"router_aux_loss_coef\": 0.02,\n",
      "  \"router_jitter_noise\": 0.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from swift.llm import get_model_tokenizer\n",
    "dirs = [\"/home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm\",\n",
    "        \"..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "import covmis\n",
    "from custom import CustomModelType, CustomTemplateType\n",
    "model_type = CustomModelType.mixtral_moe_7b_instruct_awq\n",
    "# model_type = CustomModelType.llama_3_70b_instruct_awq\n",
    "model, tokenizer = get_model_tokenizer(\n",
    "    model_type, \n",
    "    load_model=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf282b72e55944cd823734f4b7fbbdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sort = False\n",
    "prior_knowledge_list = []\n",
    "\n",
    "K = 5\n",
    "prior_knowledge_version = \"1\"\n",
    "model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "with open(f\"train_search_llm_tmp.json\", \"r\") as f:\n",
    "    prior_knowledge_list = json.load(f)\n",
    "# prior_knowledge_list = covmis.load_train_llm()\n",
    "\n",
    "\n",
    "lens1 = []\n",
    "lens2 = []\n",
    "\n",
    "# for item in tqdm(prior_knowledge_list):\n",
    "#     pk=item[f\"prior_knowledge_{model_name}\"]\n",
    "#     lens1.append(len(tokenizer(pk)[\"input_ids\"]))\n",
    "\n",
    "for item in tqdm(prior_knowledge_list):\n",
    "    # if item.get(f\"prior_knowledge_{model_name}\") is None:\n",
    "    #     lens1.append(1000)\n",
    "    #     continue\n",
    "\n",
    "    pk=item[f\"prior_knowledge_{model_name}\"]\n",
    "    # pk=item[f\"prior_knowledge_{model_name}_v1_K=5\"]\n",
    "\n",
    "    lens1.append(len(tokenizer(pk)[\"input_ids\"]))\n",
    "    # lens2.append(len(tokenizer.tokenize(item[\"query\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in lens1:\n",
    "    if i < 240 or i > 900:\n",
    "        cnt += 1\n",
    "cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240, 240, 240, 240, 240, 240, 240, 240, 240, 240]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mixtral: 240~900之外的单独跑\n",
    "# llama3: 172~715\n",
    "sorted(lens1, reverse=False)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改较长的句子\n",
    "\n",
    "显卡 24GB\n",
    "\n",
    "7B模型，长度控制在3600以下 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5994, 8863, 11417, 13820]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_ids = []\n",
    "for i, item in enumerate(lens1):\n",
    "    if item == 151:\n",
    "        del_ids.append(i)\n",
    "\n",
    "del_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Information 3 is relevant to the claim. According to Information 3. the claim was investigated by a Ghanaian fact-checking organization called Dubawa Ghana. They found no evidence to support the claim that Ghana's President, Nana Akufo-Addo, planned on resigning and will not contest the December 2020 elections if Ghana recorded 500 Covid-19 cases. The Director of Communications to the President, Eugene Arhin, has also denied the claim. Dubawa Ghana was unable to find any evidence of the claim being made by the Ghanaian President.\\n\\nThe other information provided does not directly address the claim, but they provide context to the actions of the Ghanian government and its leadership in response to the COVID-19 pandemic.\\n\\nTherefore, based on the information provided, the claim is FALSE, as the claim of resignation was investigated and found to be false.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(tokenizer(dict_list[4157][\"query\"])[\"input_ids\"]))\n",
    "prior_knowledge_list[14188][f\"prior_knowledge_{model_name}\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information 1 directly refutes the claim, stating that a photograph often shared in connection with food scarcity and lockdowns is actually from 2013 and unrelated to the COVID-19 pandemic. The photograph shows a baby breastfeeding on her living, mother, not a dead one. Later information provided is unrelated to the claim.\n",
      "\n",
      "Given the evidence. FALSE\n",
      "\n",
      "Reference(s):\n",
      "Information 1: FALSE: A photograph shows a baby breastfeeding on her dead mother ... (2020-06-12)\n",
      "CLAIM: A photograph shows a baby breastfeeding on her dead mother who lost her life due to food scarcity during the lockdown.\n"
     ]
    }
   ],
   "source": [
    "# print(prior_knowledge_list[2278][f\"prior_knowledge_{model_name}_v1_K=5\"])\n",
    "print(prior_knowledge_list[5994][f\"prior_knowledge_{model_name}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The claim that the government of Paraíba, a state in Brazil, received 11.6 million Brazilian reais from the federal government to spend on healthcare during the COVID-19 crisis but instead, this money is being spent on artistic performances, cannot be definitively assessed as true or false with the provided information. However, the information about Brazil's history of corruption (Information 4 and 5) suggests that such misuse of public funds is a possibility.\n",
      "Based on the provided information, the claim is false. The document approved by the Italian Health Ministry does not \"ban\" but rather discourages the routine performance of autopsies on COVID-19 patients, except for specific circumstances. The information in the article is consistent with the guidelines and protocols established by the Italian government regarding the post-mortem of COVID-19 patients.\n",
      "Based on the given information, the CLAIM that the CCTV footage of a Wuhan wildlife market showing the sale and butchering of snakes, bats, and other wild animals is false. The claim originates. from a misunderstanding, as the actual footage stems from the Indonesian island of Sulawesi.\n",
      "The claim that the U.S. has \"a better handle on [COVID-19] than Europe\" and that the disease is \"less deadly\" in the U.S. than in Europe is incorrect. The COVID-19 pandemic has had a significant impact in both the US and in many countries in Europe, and the response to the virus in these regions has been criticized. Factors including an unsuitable level of integration, inability to make rapid decisions, and a breakdown of trust between governments and the governed have made it difficult for many countries to cope with the pandemic.\n",
      "It is important to note that the information provided is from 2020, and the current situation regarding the spread of the virus and the availability of testing has likely changed. However, based on the information provided, the claim was accurate as of July 2020.\n",
      "Based on the provided information, the claim is mostly false. The claim suggests that the media is hyping the threat of the virus by wearing protective gear when it is not necessary, but the actual photo in question was taken during a test of the gear, and the journalist clarified that there was no need to panic at the time. Additionally, the claim incorrectly assumes that the photo is from Brazil, but it actually depicts a Lebanese journalist in Lebanon. Therefore, the claim lacks sufficient evidence and is misleading.\n",
      "Regarding the information 5, it is not directly related to the claim, but it does provide useful information on the current status of the global coronavirus-related intellectual property and the efforts of the international community to address the current pandemic.\n",
      "Given the information, the claim is false. Dr. Wenliang Li, the doctor who warned others about the novel coronavirus and later succumbed to the virus, is not the same as the unnamed Wuhan hospital doctor in the claim.\n",
      "Given the above information, the claim that \"New York schools add a COVID-19 vaccine to the mandatory school schedule\" is currently false, as of October 2022, as a state law to require the COVID-19 vaccine for school attendance is still being considered.\n",
      "Therefore, the claim lacks the proper nuance and is mostly false.\n",
      "The claim is that a ban on Chinese people in Australian supermarkets exists.\n",
      "Information 3 is a statement from the ex-Governor Mike Sonko, where he claimed that some Kenyan senators were offered KSh 2 million (which is equal to around 18,000 USD) as a bribe to support the censure motion motion.\n",
      "Therefore, the claim remains as \"unverified\" and no reasonable evidence is available to accurately assess the claim's correctness.\n",
      "The claim is false. There is no evidence that the previous French health minister prevented the use of a specific medication to harm Didier Raoult. The articles mainly describe the disagreements between Raoult and the public health authorities regarding the treatment of Covid-19.\n",
      "Based on the aforementioned information. The claim that the image of Muslims praying on an Australian street circulating in reports since 2013 is not related to the COVID-19 lockdown is rated as \"True\". The evidence presented confirms that the photo is not related to the pandemic and has been in circulation since at least 2013.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'mixtral'\n",
    "import json\n",
    "# prior_knowledge_list = covmis.load_train_llm()\n",
    "with open(f\"train_search_llm_tmp.json\", \"r\") as f:\n",
    "    prior_knowledge_list = json.load(f)\n",
    "def get_lst_sent(s, model_name):\n",
    "    assert model_name in [\"mixtral\", \"llama3\", \"solar\"], \"model name error\"\n",
    "    mixtral_pass_list = [\"[Reference(s):\", \"Reference(s):\", \"Reliable sources,\",\n",
    "              \"References:\", \"Sources:\", \"Reference List.\", \"Reference:\", \"Source:\", \"[References]:\",\n",
    "              \"Reference(s, if any):\", \"[Reference article\", \"Reference links:\",\n",
    "\n",
    "              \"Reasonable evidence to support the judgment:\", \"Reasoning behind the classification:\",\n",
    "              \"Reasoning and evidence hierarchy:\", \"Reasonable evidence:\", \"Evidence grade:\",\n",
    "              \"Evidence:\", \"Reasoning..:\", \"Reasoning:\", \"Reason:\", \"Rationale:\", \"reasons:\", \"Reasoning.\",\n",
    "\n",
    "              \"Myevidencelock:\", \n",
    "              \"Factual Details:\",\n",
    "              \"(Note:\",\n",
    "              \"*Note:\", \"Note:\", \"Extra note.\",\n",
    "              \"Similar symptoms:\",\n",
    "              \"Justification:\",\n",
    "              \"*Partial truth:\",\n",
    "              \"Regarding the other information\",\n",
    "              \n",
    "              \"publishers:\",\n",
    "              \"Background:\",\n",
    "              \"More information is available\",\n",
    "              \"Confidence:\",\n",
    "              \"Sincerely,\",\n",
    "              \"Please note:\",\n",
    "              \"Action:\",\"Explication:\",\n",
    "              \"The NIH is beginning a new study to determine the spread of the novel\",\n",
    "              \"Reasonable evidence to support the claim's inaccuracy includes:\",\n",
    "            \"Comments:\", \"Confidence level:\", \"Suggested citation:\", \"Bibliography:\",\n",
    "            \"The following is a summary of the relevant information regarding the claim:\",\n",
    "            \"The following is a summary of the information provided:\",\n",
    "            \"The references for the information used in the summary:\",\n",
    "            \"Stealth mode:\", \"Caution:\",\n",
    "            \"The following evidence was used to support the determination of FACTUALITY:\",\n",
    "            \"The other information provided\", \"Reference List:\", \"Source list:\",\n",
    "            \"Here are the sources used for this answer:\",\n",
    "            \"[X](\", \"The reference to the other Information and articles:\", \"Published on 05/22/2023 02:12 PM\",\"Thus, the claim is classified as:\",\n",
    "            \"More specifically.\", \"Changes:\", \"Reasonable evidence to judge the correctness of the claim:\", \"Reference articles used in the evaluation of the claim:\",\n",
    "            \"Meta:\", \"The claim wrongfully combines\", \"[Factualness:\", \"Source citations:\", \"The first information confirms that the\", \"Here’s why:\",\n",
    "              ]\n",
    "    \n",
    "    if model_name == \"mixtral\":\n",
    "        for x in mixtral_pass_list:\n",
    "            src_pos = s.lower().find(x.lower())\n",
    "            if src_pos != -1:\n",
    "                s = s[:src_pos].strip()\n",
    "\n",
    "    lines = []\n",
    "    for line in s.split('\\n'):\n",
    "        if len(line) > 0:\n",
    "            lines.append(line)\n",
    "    \n",
    "    labels = [\n",
    "        \"FALSE\", \"TRUE\",\n",
    "        # \"UNVERIFIED\", # llama3\n",
    "        ]\n",
    "    for line in lines[::-1]:\n",
    "        for label in labels:\n",
    "            _pos = line.find(label)\n",
    "            if _pos != -1:\n",
    "                return line\n",
    "\n",
    "    return lines[-1], 1\n",
    "    # pos = s.rfind(\"\\n\")\n",
    "    # return s[pos + 1:]\n",
    "\n",
    "# \"the CLAIM is classified as FALSE.\"\n",
    "nn = 60\n",
    "cnt = 0\n",
    "for i, item in enumerate(prior_knowledge_list[:50]):\n",
    "    \n",
    "    a = get_lst_sent(item[f\"prior_knowledge_{model_name}\"], model_name)\n",
    "    if isinstance(a, tuple):\n",
    "        # print(i)\n",
    "        # print(item[f\"prior_knowledge_{model_name}_v1_K=5\"])\n",
    "        # print('\\n\\n')\n",
    "        print(a[0])\n",
    "        cnt += 1\n",
    "\n",
    "cnt\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['While the CLAIM does not provide specific details about the patents, it is likely that this is another conspiracy theory with no scientific basis. The cumulative evidence from the provided information suggests that the CLAIM is FALSE.',\n",
       " '3. Information 5, a Wikipedia entry from 2024-01-06, mentions a video circulating online in January 2020, which claimed to show a nurse describing a dire situation in Wuhan. However, the BBC debunked the video, stating that the woman did not claim to be a nurse or doctor, and her attire did not match medical staff in Hubei. This suggests that similar videos with false claims were circulating online during the pandemic.',\n",
       " '2. Information 3, an article from 2020-05-12, discusses a viral video with harmful claims, which was removed by platforms, but still managed to reach over 8 million views. This could be the same video referred to in the CLAIM.',\n",
       " '1. Information 1, a fact-check from 2020-04-10, states that scientific evidence indicates the SARS-CoV-2 virus was not intentionally created in a laboratory, and there is no evidence of its existence before December 2019. This contradicts the CLAIM that the virus already existed.',\n",
       " \"Based on the provided information, it appears that the CLAIM is likely FALSE. Here's why:\",\n",
       " '**Evidence to judge the correctness of the CLAIM:**',\n",
       " 'The claim states that a woman in a video asserts that everything about the pandemic is a hoax, that the virus already existed, and that there are patents that prove it.',\n",
       " '**Summary of CLAIM:**',\n",
       " 'The provided information consists of five pieces of content related to the COVID-19 pandemic and conspiracy theories surrounding it. The information covers fact-checks, articles, and Wikipedia entries that debunk various false claims about the pandemic.',\n",
       " '**Summary of INFORMATION:**']"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lines = []\n",
    "for line in prior_knowledge_list[nn][f\"prior_knowledge_{model_name}_v1_K=5\"].split('\\n'):\n",
    "    if len(line) > 0:\n",
    "        lines.append(line)\n",
    "lines[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ok_list = [\n",
    "    \"information\",\n",
    "    \"* TRUE for the \\\"COVID-19 Daily\".lower(),\n",
    "    \"claim\", \"impact\", \"aily\",\n",
    "    \"classified as\", \"clarifications\",\n",
    "    \"summary\",\"conclusion\",\"summarized\",\n",
    "    \"is\", \"ydroxychloroquine\", \n",
    "    \"formation 1\",\"formation 2\",\"formation 3\",\"formation 4\",\"formation 5\", \"5\",\n",
    "    \"discussion\", \"decision\", \"assessment\", \"classification\", \"covid-19\", \"covid--19\", \"clarification\",\n",
    "    \"content\", \"force\", \"includes\", \"title\", \"'cabin'\", \"check\",\n",
    "    \"rating\", \"social\", \"infodemic\", \"SARS-CoV-2\".lower(),\n",
    "    \"uestions\", \"as follows\", \"analysis\", \"idsa\", \"niversities\",\"include\", \"auci\",\n",
    "    \"https\", \"date\", \"verification\", \"verdict\", \"contact\", \"symptoms\", \"says\", \"knowledge\",\n",
    "    \"correctness\", \"DETERMINATION\".lower(), \"assertion\", \"system'\", \"system\", \"rally\",\n",
    "    \"are\", \"RULING\".lower(), \"as\", \"published\", \"coronavirus\", \"false\", \"COMMENTARY\".lower(),\n",
    "    \"explanation\", \"pandemic\", \"igerians\", \"you\", \"publication\", \"pets\", \"hype\",\"this'\",\"laim\",\n",
    "    \"topic\", \"covid\", \"14\", \")\", \"act-check findings\", \"eracity\", \"vidence.1\", \"response\",\n",
    "    \"eaths\", \"diarrhea\", \"inaccuracy\", \"caveat\", \"ockdown\", \"classifications\", \"STATUS\".lower(),\n",
    "    \"that\", \"ates\", \"ays\", \"judgment\", \"true\", \"be\", \"doi\", \"biotics\", \"articles\", \"mostly\",\n",
    "    \"trump\", \"details\", \"answer\", \"theories\", \"following\", \"2020-21\", \"outcomes\", \"tudy\",\n",
    "    \"ives\", \"judgement\", \"ntroduction\", \"ine\", \"CLUII\".lower(), \"ormula\",\n",
    "    \"johnshopkins\", \"diagnostic remarks\", \"http\", \"exercises\", \"recommendation\", \"leak\",\n",
    "    \"coronaviruses\", \"summarize\", \"istancing\", \"utlook\", \"orrection\", \"remains\",\"ongolia\",\n",
    "    \"abric\", \"43\", \"28\", \"reasonings\", \"esult\", \"landemic\", \"DRUGS\".lower(), \"esting\",\n",
    "    \"ositive\", \"therefore\", \"used\", \"06\", \"incidents\", \"onuses\", \"above\", \"masks\", \"opposite\",\n",
    "    \"involves\", \"ictims\", \"informations\", \"treatments\", \"insights\", \"angerous\", \"pread\",\n",
    "    \"concepts\", \"ight\", \"valuation\", \"provided\", \"said\", \"odels\", \"partments\", \"fizer\", \"examination\",\n",
    "    \"context\", \"tests\", \"oll\", \"keypoint\", \"lasification\", \"diseases\", \"ighlighted\", \"iktionary\",\n",
    "    \"including\", \"**CLAIM\".lower(), \"ovations\", \"contents\", \"actual\", \"co-ki”\", \"recipients\",\n",
    "    \"remarks\", \"84\", \"debunked\", \"accuracy\", \"elements\", \"claire\", \"china\", \"fact\", \"display\", \"explain\",\n",
    "    \"turkish\", \"tv\", \"ones\", \"mailto\", \"opinion\", \"validity\", \"a 2\", \"aev\", \"well\", \"ystery\", \"color\",\n",
    "    \"true*\", \"hmadinejad\", \"ay 2\", \"lunchtime\", \"~\", \"processes**\", \"xpert\", \"sleep\", \"considering\",\n",
    "    \"misleading\", \"factors\", \"cdc\", \"lait\", \"taught\", \"findings\", \"ruth\", \"rick\", \"oax\", \"20\",\n",
    "\n",
    "]\n",
    "for i, item in enumerate(prior_knowledge_list):\n",
    "    \n",
    "    s = item[f\"prior_knowledge_{model_name}\"]\n",
    "    nxt = False\n",
    "    for x in pass_list:\n",
    "        src_pos = s.lower().find(x.lower())\n",
    "        if src_pos != -1:\n",
    "            nxt = True\n",
    "            break\n",
    "\n",
    "    if nxt:\n",
    "        continue\n",
    "    pos1 = s.rfind(\":\")\n",
    "    if pos1 == -1:\n",
    "        continue\n",
    "    pos2 = s[:pos1].rfind(\"\\n\")\n",
    "    for s_ok in ok_list:\n",
    "        if s[pos2+1:pos1].lower().endswith(s_ok) or s[pos2+1:pos1].lower().startswith(s_ok):\n",
    "            nxt = True\n",
    "            break\n",
    "    if nxt:\n",
    "        continue\n",
    "    print(i)\n",
    "    # print(s[pos2+1:pos1])\n",
    "    print(s[pos2+1:])\n",
    "    print('#'*50)\n",
    "    print(s)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
