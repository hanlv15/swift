{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import sys\n",
    "import prompt_rag\n",
    "\n",
    "search_engine = \"brave\"\n",
    "\n",
    "with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search.json\", \"r\") as f:\n",
    "    data_search = json.load(f)\n",
    "\n",
    "try:\n",
    "    with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"r\") as f:\n",
    "        data_search_llm = json.load(f)\n",
    "except:\n",
    "    data_search_llm = [{\n",
    "        \"claim\": i[\"claim\"],\n",
    "        \"claimant\": i[\"claimant\"],\n",
    "        \"label\": i[\"label\"],\n",
    "        \"date\": i[\"date\"],\n",
    "    } for i in data_search]\n",
    "    with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"w\") as f:\n",
    "        json.dump(data_search_llm, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.update_train_search_llm( \n",
    "#     \"SOLAR-10.7B-Instruct-v1.0\", \"solar\", port=8001, \n",
    "#     data_search=data_search, data_search_llm=data_search_llm) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并多个文件的先验知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对prior_knowledge做修改\n",
    "# sort = False\n",
    "# prior_knowledge_list = []\n",
    "\n",
    "# K = 5\n",
    "# prior_knowledge_version = \"1\"\n",
    "# prior_knowledge_version_adjust = prior_knowledge_version + \".2\"\n",
    "# model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     prior_knowledge = item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"]\n",
    "    \n",
    "#     find_list = [\n",
    "#         \"Information Expansion and Summary:\",\n",
    "#         # \"Information Summary:\",\n",
    "#         # \"Expanded Information Summary:\",\n",
    "#         \"Claim Analysis:\",\n",
    "#         # \"Claim Verification\",\n",
    "#         # \"Claim Analysis and Judgement:\"\n",
    "#     ]\n",
    "\n",
    "\n",
    "#     for s in find_list:\n",
    "#         pos = prior_knowledge.find(s)\n",
    "#         if pos == -1:\n",
    "#             continue\n",
    "        \n",
    "#         num_extra = 2\n",
    "#         if pos!=0 and prior_knowledge[pos-1] == '\\n':\n",
    "#             pos -= 1\n",
    "#             num_extra += 1\n",
    "#         prior_knowledge = prior_knowledge[:pos] + prior_knowledge[pos + len(s) + num_extra :]\n",
    "\n",
    "  \n",
    "#     item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version_adjust}_K={K}\"] = prior_knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing search llm\n",
    "# v2: k = 5\n",
    "# v3: 不对时间排序\n",
    "\n",
    "# brave search llm\n",
    "\n",
    "# Solar\n",
    "# v1: k = 5\n",
    "# v2: k = 5 随机选取\n",
    "\n",
    "# Mixtral\n",
    "# v1: k = 5\n",
    "# v1.1: 删除结构化内容（Information Expansion and Summary、Claim Analysis）\n",
    "\n",
    "sort = False\n",
    "prior_knowledge_list = []\n",
    "\n",
    "K = 5\n",
    "prior_knowledge_version = \"1\"\n",
    "model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# with open(f\"train_search_llm_tmp.json\", \"r\") as f:\n",
    "#     prior_knowledge_list = json.load(f)\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     if item[\"claim\"] != prior_knowledge_list[i][\"claim\"].strip():\n",
    "#         print(i)\n",
    "#         print(item[\"claim\"])\n",
    "#         print(prior_knowledge_list[i][\"claim\"])\n",
    "#         raise Exception()\n",
    "#     else:\n",
    "#         # vv = \"\"\n",
    "#         # if prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}3\") is not None:\n",
    "#         #     vv = \"3\"\n",
    "#         # elif prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}2\") is not None:\n",
    "#         #     vv = \"2\"\n",
    "\n",
    "#         item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"] = prior_knowledge_list[i][f\"prior_knowledge_{model_name}\"]\n",
    "\n",
    "# data_search_llm[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.save_search_llm(data_search_llm, search_engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建数据（带有先验知识的Prompt）以微调LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list = []\n",
    "\n",
    "# data_version = \"2\"\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "    \n",
    "#     if int(item[\"label\"]) != 1:\n",
    "#         prompt = prompt_rag.get_prompt_with_prior_knowledge(\n",
    "#             item[\"claim\"], \n",
    "#             search_engine,\n",
    "#             data_search[i][f\"{search_engine}_search_results\"], \n",
    "#             item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"], \n",
    "#             K=K,\n",
    "#             claim_date=item[\"date\"],\n",
    "#             sort=sort,\n",
    "#             known_info=False, # 不含已知信息\n",
    "#             ids=None \n",
    "#         )\n",
    "#         label = \"TRUE.\" if int(item[\"label\"]) == 2 else \"FALSE.\"\n",
    "#         dict_list.append({\"query\": prompt, \"response\": label})\n",
    "# print(dict_list[0][\"query\"])\n",
    "# len(dict_list), dict_list[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_dir = \"/home/hanlv/workspace/code/research/infodemic/LLM/\"\n",
    "# with jsonlines.open(\n",
    "#     LLM_dir + \\\n",
    "#     f\"swift/examples/pytorch/llm/my_data/with_{model_name}_info/{search_engine}/data{data_version}.jsonl\", mode=\"w\") as file_jsonl:\n",
    "#     for line in dict_list:\n",
    "#         file_jsonl.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型的先验知识生成效果：一次提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 11:16:21,455 - modelscope - INFO - PyTorch version 2.3.0 Found.\n",
      "2024-05-06 11:16:21,458 - modelscope - INFO - Loading ast index from /home/hanlv/.cache/modelscope/ast_indexer\n",
      "2024-05-06 11:16:21,493 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 2a8987246d4b67f321effea600434525 and a total number of 976 components indexed\n",
      "[INFO:swift] Loading the model using model_dir: /home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\n",
      "[INFO:swift] Setting torch_dtype: torch.float16\n",
      "[INFO:swift] model_config: MixtralConfig {\n",
      "  \"_name_or_path\": \"/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\",\n",
      "  \"architectures\": [\n",
      "    \"MixtralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mixtral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts_per_tok\": 2,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_local_experts\": 8,\n",
      "  \"output_router_logits\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"bits\": 4,\n",
      "    \"damp_percent\": 0.1,\n",
      "    \"desc_act\": true,\n",
      "    \"group_size\": 32,\n",
      "    \"model_file_base_name\": \"model\",\n",
      "    \"model_name_or_path\": null,\n",
      "    \"modules_in_block_to_quantize\": [\n",
      "      [\n",
      "        \"self_attn.k_proj\",\n",
      "        \"self_attn.v_proj\",\n",
      "        \"self_attn.q_proj\"\n",
      "      ],\n",
      "      [\n",
      "        \"self_attn.o_proj\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.0.w1\",\n",
      "        \"block_sparse_moe.experts.0.w2\",\n",
      "        \"block_sparse_moe.experts.0.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.1.w1\",\n",
      "        \"block_sparse_moe.experts.1.w2\",\n",
      "        \"block_sparse_moe.experts.1.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.2.w1\",\n",
      "        \"block_sparse_moe.experts.2.w2\",\n",
      "        \"block_sparse_moe.experts.2.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.3.w1\",\n",
      "        \"block_sparse_moe.experts.3.w2\",\n",
      "        \"block_sparse_moe.experts.3.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.4.w1\",\n",
      "        \"block_sparse_moe.experts.4.w2\",\n",
      "        \"block_sparse_moe.experts.4.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.5.w1\",\n",
      "        \"block_sparse_moe.experts.5.w2\",\n",
      "        \"block_sparse_moe.experts.5.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.6.w1\",\n",
      "        \"block_sparse_moe.experts.6.w2\",\n",
      "        \"block_sparse_moe.experts.6.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.7.w1\",\n",
      "        \"block_sparse_moe.experts.7.w2\",\n",
      "        \"block_sparse_moe.experts.7.w3\"\n",
      "      ]\n",
      "    ],\n",
      "    \"quant_method\": \"gptq\",\n",
      "    \"sym\": true,\n",
      "    \"true_sequential\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"router_aux_loss_coef\": 0.02,\n",
      "  \"router_jitter_noise\": 0.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-06 11:16:22 config.py:1086] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 05-06 11:16:22 config.py:177] The model is convertible to Marlin format. Using Marlin kernel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 11:16:24,940\tINFO worker.py:1749 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-06 11:16:26 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4', speculative_config=None, tokenizer='/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, disable_custom_all_reduce=False, quantization=gptq_marlin, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=42, served_model_name=/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4)\n",
      "INFO 05-06 11:16:32 utils.py:660] Found nccl from library /home/hanlv/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:16:32 utils.py:660] Found nccl from library /home/hanlv/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-06 11:16:32 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 05-06 11:16:32 selector.py:32] Using XFormers backend.\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:16:34 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:16:34 selector.py:32] Using XFormers backend.\n",
      "INFO 05-06 11:16:35 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:16:35 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "INFO 05-06 11:16:37 utils.py:132] reading GPU P2P access cache from /home/hanlv/.config/vllm/gpu_p2p_access_cache_for_0,2.json\n",
      "WARNING 05-06 11:16:37 custom_all_reduce.py:74] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:16:37 utils.py:132] reading GPU P2P access cache from /home/hanlv/.config/vllm/gpu_p2p_access_cache_for_0,2.json\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m WARNING 05-06 11:16:37 custom_all_reduce.py:74] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 05-06 11:16:49 model_runner.py:175] Loading model weights took 12.4631 GB\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:16:48 model_runner.py:175] Loading model weights took 12.4631 GB\n",
      "INFO 05-06 11:17:03 distributed_gpu_executor.py:45] # GPU blocks: 2737, # CPU blocks: 4096\n",
      "INFO 05-06 11:17:05 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-06 11:17:05 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:17:05 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:17:05 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerWrapper pid=1235358)\u001b[0m INFO 05-06 11:17:36 model_runner.py:1017] Graph capturing finished in 31 secs.\n",
      "INFO 05-06 11:17:38 model_runner.py:1017] Graph capturing finished in 33 secs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,2'\n",
    "\n",
    "dirs = [\"../..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "\n",
    "from swift.llm import (\n",
    "    ModelType, get_vllm_engine, get_default_template_type,\n",
    "    get_template, inference_vllm, VllmGenerationConfig\n",
    ")\n",
    "from custom import CustomModelType, CustomTemplateType\n",
    "\n",
    "# model_type = ModelType.mixtral_moe_7b_instruct\n",
    "model_type = CustomModelType.mixtral_moe_7b_instruct_gptq_int4\n",
    "# model_type = CustomModelType.solar_instruct_10_7b\n",
    "\n",
    "llm_engine = get_vllm_engine(\n",
    "    model_type, \n",
    "    torch_dtype=torch.float16,  # 检查正确的数据类型！！！！\n",
    "    tensor_parallel_size=2,\n",
    "    # max_model_len=4096,\n",
    "    # gpu_memory_utilization=0.9,\n",
    "    # model_id_or_path=\"/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\",\n",
    "    engine_kwargs = {\n",
    "        # \"enforce_eager\": True,\n",
    "        \"max_num_seqs\": 64,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "template_type = get_default_template_type(model_type)\n",
    "template = get_template(template_type, llm_engine.hf_tokenizer)\n",
    "\n",
    "generation_config = VllmGenerationConfig(\n",
    "    max_new_tokens=2048,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "get_resp_list = lambda request_list : inference_vllm(\n",
    "    llm_engine, template, request_list, \n",
    "    generation_config=generation_config, \n",
    "    use_tqdm=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Summary:\n",
      "\n",
      "Information 1, published on 2020-12-01, discusses a false claim about a Covid-19 vaccine having the ability to \"transfer genetic material\" and manipulate human genes. The claim was shared hundreds of times on Facebook, but experts, such as Dr. Kirsty Short, have confirmed that the mRNA vaccine cannot enter the human genome. Information 2, published on 2020-05-19, mentions false claims about a future Covid-19 vaccine genetically modifying humans. Information 3, with no specific publication date, states that Covid-19 vaccines do not change a person's genes and use messenger RNA or modified adenovirus to trigger an immune response. Information 4, published on 2023-11-01, reiterates that Covid-19 vaccines cannot alter a person's genome and debunks false claims about DNA contamination leading to harmful effects. Information 5, with no specific publication date, highlights the importance of monitoring and addressing vaccine misinformation to prevent vaccine hesitancy.\n",
      "\n",
      "Restated Claim:\n",
      "On 2020-12-01, experts refuted the false claim that a Covid-19 vaccine can manipulate human genes.\n",
      "\n",
      "Given the information available, the claim is TRUE. The Covid-19 vaccines developed by Pfizer-BioNTech, Moderna, and Johnson & Johnson do not have the ability to manipulate human genes, as confirmed by various experts and sources. These vaccines either use messenger RNA or modified adenovirus to trigger an immune response, but they cannot alter human DNA.\n"
     ]
    }
   ],
   "source": [
    "s = \"Information Summary:\\n\\nInformation 1, published on 2020-12-01, discusses a false claim about a Covid-19 vaccine having the ability to \\\"transfer genetic material\\\" and manipulate human genes. The claim was shared hundreds of times on Facebook, but experts, such as Dr. Kirsty Short, have confirmed that the mRNA vaccine cannot enter the human genome. Information 2, published on 2020-05-19, mentions false claims about a future Covid-19 vaccine genetically modifying humans. Information 3, with no specific publication date, states that Covid-19 vaccines do not change a person's genes and use messenger RNA or modified adenovirus to trigger an immune response. Information 4, published on 2023-11-01, reiterates that Covid-19 vaccines cannot alter a person's genome and debunks false claims about DNA contamination leading to harmful effects. Information 5, with no specific publication date, highlights the importance of monitoring and addressing vaccine misinformation to prevent vaccine hesitancy.\\n\\nRestated Claim:\\nOn 2020-12-01, experts refuted the false claim that a Covid-19 vaccine can manipulate human genes.\\n\\nGiven the information available, the claim is TRUE. The Covid-19 vaccines developed by Pfizer-BioNTech, Moderna, and Johnson & Johnson do not have the ability to manipulate human genes, as confirmed by various experts and sources. These vaccines either use messenger RNA or modified adenovirus to trigger an immune response, but they cannot alter human DNA.\"\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\n",
      "\n",
      "INFORMATION:\n",
      "Information 1:\n",
      "Publication date: 2020-12-16\n",
      "Title: Fact check: A 2010 study on vaccines did not show that one in forty ...\n",
      "Content:\n",
      "A video posted on Facebook by an anti-lockdown activist, citing a 2010 vaccination study, claims that one in forty have “vaccine damage.” A doctor who worked on the study said that the claim in the video misinterpreted the study’s findings, which included medical events not related to vaccines.\n",
      "I’m sure that people who have a dead or damaged child as a result of vaccines think that too ... I’m sure they think they are an absolute scientific wonder that they have one less child, or that they now have a child who is now so completely disabled. Yeah, they are a scientific wonder. Of course, them instances are rare. Them instances are rare. No. They’re one in forty.\n",
      "I’m sure they think they are an absolute scientific wonder that they have one less child, or that they now have a child who is now so completely disabled. Yeah, they are a scientific wonder. Of course, them instances are rare. Them instances are rare. No. They’re one in forty. One in forty have vaccine damage according to a 2010 study”.\n",
      "For example, according to WHO reports, about one in every 500,000 live attenuated influenza vaccines given can cause an allergic reaction (here) while no evidence of severe reactions could be attributed to the hepatitis A (here) or HPV vaccines (here). False. The 2010 study did not show that one in forty vaccine recipients suffered “vaccine damage”, That study counted whether there had been medical events detected in the 30 days after a patient received a vaccine, and did not attempt to infer causal links.\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: Global impact of the first year of COVID-19 vaccination: a ...\n",
      "Content:\n",
      "COVID-19 <strong>vaccination</strong> has substantially altered the course of the pandemic, saving tens of millions of lives globally. However, inadequate access to <strong>vaccines</strong> <strong>in</strong> low-income countries has limited the impact in these settings, reinforcing the need for global <strong>vaccine</strong> equity and coverage.\n",
      "Information 3:\n",
      "Publication date: None\n",
      "Title: Historical Safety Concerns | Vaccine Safety | CDC\n",
      "Content:\n",
      "In 2014, CDC published a study on the association between 2009 H1N1 influenza vaccines, 2010/2011 seasonal influenza vaccines, and narcolepsy. The study found that vaccination was not associated with an increased risk for narcolepsy.\n",
      "Porcine circovirus (PCV) is a common virus found in pigs. In 2010, it was discovered that both rotavirus vaccines licensed in the U.S.- Rotarix and RotaTeq- contained PCV type 1. PCV1 is not known to cause disease in animals or humans. In fact, PCV is common in healthy pigs, and humans are routinely exposed to the virus by eating pork.\n",
      "H1N1 Influenza Vaccine and Narcolepsy - 2009 – 2010 · An increased risk of narcolepsy (a chronic sleep disorder) was found following vaccination with Pandemrix, a monovalent 2009 H1N1 influenza vaccine that was used in several European countries during the H1N1 influenza pandemic.\n",
      "Hmeljak J, Kern I, Cör A. No implication of Simian virus 40 in pathogenesis of malignant pleural mesothelioma in Slovenia. Tumori. 2010 Sep-Oct;96(5):667-73.https://www.ncbi.nlm.nih.gov/pubmed/21302609external icon\n",
      "Information 4:\n",
      "Publication date: 2020-02-11\n",
      "Title: Selected Adverse Events Reported after COVID-19 Vaccination | CDC\n",
      "Content:\n",
      "Rare instances of adverse events following COVID-19 vaccinations have been reported to the Vaccine Adverse Event Reporting System.\n",
      "Information 5:\n",
      "Publication date: None\n",
      "Title: The contribution of vaccination to global health: past, present ...\n",
      "Content:\n",
      "2. Allen A. 2007. Vaccine—the controversial story of medicine's greatest lifesaver. New York, NY: W.W. Norton & Co. [Google Scholar] 3. Weber TP. 2010. Alfred Russel Wallace and the antivaccination movement in Victorian England. Emerg. Infect. Dis. 16, 664–668.\n",
      "3. Weber TP. 2010. Alfred Russel Wallace and the antivaccination movement in Victorian England. Emerg. Infect. Dis. 16, 664–668. ( 10.3201/eid1604.090434) [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n",
      "11. Lu YJ, et al. 2010. GMP-grade pneumococcal whole-cell vaccine injected subcutaneously protects mice from nasphayngeal colonization and fatal aspiration-sepsis. Vaccine 28, 7468–7475. ( 10.1016/j.vaccine.2010.09.031) [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n",
      "\n",
      "CLAIM: \n",
      "Publication date: 2020-12-16\n",
      "Content: A 2010 study on vaccines did not show that one in forty were damaged by vaccination\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Summary:\n",
      "\n",
      "Information 1 discusses a Facebook video claiming that a 2010 study showed that one in forty people suffered \"vaccine damage.\" The claim is false, as the study did not attempt to infer causal links between vaccines and medical events. Information 2 highlights the global impact of COVID-19 vaccination, saving tens of millions of lives while emphasizing the need for global vaccine equity. Information 3 provides background on historical safety concerns related to vaccines, including a 2014 study on the association between 2009 H1N1 influenza vaccines and narcolepsy. Information 4 mentions rare instances of adverse events following COVID-19 vaccinations reported to the Vaccine Adverse Event Reporting System. Information 5 focuses on the contribution of vaccination to global health.\n",
      "\n",
      "Claim Restatement:\n",
      "A 2010 study on vaccines did not find evidence that one in forty people were damaged by vaccination.\n",
      "\n",
      "Judgment on Claim:\n",
      "\n",
      "The claim is TRUE based on Information 1, which states that a doctor involved in the 2010 study clarified that the study did not show a causal link between vaccines and medical events, and that the claim of one in forty people being damaged by vaccines is a misinterpretation of the study's findings. Additionally, Information 3 provides context on historical safety concerns related to vaccines, further supporting the claim's accuracy.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Information Summary:\\n\\nInformation 1 discusses a Facebook video claiming that a 2010 study showed that one in forty people suffered \"vaccine damage.\" The claim is false, as the study did not attempt to infer causal links between vaccines and medical events. Information 2 highlights the global impact of COVID-19 vaccination, saving tens of millions of lives while emphasizing the need for global vaccine equity. Information 3 provides background on historical safety concerns related to vaccines, including a 2014 study on the association between 2009 H1N1 influenza vaccines and narcolepsy. Information 4 mentions rare instances of adverse events following COVID-19 vaccinations reported to the Vaccine Adverse Event Reporting System. Information 5 focuses on the contribution of vaccination to global health.\\n\\nClaim Restatement:\\nA 2010 study on vaccines did not find evidence that one in forty people were damaged by vaccination.\\n\\nJudgment on Claim:\\n\\nThe claim is TRUE based on Information 1, which states that a doctor involved in the 2010 study clarified that the study did not show a causal link between vaccines and medical events, and that the claim of one in forty people being damaged by vaccines is a misinterpretation of the study\\'s findings. Additionally, Information 3 provides context on historical safety concerns related to vaccines, further supporting the claim\\'s accuracy.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prompt_for_generating_prior_knowledge(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    sort: 对search result 按时间进行排序\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # v1\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        # v2\n",
    "        # pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        \n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = \"CLAIM: \" + prompt_rag.get_claim_with_date(claim, claim_date)\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + info + text\n",
    "\n",
    "def get_claim_with_date(claim, claim_date=None):\n",
    "    if claim_date is None:\n",
    "        return \" \" + claim\n",
    "    \n",
    "    # res = \"\\n\"\n",
    "    res = claim + \"\\nPublication date: \" + claim_date\n",
    "    return res\n",
    "\n",
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_search)):\n",
    "        if claim.strip() in data_search[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "# i = 0\n",
    "i = get_id(\"A 2010 study on vaccines did not show that one in forty were damaged by vaccination\")\n",
    "\n",
    "claim = data_search[i][\"claim\"]\n",
    "search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "\n",
    "model_name = 'mixtral'\n",
    "prompt_list1 = [\n",
    "    get_prompt_for_generating_prior_knowledge(\n",
    "        claim, data_search[i][\"date\"], search_engine, search_results, model_name,\n",
    "        K=K, sort=False, \n",
    "        # ids=data_search[i][\"random_ids\"],\n",
    "        ids=None\n",
    "    ),\n",
    "]\n",
    "\n",
    "request_list1 = [{'query': prompt} for prompt in prompt_list1]\n",
    "\n",
    "print(prompt_list1[0])\n",
    "print()\n",
    "\n",
    "resp_list1 = get_resp_list(request_list1)\n",
    "print(resp_list1[0][\"response\"].strip())\n",
    "print()\n",
    "resp_list1[0][\"response\"].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:42<00:00,  5.40s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_prompt_for_generating_prior_knowledge2(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    sort: 对search result 按时间进行排序\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = \"CLAIM:\" + get_claim_with_date(claim, claim_date)\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + info + text\n",
    "\n",
    "def get_prompt_for_generating_prior_knowledge1(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    sort: 对search result 按时间进行排序\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = \"CLAIM: \" + get_claim_with_date(claim, claim_date) + '\\n\\n'\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + text + info\n",
    "    \n",
    "def get_claim_with_date(claim, claim_date=None):\n",
    "    if claim_date is None:\n",
    "        return \" \" + claim\n",
    "    \n",
    "    # res = \"\\n\"\n",
    "    res = claim + \"\\nPublication date: \" + claim_date\n",
    "    return res\n",
    "\n",
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_search)):\n",
    "        if claim.strip() in data_search[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "# i = 0\n",
    "\n",
    "i = get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\")\n",
    "ids = [\n",
    "    get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\"),\n",
    "    get_id(\"Myth spreads online that Australian supermarkets have banned Chinese nationals during COVID-19 pandemic\"),\n",
    "    get_id(\"Trump makes false claims about COVID-19 testing\"),\n",
    "    get_id(\"UNHCR condemns fake notice which claimed refugees in Malaysia are resisting COVID-19 tests\"),\n",
    "    get_id(\"Hospitals in Ohio were not set on fire during protests\"),\n",
    "    get_id(\"A 2010 study on vaccines did not show that one in forty were damaged by vaccination\"),\n",
    "    get_id(\"The Philippine health department said it did not issue this 'checklist' for COVID-19 symptoms\"),\n",
    "    get_id(\"Contaminated CDC COVID-19 test kits recalled and did not spread virus\"),\n",
    "    get_id(\"Experts refute false claim that Covid-19 vaccine can 'manipulate' human genes\"),\n",
    "    get_id(\"Countries were not buying Covid-19 test kits in 2018\"),\n",
    "    get_id(\"False claim circulates that Pakistani plane transported Sri Lankan students home after COVID-19 lockdown\"),\n",
    "    get_id(\"People will not have to be vaccinated against COVID-19 to receive food stamps and rent assistance\"),\n",
    "    get_id(\"Britain has not awarded a contract to develop a vaccine passport\"),\n",
    "    get_id(\"World Health Organization says COVID-19 means ‘coronavirus disease 2019’ – not 'China outbreak virus'\"),\n",
    "    get_id(\"The common cold is not the same as COVID-19 and the NHS is not saying it is\"),\n",
    "    get_id(\"Philippine authorities did not issue this warning after the novel coronavirus outbreak\"),\n",
    "    get_id(\"No tourists have been allowed to visit New Zealand since March 2020 -- this photo has circulated online since 2016\"),\n",
    "    get_id(\"This video does not show social distancing failure on an Air India flight during the coronavirus pandemic\"),\n",
    "    get_id(\"This photo shows a Sri Lankan airline pilot who tested positive for the novel coronavirus.\"), # fALSE\n",
    "]\n",
    "\n",
    "prompt_list = []\n",
    "model_name = 'mixtral'\n",
    "for i in ids:\n",
    "    claim = data_search[i][\"claim\"]\n",
    "    search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "    prompt_list.append(get_prompt_for_generating_prior_knowledge(\n",
    "            claim, data_search[i][\"date\"], search_engine, search_results, model_name,\n",
    "            K=K, sort=False, \n",
    "            # ids=data_search[i][\"random_ids\"],\n",
    "            ids=None\n",
    "        ))\n",
    "request_list = [{'query': prompt} for prompt in prompt_list]\n",
    "\n",
    "resp_list = get_resp_list(request_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "**************************************************\n",
      "Information Summary:\n",
      "\n",
      "Information 1 provides context about the financial struggles of SriLankan Airlines and the confirmation of a pilot testing positive for COVID-19. Information 2 offers travel advice from the UK government regarding COVID-19 in Sri Lanka, including isolation guidelines and sources for official information. Information 3 is a dashboard showing Sri Lanka's coronavirus statistics. Information 4 refutes a false claim that Sri Lanka has eradicated the coronavirus, stating that the first case was confirmed in January and one patient had recovered but remained under care. Information 5 discusses the impact of the COVID-19 pandemic on Sri Lankan migrant workers.\n",
      "\n",
      "Claim:\n",
      "This photo shows a Sri Lankan airline pilot who tested positive for the novel coronavirus.\n",
      "\n",
      "To judge the correctness of the claim, we need to consider the following evidence:\n",
      "\n",
      "1. SriLankan Airlines confirmed that one of their pilots tested positive for COVID-19 (Information 1).\n",
      "2. The information does not provide a direct link between the claim and the specific pilot mentioned in Information 1.\n",
      "\n",
      "Based on the available information, it is unclear if the person in the photo is the same pilot mentioned in Information 1. Therefore, it is not possible to definitively classify the claim as true or false.\n"
     ]
    }
   ],
   "source": [
    "# info + CLAIM wrong: 2, 1\n",
    "\n",
    "print(len(ids))\n",
    "\n",
    "\n",
    "nn = 18\n",
    "# print(prompt_list[nn])\n",
    "print('*'*50)\n",
    "print(resp_list[nn][\"response\"].strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
