{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import sys\n",
    "\n",
    "# dirs = [\"..\", \"/home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm/my_inferencing/create_prompt_llm\"]\n",
    "# for _dir in dirs:\n",
    "#     if _dir not in sys.path:\n",
    "#         sys.path.append(_dir)\n",
    "import prompt_rag\n",
    "\n",
    "search_engine = \"brave\"\n",
    "\n",
    "with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search.json\", \"r\") as f:\n",
    "    data_search = json.load(f)\n",
    "\n",
    "try:\n",
    "    with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"r\") as f:\n",
    "        data_search_llm = json.load(f)\n",
    "except:\n",
    "    data_search_llm = [{\n",
    "        \"claim\": i[\"claim\"],\n",
    "        \"claimant\": i[\"claimant\"],\n",
    "        \"label\": i[\"label\"],\n",
    "        \"date\": i[\"date\"],\n",
    "    } for i in data_search]\n",
    "    with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"w\") as f:\n",
    "        json.dump(data_search_llm, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.update_train_search_llm( \n",
    "#     \"SOLAR-10.7B-Instruct-v1.0\", \"solar\", port=8001, \n",
    "#     data_search=data_search, data_search_llm=data_search_llm) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并多个文件的先验知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对prior_knowledge做修改\n",
    "# sort = False\n",
    "# prior_knowledge_list = []\n",
    "\n",
    "# K = 5\n",
    "# prior_knowledge_version = \"1\"\n",
    "# prior_knowledge_version_adjust = prior_knowledge_version + \".2\"\n",
    "# model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     prior_knowledge = item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"]\n",
    "    \n",
    "#     find_list = [\n",
    "#         \"Information Expansion and Summary:\",\n",
    "#         # \"Information Summary:\",\n",
    "#         # \"Expanded Information Summary:\",\n",
    "#         \"Claim Analysis:\",\n",
    "#         # \"Claim Verification\",\n",
    "#         # \"Claim Analysis and Judgement:\"\n",
    "#     ]\n",
    "\n",
    "#     for s in find_list:\n",
    "#         pos = prior_knowledge.find(s)\n",
    "#         if pos == -1:\n",
    "#             continue\n",
    "        \n",
    "#         num_extra = 2\n",
    "#         if pos!=0 and prior_knowledge[pos-1] == '\\n':\n",
    "#             pos -= 1\n",
    "#             num_extra += 1\n",
    "#         prior_knowledge = prior_knowledge[:pos] + prior_knowledge[pos + len(s) + num_extra :]\n",
    "\n",
    "  \n",
    "#     item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version_adjust}_K={K}\"] = prior_knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing search llm\n",
    "# v2: k = 5\n",
    "# v3: 不对时间排序\n",
    "\n",
    "# brave search llm\n",
    "\n",
    "# Solar\n",
    "# v1: k = 5\n",
    "# v2: k = 5 随机选取\n",
    "\n",
    "# Mixtral\n",
    "# v1: k = 5\n",
    "# v1.1: 删除结构化内容（Information Expansion and Summary、Claim Analysis）\n",
    "\n",
    "sort = False\n",
    "prior_knowledge_list = []\n",
    "\n",
    "K = 5\n",
    "prior_knowledge_version = \"1\"\n",
    "model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# with open(f\"train_search_llm_tmp.json\", \"r\") as f:\n",
    "#     prior_knowledge_list = json.load(f)\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     if item[\"claim\"] != prior_knowledge_list[i][\"claim\"].strip():\n",
    "#         print(i)\n",
    "#         print(item[\"claim\"])\n",
    "#         print(prior_knowledge_list[i][\"claim\"])\n",
    "#         raise Exception()\n",
    "#     else:\n",
    "#         item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"] = prior_knowledge_list[i][f\"prior_knowledge_{model_name}\"]\n",
    "\n",
    "# data_search_llm[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.save_search_llm(data_search_llm, search_engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建数据（带有先验知识的Prompt）以微调LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the CLAIM and the PRIOR KNOWLEDGE, please classify the CLAIM as TRUE or FALSE. If the content described by the CLAIM is correct, then classify it as TRUE; if the content described by the CLAIM is incorrect, then classify it as FALSE.\n",
      "\n",
      "CLAIM:\n",
      "Publication date: 2020-08-13\n",
      "Content: Illinois Strengthens Face Mask Rules in Businesses\n",
      "\n",
      "PRIOR KNOWLEDGE:\n",
      "Information 1:\n",
      "Publication date: 2013-08-06\n",
      "Title: Illinois Strengthens Face Mask Rules in Businesses - WebMD\n",
      "Content:\n",
      "COVID-19 is a new type of coronavirus that causes mild to severe cases. Here’s a quick guide on how to spot symptoms, risk factors, prevent spread of the disease, and find out what to do if you think you have it.\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: press-release\n",
      "Content:\n",
      "Illinoisans can resume activities without wearing a mask indoors on February 28th except where required by federal, state, local, tribal, or territorial laws, rules, and regulations, including local business and workplace guidance. Federal requirements, in effect through at least March 18, include all transportation systems such as airports, planes, trains, and buses. \"Preparing to repeal statewide masking mandates at the end of the month is aggressive and optimistic but reasonable,\" said Dr.\n",
      "\"Broad mandates are not about individuals. They are put in place to help protect communities, businesses, and healthcare access. Repealing the mask mandate allows people to choose the mitigation layers that are best for them and I have no doubt that many should and will choose to keep mask rules.\"\n",
      "If these trends continue — and we expect them to —then on Monday, February 28th, we will lift the indoor mask requirement for the State of Illinois,\" said Governor JB Pritzker. \"I want to be clear: Many local jurisdictions, businesses and organizations have their own mask requirements and other mitigations that must be respected.\n",
      "Seth Trueger, a Northwestern emergency physician who is also immunocompromised. \"Masking has helped slow the spread even in the face of omicron's transmissibility. We can and must use this time to further increase vaccination uptake & outreach, especially among children and other populations with low vaccination rates, so when the next wave comes, we will be even better prepared.\"\n",
      "Information 3:\n",
      "Publication date: None\n",
      "Title: Mask and Vaccine Requirements FAQ's\n",
      "Content:\n",
      "On September 3, 2021, the Governor signed Executive Order 21-22 which requires all individuals over the age of 2 and who can medically tolerate a face covering to wear a face covering when in indoor public places. The Executive Order also requires health care workers, school personnel, higher education personnel and students, and employees and contractors of state-owned or operated congregate facilities to be fully vaccinated, as described in the Order\n",
      "Information 4:\n",
      "Publication date: None\n",
      "Title: FAQ for Businesses Concerning Use of Face-Coverings During COVID-19\n",
      "Content:\n",
      "A: Businesses reserve the right to refuse service to persons unable to comply with the requirement to wear a face covering, but they are required to provide a reasonable accommodation if it does not cause an undue hardship. Businesses are encouraged to inform customers there are exceptions to the requirement that all individuals must wear a mask.\n",
      "These frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. A: A face covering is a mask or cloth face covering that covers your nose and mouth.\n",
      "Exceptions may be made for individuals with medical conditions or disabilities that prevent them from safely wearing a face covering. For more information, refer to the questions on reasonable accommodations. A: Masks still must be worn by everyone on planes, buses, trains, and other forms of public transportation; in transportation hubs, such as airports and train and bus stations; in health care settings; and in congregate facilities, such as correctional facilities and homeless shelters.\n",
      "These frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. When Face Coverings are Required Q: What does it mean to wear a face covering?\n",
      "Information 5:\n",
      "Publication date: 2020-04-22\n",
      "Title: Facing Your Face Mask Duties – A List of Statewide Orders | Littler ...\n",
      "Content:\n",
      "********************************************************NOTE: Given the reduction in activity on this topic,THIS POST WILL NO LONGER BE UPDATED, as of November 10, 2022.********************************************************Governors and public health officials across the country implemented stringent mitigation measures to help contain the spread of COVID-19.\n",
      "\n",
      "Information Expansion and Summary:\n",
      "\n",
      "Information 1, published on August 6, 2013, is not related to the claim, as it discusses COVID-19 symptoms, risk factors, and prevention measures but does not mention any changes to face mask rules in Illinois businesses.\n",
      "\n",
      "Information 2, the press release, was published on an unspecified date. It announces that Illinois will lift the indoor mask requirement for the State of Illinois on February 28, 2022, except where required by federal, state, local, tribal, or territorial laws, rules, and regulations. Businesses and organizations can still have their own mask requirements. The decision is based on decreasing COVID-19 cases and increasing vaccination rates.\n",
      "\n",
      "Information 3, the FAQs on Mask and Vaccine Requirements, was published on September 3, 2021. It states that Executive Order 21-22 requires all individuals over the age of 2 to wear a face covering in indoor public places and imposes vaccine requirements for certain groups.\n",
      "\n",
      "Information 4, the FAQ for Businesses Concerning Use of Face-Coverings During COVID-19, provides guidance on the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation. It specifies that masks must still be worn on public transportation, in transportation hubs, health care settings, and congregate facilities.\n",
      "\n",
      "Information 5, the post on Facing Your Face Mask Duties, was last updated on November 10, 2022. It provides a list of statewide orders related to face mask duties but does not contain information about strengthening face mask rules in Illinois businesses.\n",
      "\n",
      "Claim Verification:\n",
      "\n",
      "The claim, stating that Illinois strengthens face mask rules in businesses, is false based on the provided information. According to the press release (Information 2), Illinois actually lifted the indoor mask requirement on February 28, 2022, except where required by various laws, rules, and regulations. Businesses and organizations can still have their own mask requirements. The other pieces of information do not contradict this statement.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12192,\n",
       " [{'query': 'According to the CLAIM and the PRIOR KNOWLEDGE, please classify the CLAIM as TRUE or FALSE. If the content described by the CLAIM is correct, then classify it as TRUE; if the content described by the CLAIM is incorrect, then classify it as FALSE.\\n\\nCLAIM:\\nPublication date: 2020-08-13\\nContent: Illinois Strengthens Face Mask Rules in Businesses\\n\\nPRIOR KNOWLEDGE:\\nInformation 1:\\nPublication date: 2013-08-06\\nTitle: Illinois Strengthens Face Mask Rules in Businesses - WebMD\\nContent:\\nCOVID-19 is a new type of coronavirus that causes mild to severe cases. Here’s a quick guide on how to spot symptoms, risk factors, prevent spread of the disease, and find out what to do if you think you have it.\\nInformation 2:\\nPublication date: None\\nTitle: press-release\\nContent:\\nIllinoisans can resume activities without wearing a mask indoors on February 28th except where required by federal, state, local, tribal, or territorial laws, rules, and regulations, including local business and workplace guidance. Federal requirements, in effect through at least March 18, include all transportation systems such as airports, planes, trains, and buses. \"Preparing to repeal statewide masking mandates at the end of the month is aggressive and optimistic but reasonable,\" said Dr.\\n\"Broad mandates are not about individuals. They are put in place to help protect communities, businesses, and healthcare access. Repealing the mask mandate allows people to choose the mitigation layers that are best for them and I have no doubt that many should and will choose to keep mask rules.\"\\nIf these trends continue — and we expect them to —then on Monday, February 28th, we will lift the indoor mask requirement for the State of Illinois,\" said Governor JB Pritzker. \"I want to be clear: Many local jurisdictions, businesses and organizations have their own mask requirements and other mitigations that must be respected.\\nSeth Trueger, a Northwestern emergency physician who is also immunocompromised. \"Masking has helped slow the spread even in the face of omicron\\'s transmissibility. We can and must use this time to further increase vaccination uptake & outreach, especially among children and other populations with low vaccination rates, so when the next wave comes, we will be even better prepared.\"\\nInformation 3:\\nPublication date: None\\nTitle: Mask and Vaccine Requirements FAQ\\'s\\nContent:\\nOn September 3, 2021, the Governor signed Executive Order 21-22 which requires all individuals over the age of 2 and who can medically tolerate a face covering to wear a face covering when in indoor public places. The Executive Order also requires health care workers, school personnel, higher education personnel and students, and employees and contractors of state-owned or operated congregate facilities to be fully vaccinated, as described in the Order\\nInformation 4:\\nPublication date: None\\nTitle: FAQ for Businesses Concerning Use of Face-Coverings During COVID-19\\nContent:\\nA: Businesses reserve the right to refuse service to persons unable to comply with the requirement to wear a face covering, but they are required to provide a reasonable accommodation if it does not cause an undue hardship. Businesses are encouraged to inform customers there are exceptions to the requirement that all individuals must wear a mask.\\nThese frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. A: A face covering is a mask or cloth face covering that covers your nose and mouth.\\nExceptions may be made for individuals with medical conditions or disabilities that prevent them from safely wearing a face covering. For more information, refer to the questions on reasonable accommodations. A: Masks still must be worn by everyone on planes, buses, trains, and other forms of public transportation; in transportation hubs, such as airports and train and bus stations; in health care settings; and in congregate facilities, such as correctional facilities and homeless shelters.\\nThese frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. When Face Coverings are Required Q: What does it mean to wear a face covering?\\nInformation 5:\\nPublication date: 2020-04-22\\nTitle: Facing Your Face Mask Duties – A List of Statewide Orders | Littler ...\\nContent:\\n********************************************************NOTE: Given the reduction in activity on this topic,THIS POST WILL NO LONGER BE UPDATED, as of November 10, 2022.********************************************************Governors and public health officials across the country implemented stringent mitigation measures to help contain the spread of COVID-19.\\n\\nInformation Expansion and Summary:\\n\\nInformation 1, published on August 6, 2013, is not related to the claim, as it discusses COVID-19 symptoms, risk factors, and prevention measures but does not mention any changes to face mask rules in Illinois businesses.\\n\\nInformation 2, the press release, was published on an unspecified date. It announces that Illinois will lift the indoor mask requirement for the State of Illinois on February 28, 2022, except where required by federal, state, local, tribal, or territorial laws, rules, and regulations. Businesses and organizations can still have their own mask requirements. The decision is based on decreasing COVID-19 cases and increasing vaccination rates.\\n\\nInformation 3, the FAQs on Mask and Vaccine Requirements, was published on September 3, 2021. It states that Executive Order 21-22 requires all individuals over the age of 2 to wear a face covering in indoor public places and imposes vaccine requirements for certain groups.\\n\\nInformation 4, the FAQ for Businesses Concerning Use of Face-Coverings During COVID-19, provides guidance on the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation. It specifies that masks must still be worn on public transportation, in transportation hubs, health care settings, and congregate facilities.\\n\\nInformation 5, the post on Facing Your Face Mask Duties, was last updated on November 10, 2022. It provides a list of statewide orders related to face mask duties but does not contain information about strengthening face mask rules in Illinois businesses.\\n\\nClaim Verification:\\n\\nThe claim, stating that Illinois strengthens face mask rules in businesses, is false based on the provided information. According to the press release (Information 2), Illinois actually lifted the indoor mask requirement on February 28, 2022, except where required by various laws, rules, and regulations. Businesses and organizations can still have their own mask requirements. The other pieces of information do not contradict this statement.',\n",
       "   'response': 'TRUE.'},\n",
       "  {'query': \"According to the CLAIM and the PRIOR KNOWLEDGE, please classify the CLAIM as TRUE or FALSE. If the content described by the CLAIM is correct, then classify it as TRUE; if the content described by the CLAIM is incorrect, then classify it as FALSE.\\n\\nCLAIM:\\nPublication date: 2020-04-03\\nContent: The government of Paraíba, a state in Brazil, received 11.6 million Brazilian reais from the federal government to spend on healthcare during the COVID-19 crisis. Instead, this money is being spent on artistic performances.\\n\\nPRIOR KNOWLEDGE:\\nInformation 1:\\nPublication date: None\\nTitle: Brazil Overview: Development news, research, data | World Bank\\nContent:\\n<strong>Brazil</strong> <strong>is</strong> projected to fall into its deepest recession on record. However, macroeconomic framework is expected to remain broadly adequate, albeit with substantial downside risks, calling for strong fiscal consolidation and adoption of structural reforms.\\nInformation 2:\\nPublication date: 2023-12-30\\nTitle: Brazilian real - Wikipedia\\nContent:\\nLula started his government in 01/01/2003 with an exchange rate of US$1=R$3.52 and finished it in 12/31/2010 with an exchange rate of US$1=R$1.66. The exchange rate as of September 2015 was US$1=R$4.05. After a period of gradual recovery, it reached US$1=R$3 by February 2017. Jair Bolsonaro's tenure, initially welcomed with enthusiasm by the financial markets, started with US$1=R$3.86. Fueled by meager results of the economy, quick disenchantment followed, resulting in lack of foreign investments and real's strong depreciation. On 13 May 2020, during the COVID-19 pandemic, which deeply affected Brazil, the real reached a historical low against the US dollar, being negotiated at US$1=R$5.90.\\nIn the following years, the currency's value against the dollar followed an erratic but mostly downwards path from 1999 until late 2002, when the prospect of the election of leftist candidate Luiz Inácio Lula da Silva, considered a radical populist by sectors of the financial markets, prompted another currency crisis and a spike in inflation. Many Brazilians feared another default on government debts or a resumption of heterodox economic policies, and rushed to exchange their reais into tangible assets or foreign currencies.\\nThe Central Bank of Brazil is the central bank and the issuing authority. The real replaced the cruzeiro real in 1994. As of April 2019, the real was the twentieth most traded currency. Currencies in use before the current real include: The Portuguese real from the 16th to 18th centuries, with 1,000 réis called the milréis. The old Brazilian real from 1747 to 1942, with 1,000 réis also called the milréis.\\nInformation 3:\\nPublication date: 2023-08-23\\nTitle: Brazil - United States Department of State\\nContent:\\nU.S. foreign direct investment in Brazil totaled $191.6 billion in 2021, by far the most of any country. The United States and Brazil conduct regular government-to-government exchanges on topics including trade facilitation, good regulatory practices, and environmental and labor standards.\\nSince June, 2021 the United States has donated 5,187,300 safe and effective COVID-19 vaccine doses with the people of Brazil. This includes 3,000,000 J&J and 2,187,300 AstraZeneca doses. Of the 5,187,300 vaccine doses, 100% were donated through bilateral agreements. The United States is committed to leading an international and coordinated effort to accelerate access to safe and effective COVID-19 vaccines to meet global needs.\\nThe United States is committed to leading an international and coordinated effort to accelerate access to safe and effective COVID-19 vaccines to meet global needs. The United States is working with other governments and partners including COVAX, Caricom, and the African Vaccine Acquisition Trust (AVAT) to protect communities from COVID-19 and apply lessons from this pandemic to enhance health security now and in the future.\\nThe United States is working with other governments and partners including COVAX, Caricom, and the African Vaccine Acquisition Trust (AVAT) to protect communities from COVID-19 and apply lessons from this pandemic to enhance health security now and in the future. Learn more about our work Delivering Vaccines and on COVID-19 Recovery.\\nInformation 4:\\nPublication date: None\\nTitle: 1 BRL to USD - Brazilian Reais to US Dollars Exchange Rate\\nContent:\\nGet the latest 1 <strong>Brazilian</strong> Real to US Dollar rate for FREE with the original Universal Currency Converter. Set rate alerts for BRL to USD and learn more about <strong>Brazilian</strong> <strong>Reais</strong> and US Dollars from XE - the Currency Authority.\\nInformation 5:\\nPublication date: None\\nTitle: Brazil’s Open Budget Transparency Portal\\nContent:\\nRead More ... As with many of the countries included in this series, Brazil has long suffered from corruption. The country is ranked 69 among 175 countries in Transparency International’s 2014 Corruption Perceptions Index, which also reports that the country’s legal system is “plagued with inefficiencies and corrupt judges.”1 Brazilian elections are also believed to be infiltrated by corruption and, despite public outrage, politicians with prior convictions are often voted back to office.\\nThe country is ranked 69 among 175 countries in Transparency International’s 2014 Corruption Perceptions Index, which also reports that the country’s legal system is “plagued with inefficiencies and corrupt judges.”1 Brazilian elections are also believed to be infiltrated by corruption and, despite public outrage, politicians with prior convictions are often voted back to office. In Rio de Janeiro, for example, Brazil’s third-largest state with a population of 11.9 million as of 20122, “only one single politician in the Brazilian state of Rio de Janeiro is said to have never fallen foul of the law,” according to one news report.3\\nIn Rio de Janeiro, for example, Brazil’s third-largest state with a population of 11.9 million as of 20122, “only one single politician in the Brazilian state of Rio de Janeiro is said to have never fallen foul of the law,” according to one news report.3 · Additionally, a 2009 World Bank and IFC1 Enterprise Survey found that 70 percent of global and domestic companies viewed corruption as a “major constraint to doing business” in Brazil, while a Federation of the Industries of the state of São Paulo investigation found that corruption cost Brazil almost $40 billion (about 2.3 percent of GDP) in 2008 alone.4\\n6Savarese, Mauricio. “No End in Sight for Brazil’s Petrobras Scandal.” Americas Society / Council of the Americans. August 5, 2015. http://www.as-coa.org/articles/no-end-sight-brazil’s-petrobras-scandal. ... 8Brazil: New Access to Information Law becomes effective today.” Article 19. May 16, 2012. https://www.article19.org/resources.php/resource/3208/en/brazil:-new-access-to-information-law-becomes-effective-today. 9New Brazilian Data Portal Dados.Gov.Br – Powered by CKAN.” Open Knowledge Blog.\\n\\nThe claim states that the government of Paraíba, a state in Brazil, received 11.6 million Brazilian reais from the federal government to spend on healthcare during the COVID-19 crisis, but instead, this money is being spent on artistic performances.\\n\\nTo evaluate the accuracy of this claim, let's first expand on the given information:\\n\\nInformation 1: Brazil is projected to fall into its deepest recession on record, and the macroeconomic framework is expected to remain adequate with downside risks, calling for strong fiscal consolidation and adoption of structural reforms.\\n\\nInformation 2: The Brazilian real has experienced significant fluctuations since 1999, with a historical low against the US dollar during the COVID-19 pandemic in May 2020. Brazil has a history of corruption, inefficiencies, and corrupt judges in its legal system.\\n\\nInformation 3: The United States has donated over 5 million COVID-19 vaccine doses to Brazil and is committed to leading an international and coordinated effort to accelerate access to safe and effective vaccines to meet global needs.\\n\\nInformation 4: The Brazilian real to US dollar exchange rate can be obtained from XE - the Currency Authority.\\n\\nInformation 5: Brazil has issues with corruption, inefficiencies, and corrupt judges in its legal system. Corruption is a significant concern for both global and domestic companies in Brazil.\\n\\nBased on the provided information, there is no direct evidence supporting the claim that the government of Paraíba is misusing COVID-19 healthcare funds for artistic performances. However, the information does highlight Brazil's history of corruption and inefficiencies in its legal system.\\n\\nGiven the lack of evidence and Brazil's history of corruption, it is not possible to definitively classify the claim as true or false. However, the claim should be treated with skepticism, and further investigation would be required to confirm its accuracy. It is essential to rely on credible sources when evaluating claims related to government funds and their allocation.\",\n",
       "   'response': 'FALSE.'}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict_list = []\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "    \n",
    "#     if int(item[\"label\"]) != 1:\n",
    "#         prompt = prompt_rag.get_prompt_with_prior_knowledge(\n",
    "#             item[\"claim\"], \n",
    "#             search_engine,\n",
    "#             data_search[i][f\"{search_engine}_search_results\"], \n",
    "#             item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"], \n",
    "#             K=K,\n",
    "#             claim_date=item[\"date\"],\n",
    "#             sort=sort,\n",
    "#             ids=None \n",
    "#         )\n",
    "#         label = \"TRUE.\" if int(item[\"label\"]) == 2 else \"FALSE.\"\n",
    "#         dict_list.append({\"query\": prompt, \"response\": label})\n",
    "# print(dict_list[0][\"query\"])\n",
    "# len(dict_list), dict_list[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_dir = \"/home/hanlv/workspace/code/research/infodemic/LLM/\"\n",
    "# data_version = \"1\"\n",
    "# with jsonlines.open(\n",
    "#     LLM_dir + \\\n",
    "#     f\"swift/examples/pytorch/llm/my_data/with_{model_name}_info/{search_engine}/data{data_version}.jsonl\", mode=\"w\") as file_jsonl:\n",
    "#     for line in dict_list:\n",
    "#         file_jsonl.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型的先验知识生成效果：一次提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 11:10:32,264 - modelscope - INFO - PyTorch version 2.1.2 Found.\n",
      "2024-03-28 11:10:32,267 - modelscope - INFO - Loading ast index from /home/hanlv/.cache/modelscope/ast_indexer\n",
      "2024-03-28 11:10:32,305 - modelscope - INFO - Loading done! Current index file version is 1.13.1, with md5 ad87f4a589251d86333765b92ab59e41 and a total number of 972 components indexed\n",
      "[INFO:swift] Loading the model using model_dir: /home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\n",
      "[INFO:swift] Setting torch_dtype: torch.bfloat16\n",
      "[INFO:swift] model_config: MixtralConfig {\n",
      "  \"_name_or_path\": \"/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\",\n",
      "  \"architectures\": [\n",
      "    \"MixtralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mixtral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts_per_tok\": 2,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_local_experts\": 8,\n",
      "  \"output_router_logits\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"bits\": 4,\n",
      "    \"damp_percent\": 0.1,\n",
      "    \"desc_act\": true,\n",
      "    \"group_size\": 32,\n",
      "    \"model_file_base_name\": \"model\",\n",
      "    \"model_name_or_path\": null,\n",
      "    \"modules_in_block_to_quantize\": [\n",
      "      [\n",
      "        \"self_attn.k_proj\",\n",
      "        \"self_attn.v_proj\",\n",
      "        \"self_attn.q_proj\"\n",
      "      ],\n",
      "      [\n",
      "        \"self_attn.o_proj\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.0.w1\",\n",
      "        \"block_sparse_moe.experts.0.w2\",\n",
      "        \"block_sparse_moe.experts.0.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.1.w1\",\n",
      "        \"block_sparse_moe.experts.1.w2\",\n",
      "        \"block_sparse_moe.experts.1.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.2.w1\",\n",
      "        \"block_sparse_moe.experts.2.w2\",\n",
      "        \"block_sparse_moe.experts.2.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.3.w1\",\n",
      "        \"block_sparse_moe.experts.3.w2\",\n",
      "        \"block_sparse_moe.experts.3.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.4.w1\",\n",
      "        \"block_sparse_moe.experts.4.w2\",\n",
      "        \"block_sparse_moe.experts.4.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.5.w1\",\n",
      "        \"block_sparse_moe.experts.5.w2\",\n",
      "        \"block_sparse_moe.experts.5.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.6.w1\",\n",
      "        \"block_sparse_moe.experts.6.w2\",\n",
      "        \"block_sparse_moe.experts.6.w3\"\n",
      "      ],\n",
      "      [\n",
      "        \"block_sparse_moe.experts.7.w1\",\n",
      "        \"block_sparse_moe.experts.7.w2\",\n",
      "        \"block_sparse_moe.experts.7.w3\"\n",
      "      ]\n",
      "    ],\n",
      "    \"quant_method\": \"gptq\",\n",
      "    \"sym\": true,\n",
      "    \"true_sequential\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"router_aux_loss_coef\": 0.02,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-28 11:10:32 config.py:618] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 03-28 11:10:32 config.py:193] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 03-28 11:10:32 llm_engine.py:87] Initializing an LLM engine with config: model='/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4', tokenizer='/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=42)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 358.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model_type \u001b[38;5;241m=\u001b[39m CustomModelType\u001b[38;5;241m.\u001b[39mmixtral_moe_7b_instruct_gptq_int4\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# model_type = CustomModelType.solar_instruct_10_7b\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m llm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mget_vllm_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 检查正确的数据类型！！！！\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"enforce_eager\": True,\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_num_seqs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m template_type \u001b[38;5;241m=\u001b[39m get_default_template_type(model_type)\n\u001b[1;32m     33\u001b[0m template \u001b[38;5;241m=\u001b[39m get_template(template_type, llm_engine\u001b[38;5;241m.\u001b[39mhf_tokenizer)\n",
      "File \u001b[0;32m~/workspace/code/research/infodemic/LLM/swift/swift/llm/utils/vllm_utils.py:98\u001b[0m, in \u001b[0;36mget_vllm_engine\u001b[0;34m(model_type, torch_dtype, model_id_or_path, gpu_memory_utilization, tensor_parallel_size, max_model_len, engine_kwargs, use_async, enable_lora, max_loras, max_lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# fix HTTPError bug (use model_dir)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVLLM_USE_MODELSCOPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 98\u001b[0m llm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mllm_engine_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m llm_engine\u001b[38;5;241m.\u001b[39mengine_args \u001b[38;5;241m=\u001b[39m engine_args\n\u001b[1;32m    100\u001b[0m llm_engine\u001b[38;5;241m.\u001b[39mmodel_dir \u001b[38;5;241m=\u001b[39m model_dir\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:391\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args)\u001b[0m\n\u001b[1;32m    389\u001b[0m placement_group \u001b[38;5;241m=\u001b[39m initialize_cluster(parallel_config)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m             \u001b[49m\u001b[43mplacement_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m             \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:128\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, lora_config, placement_group, log_stats)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_workers_ray(placement_group)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Profile the memory usage and initialize the cache.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_cache()\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:181\u001b[0m, in \u001b[0;36mLLMEngine._init_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m Worker(\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m     is_driver_worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_workers(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/engine/llm_engine.py:1041\u001b[0m, in \u001b[0;36mLLMEngine._run_workers\u001b[0;34m(self, method, driver_args, driver_kwargs, max_concurrent_workers, use_ray_compiled_dag, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     driver_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# Start the driver worker after all the ray workers.\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m driver_worker_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdriver_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdriver_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;66;03m# Get the results of the ray workers.\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers:\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/worker/worker.py:100\u001b[0m, in \u001b[0;36mWorker.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/worker/model_runner.py:88\u001b[0m, in \u001b[0;36mModelRunner.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_config:\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/utils.py:52\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, device_config, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m imported_model_loader \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvllm.model_executor.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_loader_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m get_model_fn \u001b[38;5;241m=\u001b[39m imported_model_loader\u001b[38;5;241m.\u001b[39mget_model\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_model_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/model_loader.py:79\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, device_config, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support LoRA, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut LoRA is enabled. Support for this model may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe added in the future. If this is important to you, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease open an issue on github.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mload_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# NOTE(woosuk): For accurate performance evaluation, we assign\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# random values to the weights.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     initialize_dummy_weights(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:345\u001b[0m, in \u001b[0;36mMixtralForCausalLM.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_method \u001b[38;5;241m=\u001b[39m linear_method\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mMixtralModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m ParallelLMHead(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;241m=\u001b[39m Sampler(config\u001b[38;5;241m.\u001b[39mvocab_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:311\u001b[0m, in \u001b[0;36mMixtralModel.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m VocabParallelEmbedding(\n\u001b[1;32m    308\u001b[0m     config\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    309\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m    312\u001b[0m     MixtralDecoderLayer(config, linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    314\u001b[0m ])\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:312\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m VocabParallelEmbedding(\n\u001b[1;32m    308\u001b[0m     config\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    309\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    310\u001b[0m )\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m--> 312\u001b[0m     \u001b[43mMixtralDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    314\u001b[0m ])\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:260\u001b[0m, in \u001b[0;36mMixtralDecoderLayer.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    251\u001b[0m rope_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_theta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m MixtralAttention(\n\u001b[1;32m    253\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    254\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_attention_heads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     sliding_window\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39msliding_window,\n\u001b[1;32m    259\u001b[0m     linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_sparse_moe \u001b[38;5;241m=\u001b[39m \u001b[43mMixtralMoE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    263\u001b[0m                                eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    265\u001b[0m                                         eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:120\u001b[0m, in \u001b[0;36mMixtralMoE.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no experts assigned to it.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m    121\u001b[0m     MixtralMLP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts,\n\u001b[1;32m    122\u001b[0m                config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    123\u001b[0m                config\u001b[38;5;241m.\u001b[39mintermediate_size,\n\u001b[1;32m    124\u001b[0m                linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts)\n\u001b[1;32m    127\u001b[0m ])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate \u001b[38;5;241m=\u001b[39m ReplicatedLinear(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    129\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts,\n\u001b[1;32m    130\u001b[0m                              bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    131\u001b[0m                              linear_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:121\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no experts assigned to it.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mMixtralMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_total_experts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m               \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m               \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m               \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_indicies \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts)\n\u001b[1;32m    127\u001b[0m ])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate \u001b[38;5;241m=\u001b[39m ReplicatedLinear(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    129\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_experts,\n\u001b[1;32m    130\u001b[0m                              bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    131\u001b[0m                              linear_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/models/mixtral_quant.py:75\u001b[0m, in \u001b[0;36mMixtralMLP.__init__\u001b[0;34m(self, num_experts, hidden_size, intermediate_size, linear_method)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim \u001b[38;5;241m=\u001b[39m hidden_size\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1 \u001b[38;5;241m=\u001b[39m ReplicatedLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim,\n\u001b[1;32m     72\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_dim,\n\u001b[1;32m     73\u001b[0m                            bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     74\u001b[0m                            linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2 \u001b[38;5;241m=\u001b[39m \u001b[43mReplicatedLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3 \u001b[38;5;241m=\u001b[39m ReplicatedLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim,\n\u001b[1;32m     80\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_dim,\n\u001b[1;32m     81\u001b[0m                            bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m                            linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# TODO: Use vllm's SiluAndMul\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py:115\u001b[0m, in \u001b[0;36mReplicatedLinear.__init__\u001b[0;34m(self, input_size, output_size, bias, skip_bias_add, params_dtype, linear_method)\u001b[0m\n\u001b[1;32m    113\u001b[0m     linear_method \u001b[38;5;241m=\u001b[39m UnquantizedLinearMethod()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_method \u001b[38;5;241m=\u001b[39m linear_method\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_weights\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weight, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/gptq.py:127\u001b[0m, in \u001b[0;36mGPTQLinearMethod.create_weights\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    123\u001b[0m         scale_and_zero_size \u001b[38;5;241m=\u001b[39m input_size_per_partition \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m group_size\n\u001b[1;32m    124\u001b[0m         scale_and_zero_input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    126\u001b[0m qweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    132\u001b[0m     requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m set_weight_attrs(\n\u001b[1;32m    135\u001b[0m     qweight, {\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpack_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mpack_factor,\n\u001b[1;32m    140\u001b[0m     })\n\u001b[1;32m    141\u001b[0m g_idx \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m    142\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    143\u001b[0m         [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/swift/lib/python3.10/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 10.06 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.70 GiB is allocated by PyTorch, and 358.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "dirs = [\"../..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "\n",
    "from swift.llm import (\n",
    "    ModelType, get_vllm_engine, get_default_template_type,\n",
    "    get_template, inference_vllm, VllmGenerationConfig\n",
    ")\n",
    "from custom import CustomModelType, CustomTemplateType\n",
    "\n",
    "model_type = CustomModelType.mixtral_moe_7b_instruct_gptq_int4\n",
    "# model_type = CustomModelType.solar_instruct_10_7b\n",
    "\n",
    "llm_engine = get_vllm_engine(\n",
    "    model_type, \n",
    "    torch_dtype=torch.float16,  # 检查正确的数据类型！！！！\n",
    "    tensor_parallel_size=1,\n",
    "    \n",
    "    engine_kwargs = {\n",
    "        # \"enforce_eager\": True,\n",
    "        \"max_num_seqs\": 64,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "template_type = get_default_template_type(model_type)\n",
    "template = get_template(template_type, llm_engine.hf_tokenizer)\n",
    "\n",
    "generation_config = VllmGenerationConfig(\n",
    "    max_new_tokens=4096,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "get_resp_list = lambda request_list : inference_vllm(\n",
    "    llm_engine, template, request_list, \n",
    "    generation_config=generation_config, \n",
    "    use_tqdm=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\n",
      "\n",
      "CLAIM:\n",
      "Publication date: 2020-08-13\n",
      "Content: Illinois Strengthens Face Mask Rules in Businesses\n",
      "\n",
      "INFORMATION:\n",
      "Information 1:\n",
      "Publication date: 2013-08-06\n",
      "Title: Illinois Strengthens Face Mask Rules in Businesses - WebMD\n",
      "Content:\n",
      "COVID-19 is a new type of coronavirus that causes mild to severe cases. Here’s a quick guide on how to spot symptoms, risk factors, prevent spread of the disease, and find out what to do if you think you have it.\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: press-release\n",
      "Content:\n",
      "Illinoisans can resume activities without wearing a mask indoors on February 28th except where required by federal, state, local, tribal, or territorial laws, rules, and regulations, including local business and workplace guidance. Federal requirements, in effect through at least March 18, include all transportation systems such as airports, planes, trains, and buses. \"Preparing to repeal statewide masking mandates at the end of the month is aggressive and optimistic but reasonable,\" said Dr.\n",
      "\"Broad mandates are not about individuals. They are put in place to help protect communities, businesses, and healthcare access. Repealing the mask mandate allows people to choose the mitigation layers that are best for them and I have no doubt that many should and will choose to keep mask rules.\"\n",
      "If these trends continue — and we expect them to —then on Monday, February 28th, we will lift the indoor mask requirement for the State of Illinois,\" said Governor JB Pritzker. \"I want to be clear: Many local jurisdictions, businesses and organizations have their own mask requirements and other mitigations that must be respected.\n",
      "Seth Trueger, a Northwestern emergency physician who is also immunocompromised. \"Masking has helped slow the spread even in the face of omicron's transmissibility. We can and must use this time to further increase vaccination uptake & outreach, especially among children and other populations with low vaccination rates, so when the next wave comes, we will be even better prepared.\"\n",
      "Information 3:\n",
      "Publication date: None\n",
      "Title: Mask and Vaccine Requirements FAQ's\n",
      "Content:\n",
      "On September 3, 2021, the Governor signed Executive Order 21-22 which requires all individuals over the age of 2 and who can medically tolerate a face covering to wear a face covering when in indoor public places. The Executive Order also requires health care workers, school personnel, higher education personnel and students, and employees and contractors of state-owned or operated congregate facilities to be fully vaccinated, as described in the Order\n",
      "Information 4:\n",
      "Publication date: None\n",
      "Title: FAQ for Businesses Concerning Use of Face-Coverings During COVID-19\n",
      "Content:\n",
      "A: Businesses reserve the right to refuse service to persons unable to comply with the requirement to wear a face covering, but they are required to provide a reasonable accommodation if it does not cause an undue hardship. Businesses are encouraged to inform customers there are exceptions to the requirement that all individuals must wear a mask.\n",
      "These frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. A: A face covering is a mask or cloth face covering that covers your nose and mouth.\n",
      "Exceptions may be made for individuals with medical conditions or disabilities that prevent them from safely wearing a face covering. For more information, refer to the questions on reasonable accommodations. A: Masks still must be worn by everyone on planes, buses, trains, and other forms of public transportation; in transportation hubs, such as airports and train and bus stations; in health care settings; and in congregate facilities, such as correctional facilities and homeless shelters.\n",
      "These frequently asked questions are to provide guidance regarding the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation subject to Article 5 of the Illinois Human Rights Act, 775 ILCS 5/. When Face Coverings are Required Q: What does it mean to wear a face covering?\n",
      "Information 5:\n",
      "Publication date: 2020-04-22\n",
      "Title: Facing Your Face Mask Duties – A List of Statewide Orders | Littler ...\n",
      "Content:\n",
      "********************************************************NOTE: Given the reduction in activity on this topic,THIS POST WILL NO LONGER BE UPDATED, as of November 10, 2022.********************************************************Governors and public health officials across the country implemented stringent mitigation measures to help contain the spread of COVID-19.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Expansion and Summary:\n",
      "\n",
      "Information 1, published on August 6, 2013, is not related to the claim, as it discusses COVID-19 symptoms, risk factors, and prevention measures but does not mention any changes to face mask rules in Illinois businesses.\n",
      "\n",
      "Information 2, the press release, was published on an unspecified date. It announces that Illinois will lift the indoor mask requirement for the State of Illinois on February 28, 2022, except where required by federal, state, local, tribal, or territorial laws, rules, and regulations. Businesses and organizations can still have their own mask requirements. The decision is based on decreasing COVID-19 cases and increasing vaccination rates.\n",
      "\n",
      "Information 3, the FAQs on Mask and Vaccine Requirements, was published on September 3, 2021. It states that Executive Order 21-22 requires all individuals over the age of 2 to wear a face covering in indoor public places and imposes vaccine requirements for certain groups.\n",
      "\n",
      "Information 4, the FAQ for Businesses Concerning Use of Face-Coverings During COVID-19, provides guidance on the application of the face covering requirement in Executive Order 2021-10 for businesses and other places of public accommodation. It specifies that masks must still be worn on public transportation, in transportation hubs, health care settings, and congregate facilities.\n",
      "\n",
      "Information 5, the post on Facing Your Face Mask Duties, was last updated on November 10, 2022. It provides a list of statewide orders related to face mask duties but does not contain information specific to Illinois businesses.\n",
      "\n",
      "Claim Verification:\n",
      "\n",
      "The claim, published on August 13, 2020, states that Illinois strengthens face mask rules in businesses. However, the provided information shows that Illinois actually lifted the indoor mask requirement for the State of Illinois on February 28, 2022, except in specific situations. Therefore, the claim is:\n",
      "\n",
      "FALSE.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_search)):\n",
    "        if claim.strip() in data_search[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "i = 0\n",
    "# i = get_id(\"The Government of Mexico City offers $1,000 weekly if you stay at home.\")\n",
    "\n",
    "claim = data_search[i][\"claim\"]\n",
    "search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "\n",
    "model_name = 'mixtral'\n",
    "prompt_list = [\n",
    "    prompt_rag.get_prompt_for_generating_prior_knowledge(\n",
    "        claim, data_search[i][\"date\"], search_engine, search_results, model_name,\n",
    "        K=K, sort=False, \n",
    "        # ids=data_search[i][\"random_ids\"],\n",
    "        ids=None\n",
    "    ),\n",
    "]\n",
    "\n",
    "request_list = [{'query': prompt} for prompt in prompt_list]\n",
    "\n",
    "print(prompt_list[0])\n",
    "\n",
    "resp_list = get_resp_list(request_list)\n",
    "print(resp_list[0][\"response\"].strip())\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
