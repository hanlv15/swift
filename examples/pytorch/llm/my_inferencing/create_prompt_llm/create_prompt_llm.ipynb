{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import sys\n",
    "import prompt_rag\n",
    "\n",
    "dirs = [\"..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "\n",
    "import covmis\n",
    "\n",
    "search_engine = \"brave\"\n",
    "\n",
    "data_train = covmis.load_train()\n",
    "data_search = covmis.load_train_search()\n",
    "data_search_llm = covmis.load_train_llm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并多个文件的先验知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 5,\n",
       " 'prior_knowledge_llama3_v1_K=5': '**Summary of INFORMATION**\\n\\nThe provided information consists of five articles and a Wikipedia page that discuss Dr. Judy Mikovits, a former research scientist, and her claims about COVID-19, Dr. Anthony Fauci, and vaccines. The articles fact-check her statements and conclude that they are largely false or misleading.\\n\\n**Information 1**: A fact-checking article debunks several claims, including the alleged cover-up by Dr. Fauci, the lab-made origin of SARS-CoV-2, and the 36% increase in COVID-19 mortality due to influenza vaccines.\\n\\n**Information 2**: An article describes Dr. Mikovits\\' conspiracy theories as \"demonstrably untrue\" and mentions that her research was fraudulent.\\n\\n**Information 3**: A fact-checking article examines Dr. Mikovits\\' claims, including her statement that face masks \"activate\" the virus, and finds no evidence to support her assertions.\\n\\n**Information 4**: Dr. Mikovits\\' Wikipedia page summarizes her background, research, and controversies, including her promotion of conspiracy theories about COVID-19 and her arrest in 2011.\\n\\n**Information 5**: A fact-checking article analyzes the \"Plandemic\" video, which features Dr. Mikovits, and debunks several false and misleading claims about COVID-19, vaccines, and treatments.\\n\\n**Evaluation of the CLAIM**\\n\\nBased on the provided information, the CLAIM is classified as **FALSE**.\\n\\nThere is no credible evidence to support Dr. Mikovits\\' claims that Dr. Anthony Fauci was paid to cover up the extent of the COVID-19 problem, that SARS-CoV-2 was created in a lab, or that influenza vaccines increase COVID-19 mortality by 36%. Multiple fact-checking articles and experts have debunked these claims, and Dr. Mikovits\\' research has been discredited due to fraud and lack of evidence.',\n",
       " 'prior_knowledge_mixtral_v1_K=5': 'Information:\\n\\n1. A false claim. No evidence of a COVID-19 cover-up by Dr. Fauci or any link between influenza vaccines and increased COVID-19 mortality. The claim about influenza vaccines increasing COVID-19 deaths originates from a misinterpreted study on four types of common coronaviruses, not SARS-Cov-2.\\n2. Dr. Judy Mikovits is a controversial virologist. Her claims of a scientific cover-up involving Dr. Fauci and \"Big Pharma\" lack credibility. She perpetrated a scientific fraud in 2009.\\n3. Dr. Mikovits has a history of unfounded and unscientific claims, including her belief that a flu vaccine caused a \"bad strain of flu virus\" that led to COVID-19. She also claims that wearing a mask \"literally activates your own virus\" and that the flu vaccine is responsible for spreading the novel coronavirus.\\n4. Dr. Mikovits gained attention for spreading conspiracy theories related to the COVID-19 pandemic. No evidence exists to support her claims that the flu vaccine is responsible for spreading the novel coronavirus.\\n5. The \"Plandemic\" viral interview with Dr. Mikovits contains a series of misleading and unsubstantiated claims. The claim that the flu vaccine is linked to an increased risk of novel coronavirus is not supported by any scientific evidence.\\n\\nGiven the information above, the claim that \"Dr. Mikovits, an established scientist, revealed that Dr. Anthony Fauci was paid to cover up the extent of the problem caused by COVID-19. Also, she revealed that SARS-CoV-2 was created in a lab and that influenza vaccines increase COVID-19 mortality by 36%\" is FALSE.\\n\\nThere is no credible evidence to support the claim that influenza vaccines increase the risk of novel coronavirus, and the claim that the virus was created in a laboratory lacks any scientific credibility. Dr. Mikovits\\'s credibility is further undermined by her previous scientific misconduct and her spreading of conspiracy theories.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bing search llm\n",
    "# v2: k = 5\n",
    "# v3: 不对时间排序\n",
    "\n",
    "# brave search llm\n",
    "\n",
    "# Solar\n",
    "# v1: k = 5\n",
    "# v2: k = 5 随机选取\n",
    "\n",
    "# Mixtral\n",
    "# v1: k = 5\n",
    "\n",
    "\n",
    "# llama3\n",
    "# v1: k = 5, vllm = 0.5.0\n",
    "\n",
    "sort = False\n",
    "prior_knowledge_list = []\n",
    "\n",
    "K = 5\n",
    "prior_knowledge_version = \"1\"\n",
    "model_name = \"mixtral\"\n",
    "\n",
    "with open(f\"train_search_llm_tmp.json\", \"r\") as f:\n",
    "    prior_knowledge_list = json.load(f)\n",
    "\n",
    "for i, item in enumerate(data_search_llm):\n",
    "\n",
    "    if item[\"id\"] != prior_knowledge_list[i][\"id\"]:\n",
    "        print(i)\n",
    "        print(data_train[i][\"claim\"])\n",
    "        print(prior_knowledge_list[i][\"claim\"])\n",
    "        raise Exception()\n",
    "    else:\n",
    "        # vv = \"\"\n",
    "        # if prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}3\") is not None:\n",
    "        #     vv = \"3\"\n",
    "        # elif prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}2\") is not None:\n",
    "        #     vv = \"2\"\n",
    "\n",
    "        item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"] = prior_knowledge_list[i][f\"prior_knowledge_{model_name}\"]\n",
    "# There was a false study done where they gave it to very sick people -- extremely sick people, people that were ready to die. It was given by, obviously, not friends of the administration. And the study came out. The people were ready to die. Everybody was old, had bad problems with hearts, diabetes, and everything else you can imagine. So they gave it. So, immediately, when it came out, they gave a lot of false information, just so you understand. Great studies came out of Italy on hydroxy. \n",
    "# There was a false study done where they gave it to very sick people -- extremely sick people, people that were ready to die. It was given by, obviously, not friends of the administration. And the study came out. The people were ready to die. Everybody was old, had bad problems with hearts, diabetes, and everything else you can imagine. So they gave it. So, immediately, when it came out, they gave a lot of false information, just so you understand. Great studies came out of Italy on hydroxy. \n",
    "\n",
    "data_search_llm[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covmis.save_train_llm(data_search_llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建数据（带有先验知识的Prompt）以微调LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list = []\n",
    "\n",
    "# data_version = \"1\"\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "    \n",
    "#     if int(data_train[i][\"label\"]) != 1:\n",
    "#         prompt = prompt_rag.get_prompt_with_prior_knowledge(\n",
    "#             data_train[i][\"claim\"], \n",
    "#             search_engine,\n",
    "#             data_search[i][f\"{search_engine}_search_results\"], \n",
    "#             item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"], \n",
    "#             K=K,\n",
    "#             claim_date=data_train[i][\"date\"],\n",
    "#             known_info=True, \n",
    "#             ids=None\n",
    "#         )\n",
    "#         label = \"TRUE.\" if int(data_train[i][\"label\"]) == 2 else \"FALSE.\"\n",
    "#         dict_list.append({\"query\": prompt, \"response\": label})\n",
    "# print(dict_list[0][\"query\"])\n",
    "# len(dict_list), dict_list[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_dir = \"/home/hanlv/workspace/code/research/infodemic/LLM/\"\n",
    "# with jsonlines.open(\n",
    "#     LLM_dir + \\\n",
    "#     f\"swift/examples/pytorch/llm/my_data/with_{model_name}_info/{search_engine}/data{data_version}.jsonl\", mode=\"w\") as file_jsonl:\n",
    "#     for line in dict_list:\n",
    "#         file_jsonl.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型的先验知识生成效果：一次提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 01:26:04,247 - modelscope - INFO - PyTorch version 2.3.0 Found.\n",
      "2024-07-01 01:26:04,249 - modelscope - INFO - Loading ast index from /home/hanlv/.cache/modelscope/ast_indexer\n",
      "2024-07-01 01:26:04,274 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 21bc0b9ccf26bcf3f4ca2e675ec8875d and a total number of 980 components indexed\n",
      "[INFO:swift] Successfully registered `/home/hanlv/workspace/code/research/infodemic/LLM/swift/swift/llm/data/dataset_info.json`\n",
      "[INFO:swift] Loading the model using model_dir: /home/css/models/Mixtral-8x7B-Instruct-v0.1-AWQ\n",
      "[INFO:swift] model_config: MixtralConfig {\n",
      "  \"_name_or_path\": \"/home/css/models/Mixtral-8x7B-Instruct-v0.1-AWQ\",\n",
      "  \"architectures\": [\n",
      "    \"MixtralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mixtral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts_per_tok\": 2,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_local_experts\": 8,\n",
      "  \"output_router_logits\": false,\n",
      "  \"quantization_config\": {\n",
      "    \"bits\": 4,\n",
      "    \"group_size\": 128,\n",
      "    \"modules_to_not_convert\": [\n",
      "      \"gate\"\n",
      "    ],\n",
      "    \"quant_method\": \"awq\",\n",
      "    \"version\": \"gemm\",\n",
      "    \"zero_point\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"router_aux_loss_coef\": 0.02,\n",
      "  \"router_jitter_noise\": 0.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 07-01 01:26:04 config.py:217] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 01:26:08,336\tINFO worker.py:1753 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-01 01:26:09 config.py:623] Defaulting to use mp for distributed inference\n",
      "INFO 07-01 01:26:09 llm_engine.py:161] Initializing an LLM engine (v0.5.0.post1) with config: model='/home/css/models/Mixtral-8x7B-Instruct-v0.1-AWQ', speculative_config=None, tokenizer='/home/css/models/Mixtral-8x7B-Instruct-v0.1-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=42, served_model_name=/home/css/models/Mixtral-8x7B-Instruct-v0.1-AWQ)\n",
      "INFO 07-01 01:26:09 selector.py:150] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 07-01 01:26:09 selector.py:51] Using XFormers backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:11 selector.py:150] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:11 selector.py:51] Using XFormers backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:12 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 07-01 01:26:12 utils.py:637] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:12 utils.py:637] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:12 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "INFO 07-01 01:26:12 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:13 selector.py:150] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:13 selector.py:51] Using XFormers backend.\n",
      "INFO 07-01 01:26:13 selector.py:150] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 07-01 01:26:13 selector.py:51] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-07-01 01:26:17,226 E 124916 124953] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-01_01-26-04_766329_124564 is over 95% full, available space: 16588029952; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:19 model_runner.py:160] Loading model weights took 11.4912 GB\n",
      "INFO 07-01 01:26:20 model_runner.py:160] Loading model weights took 11.4912 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f42d37d1650>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-01 01:26:23 distributed_gpu_executor.py:56] # GPU blocks: 9029, # CPU blocks: 4096\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:26 model_runner.py:889] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=128518)\u001b[0;0m INFO 07-01 01:26:26 model_runner.py:893] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 07-01 01:26:26 model_runner.py:889] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 07-01 01:26:26 model_runner.py:893] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-07-01 01:26:27,240 E 124916 124953] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-07-01_01-26-04_766329_124564 is over 95% full, available space: 16587997184; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "dirs = [\"../..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "\n",
    "from swift.llm import (\n",
    "    ModelType, get_vllm_engine, get_default_template_type,\n",
    "    get_template, inference_vllm, VllmGenerationConfig\n",
    ")\n",
    "from custom import CustomModelType, CustomTemplateType\n",
    "\n",
    "# model_type = ModelType.mixtral_moe_7b_instruct\n",
    "\n",
    "# model_type = CustomModelType.phi_3_medium_4k_instruct\n",
    "# model_type = CustomModelType.llama_3_70b_instruct_awq\n",
    "model_type = CustomModelType.mixtral_moe_7b_instruct_awq\n",
    "# model_type = CustomModelType.solar_instruct_10_7b\n",
    "\n",
    "llm_engine = get_vllm_engine(\n",
    "    model_type, \n",
    "    # torch_dtype=torch.float16,  # 检查正确的数据类型！！！！\n",
    "    tensor_parallel_size=2,\n",
    "    max_model_len=4096,\n",
    "    # gpu_memory_utilization=0.92,\n",
    "    # model_id_or_path=\"/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\",\n",
    "    engine_kwargs = {\n",
    "        # \"enforce_eager\": True,\n",
    "        \"max_num_seqs\": 64, # 64\n",
    "        \"seed\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "template_type = get_default_template_type(model_type)\n",
    "template = get_template(template_type, llm_engine.hf_tokenizer)\n",
    "\n",
    "generation_config = VllmGenerationConfig(\n",
    "    max_new_tokens=2048,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "get_resp_list = lambda request_list : inference_vllm(\n",
    "    llm_engine, template, request_list, \n",
    "    generation_config=generation_config, \n",
    "    use_tqdm=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n",
      "I'm just a computer program, so I don't have feelings or emotions. I don't have the ability to \"be.\" I exist only to process and provide information. How can I help you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get_resp_list = lambda request_list : inference_vllm(\n",
    "#     llm_engine, template, request_list, \n",
    "#     generation_config=generation_config, \n",
    "#     use_tqdm=False, \n",
    "#     verbose=True, prompt_prefix=\"\", output_prefix=\"\"\n",
    "# )\n",
    "\n",
    "s = \"Information Summary:\\n\\nInformation 1, published on 2020-12-01, discusses a false claim about a Covid-19 vaccine having the ability to \\\"transfer genetic material\\\" and manipulate human genes. The claim was shared hundreds of times on Facebook, but experts, such as Dr. Kirsty Short, have confirmed that the mRNA vaccine cannot enter the human genome. Information 2, published on 2020-05-19, mentions false claims about a future Covid-19 vaccine genetically modifying humans. Information 3, with no specific publication date, states that Covid-19 vaccines do not change a person's genes and use messenger RNA or modified adenovirus to trigger an immune response. Information 4, published on 2023-11-01, reiterates that Covid-19 vaccines cannot alter a person's genome and debunks false claims about DNA contamination leading to harmful effects. Information 5, with no specific publication date, highlights the importance of monitoring and addressing vaccine misinformation to prevent vaccine hesitancy.\\n\\nRestated Claim:\\nOn 2020-12-01, experts refuted the false claim that a Covid-19 vaccine can manipulate human genes.\\n\\nGiven the information available, the claim is TRUE. The Covid-19 vaccines developed by Pfizer-BioNTech, Moderna, and Johnson & Johnson do not have the ability to manipulate human genes, as confirmed by various experts and sources. These vaccines either use messenger RNA or modified adenovirus to trigger an immune response, but they cannot alter human DNA.\"\n",
    "\n",
    "prompt_list = [\"how are you\"] * 10\n",
    "\n",
    "resp_list = get_resp_list([{'query': prompt} for prompt in prompt_list])\n",
    "\n",
    "for resp in resp_list:\n",
    "    print(resp[\"response\"])\n",
    "\n",
    "# print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prompt_for_generating_prior_knowledge(\n",
    "#         claim, claim_date, search_engine, search_results, model_name,\n",
    "#         K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "#     \"\"\"\n",
    "#     sort: 对search result 按时间进行排序\n",
    "#     \"\"\"\n",
    "\n",
    "#     claim = claim.strip()\n",
    "\n",
    "#     if model_name == \"solar\":\n",
    "#         pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "#     elif model_name == \"mixtral\":\n",
    "#         # v1\n",
    "#         # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "#         # v2\n",
    "#         # pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        \n",
    "#         pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "\n",
    "#     else:\n",
    "#         raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "#     if without_claim_date:\n",
    "#         text = \"CLAIM: \" + claim\n",
    "#     else:\n",
    "#         text = \"CLAIM: \" + prompt_rag.get_claim_with_date(claim, claim_date)\n",
    "\n",
    "#     if search_engine == \"bing\":\n",
    "#         snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "#     elif search_engine == \"brave\":\n",
    "#         if ids is None:\n",
    "#             ids = slice(0, K)\n",
    "#         snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "#     else:\n",
    "#         raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "#     info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "#     if without_info:\n",
    "#         return (pre + text).strip()\n",
    "#     else:\n",
    "#         return pre + info + text\n",
    "\n",
    "# def get_claim_with_date(claim, claim_date=None):\n",
    "#     if claim_date is None:\n",
    "#         return \" \" + claim\n",
    "    \n",
    "#     # res = \"\\n\"\n",
    "#     res = claim + \"\\nPublication date: \" + claim_date\n",
    "#     return res\n",
    "\n",
    "# K = 5\n",
    "# def get_id(claim):\n",
    "#     for i in range(len(data_train)):\n",
    "#         if claim.strip() in data_train[i][\"claim\"].strip():\n",
    "#             return i\n",
    "\n",
    "# # i = 0\n",
    "# i = get_id(\"False claim circulates that Pakistani plane transported Sri Lankan students home after COVID-19 lockdown\")\n",
    "\n",
    "# # claim = data_search[i][\"claim\"]\n",
    "# search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "\n",
    "# model_name = 'mixtral'\n",
    "# prompt_list1 = [\n",
    "#     get_prompt_for_generating_prior_knowledge(\n",
    "#         data_train[i][\"claim\"], data_train[i][\"date\"], search_engine, search_results, model_name,\n",
    "#         K=K, sort=False, \n",
    "#         # ids=data_search[i][\"random_ids\"],\n",
    "#         ids=None\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "# request_list1 = [{'query': prompt} for prompt in prompt_list1]\n",
    "\n",
    "# print(prompt_list1[0])\n",
    "# print()\n",
    "\n",
    "# resp_list1 = get_resp_list(request_list1)\n",
    "# print(resp_list1[0][\"response\"].strip())\n",
    "# print()\n",
    "# resp_list1[0][\"response\"].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [07:10<00:00,  8.12s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_prompt_for_generating_prior_knowledge2(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    pre + info + text\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        \n",
    "        # pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "    \n",
    "    elif model_name == \"llama3\":\n",
    "        # pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "    elif model_name == \"phi3\":\n",
    "        # CLAIM\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        \n",
    "        # <CLAIM>\n",
    "        # pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        if model_name == \"mixtral\":\n",
    "            text = \"CLAIM: \"\n",
    "        elif model_name == \"llama3\":\n",
    "            text = \"<CLAIM>: \"\n",
    "        elif model_name == \"phi3\":\n",
    "            text = \"CLAIM: \"\n",
    "        text += get_claim_with_date(claim, claim_date)\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + info + text\n",
    "\n",
    "def get_prompt_for_generating_prior_knowledge1(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    pre + text + info\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "\n",
    "\n",
    "        pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        pre += \"CLAIM: \"\n",
    "\n",
    "        # pre = \"Below is a <CLAIM> and some INFORMATION searched online. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        # pre += \"<CLAIM>: \"\n",
    "\n",
    "    elif model_name == \"llama3\":\n",
    "\n",
    "        pre = \"Below is a <CLAIM> and some INFORMATION searched online. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        pre += \"<CLAIM>: \"\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = get_claim_with_date(claim, claim_date) + '\\n\\n'\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + text + info\n",
    "    \n",
    "def get_claim_with_date(claim, claim_date=None):\n",
    "    if claim_date is None:\n",
    "        return \" \" + claim\n",
    "    \n",
    "    # res = \"\\n\"\n",
    "    res = claim + \"\\nPublication date: \" + claim_date\n",
    "    return res\n",
    "\n",
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_train)):\n",
    "        if claim.strip() in data_train[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "# i = 0\n",
    "i = get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\")\n",
    "\n",
    "# ids = [194]\n",
    "ids1 = [19, 36, 57, 85, 98, 107, 116, 117, 125, 129, 194, 195, 204, 208, 212, 235, 279, 324, 328]\n",
    "# ids1 = [\n",
    "#     get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\"),\n",
    "#     get_id(\"Myth spreads online that Australian supermarkets have banned Chinese nationals during COVID-19 pandemic\"),\n",
    "#     get_id(\"Trump makes false claims about COVID-19 testing\"),\n",
    "#     get_id(\"UNHCR condemns fake notice which claimed refugees in Malaysia are resisting COVID-19 tests\"),\n",
    "#     get_id(\"Hospitals in Ohio were not set on fire during protests\"),\n",
    "#     get_id(\"A 2010 study on vaccines did not show that one in forty were damaged by vaccination\"),\n",
    "#     get_id(\"The Philippine health department said it did not issue this 'checklist' for COVID-19 symptoms\"),\n",
    "#     get_id(\"Contaminated CDC COVID-19 test kits recalled and did not spread virus\"),\n",
    "#     get_id(\"Experts refute false claim that Covid-19 vaccine can 'manipulate' human genes\"),\n",
    "#     get_id(\"Countries were not buying Covid-19 test kits in 2018\"),\n",
    "#     get_id(\"False claim circulates that Pakistani plane transported Sri Lankan students home after COVID-19 lockdown\"),\n",
    "#     get_id(\"People will not have to be vaccinated against COVID-19 to receive food stamps and rent assistance\"),\n",
    "#     get_id(\"Britain has not awarded a contract to develop a vaccine passport\"),\n",
    "#     get_id(\"World Health Organization says COVID-19 means ‘coronavirus disease 2019’ – not 'China outbreak virus'\"),\n",
    "#     get_id(\"The common cold is not the same as COVID-19 and the NHS is not saying it is\"),\n",
    "#     get_id(\"Philippine authorities did not issue this warning after the novel coronavirus outbreak\"),\n",
    "#     get_id(\"No tourists have been allowed to visit New Zealand since March 2020 -- this photo has circulated online since 2016\"),\n",
    "#     get_id(\"This video does not show social distancing failure on an Air India flight during the coronavirus pandemic\"),\n",
    "#     get_id(\"This photo shows a Sri Lankan airline pilot who tested positive for the novel coronavirus.\"), # fALSE\n",
    "# ]\n",
    "\n",
    "ids2 = [\n",
    "    get_id(\"Gynecological Cancers Not Tied to Severe COVID-19\"),\n",
    "    get_id(\"In February 2021, the Centers for Disease Control and Prevention (CDC) advised U.S. travelers to \\u201cavoid all travel to Mexico.\\u201d\"),\n",
    "    get_id(\"The U.S. CDC encourages the use of a \\u201c[COVID-19] flu shot\\u201d on children.\"),\n",
    "    get_id(\"An announcement was made on March 9 that all classes in the Basque Country were canceled due to the coronavirus.\"),\n",
    "    get_id(\"Rita Wilson, Tom Hanks’ wife, stated in an interview at CBS that “she wouldn’t be alive if not for chloroquine”\"),\n",
    "    get_id(\"Japan’s Nobel Prize winning Professor of Medicine, Professor Dr Tasuku Honjo has claimed that the coronavirus is not natural and that China manufactured it.\"),\n",
    "    get_id(\"Lies spread by Serbian authorities about COVID-19. For example, the virus does not affect pregnant women, children and young people; no newborn is infected with the coronavirus; the virus does not last long on objects; the number of respiratory machines that Serbia possesses, etc.\"),\n",
    "    get_id(\"Chief Secretary of West Bengal was not following relaxing while the state was performing poorly as it fought COVID-19.\"),\n",
    "    get_id(\"Businessman Ratan Tata has said that 2020 is the year to survive and not care about profits and losses.\"),\n",
    "    get_id(\"Celebrities spreading misinformation about coronavirus and the Janata curfew in India.\"),\n",
    "    get_id(\"This 3 year old girl is fighting for her life after getting the coronavirus.\"),\n",
    "    get_id(\"President Vucic claims that no one said coronavirus is the “funniest” virus.\"),\n",
    "    get_id(\"News photo from stay-at-home protest was doctored to add Confederate flag.\"),\n",
    "    get_id(\"President Donald Trump referred to the coronavirus as a “hoax” or “political conspiracy.”\"),\n",
    "    get_id(\"President Trump refers to the coronavirus as a hoax in an audio clip.\"),\n",
    "    get_id(\"A false image says that President Duque will declare a shutdown on November 1st.\"),\n",
    "    get_id(\"Professor Perronne makes several false claims on PCR tests, HCQ and hospitals.\"),\n",
    "    get_id(\"Audio of Biden calling the coronavirus a hoax.\"),\n",
    "    get_id(\"President Trump’s claim that he inherited no ventilators from the Obama administration.\"),\n",
    "    get_id(\"Video shows President Donald Trump saying COVID-19 is Democrats’ “new hoax.”\"),\n",
    "    get_id(\"Fauci Wasn't Involved in New Testing Guidelines\"),\n",
    "    get_id(\"This movie “Songbird” has been made before Covid. We’ve seen a lot of similar movies, yes. But, it is interesting that in the movie the virus is called COVID-23. Stop the scene when there is news on TV and you will see. Coincidence?\"),\n",
    "    get_id(\"Images of the newspaper front pages sharing vaccine misinformation\"),\n",
    "    get_id(\"I don't believe illegal casinos are operating in Bangkok, but if the doctor knows about it, he can inform the authorities.\"),\n",
    "    get_id(\"Facebook posts promote false conspiracy that coronavirus testing patent was submitted in 2015\"),\n",
    "    get_id(\"Misleading description of Canada\\u2019s quarantine sites feeds Covid-19 conspiracy\"),\n",
    "    get_id(\"Video repeats COVID-19 conspiracy theories\"),\n",
    "    get_id(\"The post contains a COVID-19 conspiracy theory written by former South Carolina Rep. Trey Gowdy.\"),\n",
    "    get_id(\"A long conspiracy video claims that: vaccines can alter a person’s DNA, nanorobots are inserted with the vaccine to collect biometric data, Bill Gates already owns this data and the body can receive 5G signal after the vaccine is taken\"),\n",
    "    get_id(\"Jorge Luis Sonnante published a 16-minute video that went viral on networks. In the video, Sonnante (who describes himself as a \\u201cdeacon\\u201d, but gives falsified evidence of this charge) mixes several conspiracy theories, some meaningless, others already denied, about the pandemic caused by the SARS coronavirus -CoV-2.\"),\n",
    "    get_id(\"Trump touts testing as \\\"greatest capacity in the world,\\\" but says people \\\"shouldn't want to get tested\\\"\"),\n",
    "    get_id(\"Alberto Fernández, about the coronavirus: “Mortality in people over 65 is 80%”.\"),\n",
    "    get_id(\"An English man received a COVID-19 vaccine through his shirt\"),\n",
    "    get_id(\"The first recipient of the COVID-19 trial vaccine is dead.\"),\n",
    "    get_id(\"ICUs are not overwhelmed\"),\n",
    "    get_id(\"Coronavirus tests do not work to diagnose COVID-19. Red Bull tests positive.\"),\n",
    "    get_id(\"Rapidly developed pharmaceuticals such as the Covid-19 vaccines compared to a sedative from the 1950s that caused serious birth defects.\"),\n",
    "    get_id(\"The major cause of death in Covid-19 is thrombosis or blood clot and not pneumonia.\"),\n",
    "    get_id(\"The COVID-19 virus was artificially created by the U.S. military and placed in a capsule.\"),\n",
    "    get_id(\"A video of a girl collapsing in a store is being shared widely on social media with a claim that the girl died of Coronavirus.\"),\n",
    "    get_id(\"Italy\\u2019s prime minister cries and declares that his country \\u201clost the battle\\u201d against the coronavirus.\"),\n",
    "    get_id(\"Black people are not being targeted for UK coronavirus vaccine trials\"),\n",
    "    get_id(\"In September 2019, a train named COVID-19 appeared in the United States, carrying gases that cause COVID-19.\"),\n",
    "    get_id(\"If you take the vaccine, you'll be enrolled in a pharmacovigilance tracking system. It means that you've enrolled yourself in a medical trial.\"),\n",
    "    get_id(\"Henry Kissinger quote about mandatory vaccinations\"),\n",
    "    get_id(\"RECEIVE FOOD AID SOCIAL PLAN 2020\"),\n",
    "    get_id(\"Post claims the video clip is last message of deceased Pakistani doctor Osama Riyaz who had contracted Coronavirus while treating patients\"),\n",
    "    get_id(\"For a few days now, an image has been circulating on Facebook claiming that COVID-19 can be cured with Dolex Gripa, \\\"Noraver\\\" night, and gargling with warm water and lemon.\"),\n",
    "    get_id(\"A magic remedy to prevent COVID-19: mix brown sugar, ginger, garlic, and Chinese leek, boil them and drink it.\"),\n",
    "    get_id(\"Some statements by the American political scientist and activist Susan George in which she says that “Spaniards are laboratory rats: let’s see how much punishment they tolerate without rebelling.” The phrase is shared related to the current coronavirus pandemic.\"),\n",
    "    get_id(\"Saddam Hussein explains what the coronavirus is.\"),\n",
    "    get_id(\"A Facebook post is spreading the false claim that former President Barack Obama gave $3.8 million to a lab in Wuhan, China.\"),\n",
    "    get_id(\"\\u2019No discrimination\\u2019 against Africans amid pandemic.\")\n",
    "]\n",
    "\n",
    "ids_x = [ids2[3],]\n",
    "\n",
    "prompt_list = []\n",
    "model_name = 'mixtral'\n",
    "\n",
    "# [ids2[ii] for ii in ids_filtered]:\n",
    "for i in ids2:\n",
    "    # claim = data_search[i][\"claim\"]\n",
    "    search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "    prompt_list.append(get_prompt_for_generating_prior_knowledge2(\n",
    "            data_train[i][\"claim\"], data_train[i][\"date\"], search_engine, \n",
    "            search_results, model_name, K=K, sort=False, \n",
    "            # ids=data_search[i][\"random_ids\"],\n",
    "            ids=None\n",
    "        ))\n",
    "request_list = [{'query': prompt} for prompt in prompt_list]\n",
    "\n",
    "resp_list = get_resp_list(request_list)\n",
    "# print(resp_list[0][\"response\"].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\n",
      "\n",
      "INFORMATION:\n",
      "Information 1:\n",
      "Publication date: 2020-05-14\n",
      "Title: FALSE: Jorge Luis Sonnante published a 16-minute video that went ...\n",
      "Content:\n",
      "The #CoronavirusFacts database records fact-checks published since the beginning of the COVID-19 outbreak. The pandemic and its consequences are constantly evolving and data that was accurate weeks or even days ago might have changed. Remember to check the date when the fact-check you are reading was published before sharing it.\n",
      "Explanation: The Argentinian man, a frequent disseminator of disinformation, published a video with a patchwork quilt with false information about the COVID-19 pandemic. Read the Full Article (Colombiacheck) ... The #CoronavirusFacts database records fact-checks published since the beginning of the COVID-19 outbreak.\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: Video de Jorge Sonnante sobre coronavirus está repleto de falsedades ...\n",
      "Content:\n",
      "El argentino, frecuente diseminador de desinformaciones, publicó un <strong>video</strong> con una colcha de retazos con informaciones falsas acerca de la pandemia por COVID-19.\n",
      "Information 3:\n",
      "Publication date: None\n",
      "Title: Deacon George Sonnante - YouTube\n",
      "Content:\n",
      "AboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy &amp; SafetyHow YouTube worksTest new features · © 2023 Google LLC\n",
      "Information 4:\n",
      "Publication date: None\n",
      "Title: Diacono Jorge Sonnante (@observadorpapal) | Twitter\n",
      "Content:\n",
      "The latest tweets from Diacono <strong>Jorge</strong> <strong>Sonnante</strong> (@observadorpapal)\n",
      "Information 5:\n",
      "Publication date: None\n",
      "Title: Diacono Jorge Sonnante on Twitter: \"NOTICE: \"ALL THE ...\n",
      "Content:\n",
      "Diacono <strong>Jorge</strong> <strong>Sonnante</strong> <strong>on</strong> Twitter: &quot;NOTICE: &quot;ALL THE ...\n",
      "\n",
      "CLAIM: Jorge Luis Sonnante published a 16-minute video that went viral on networks. In the video, Sonnante (who describes himself as a “deacon”, but gives falsified evidence of this charge) mixes several conspiracy theories, some meaningless, others already denied, about the pandemic caused by the SARS coronavirus -CoV-2.\n",
      "Publication date: 2020-05-14\n"
     ]
    }
   ],
   "source": [
    "# llama-3-70b\n",
    "# CLAIM + info wrong: 1, 18\n",
    "# info + CLAIM wrong: 18\n",
    "\n",
    "# CLAIM + info wrong: 1, 2, 3, 7, 11, 15, 20, 30, 45, 51\n",
    "# info + CLAIM wrong: 1, 2, $3, 7, 11, 20, 45  √√√√√√√√√√√\n",
    "\n",
    "\n",
    "# mixtral-8x7b\n",
    "# claim wrong: 0, 1, 8, 10, 12\n",
    "# <claim>:1, 3\n",
    "\n",
    "# claim: 0, 1, 15, 16, 20, 24, 25, 30, 51\n",
    "# <claim>: 0, 1, 2, 7, 15, 16, 24, 25, 29, 51\n",
    "\n",
    "# phi-3-medium\n",
    "# claim wrong: \n",
    "# <claim>: 1, 8, 13, 18\n",
    "\n",
    "# claim: 1, 3, 7, 13, 15, 20, 22, 24, 25, 39, 51\n",
    "# <claim>: \n",
    "\n",
    "\n",
    "print(len(ids2))\n",
    "\n",
    "nn = 29\n",
    "print(prompt_list[nn])\n",
    "# print('*'*50)\n",
    "# print(data_train[ids2[nn]][\"label\"])\n",
    "# print(resp_list[nn][\"response\"].strip())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
