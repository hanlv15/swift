{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import sys\n",
    "import prompt_rag\n",
    "\n",
    "search_engine = \"brave\"\n",
    "\n",
    "with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-2024/train_{search_engine}_search.json\", \"r\") as f:\n",
    "    data_search = json.load(f)\n",
    "\n",
    "try:\n",
    "    with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-2024/train_{search_engine}_search_llm.json\", \"r\") as f:\n",
    "        data_search_llm = json.load(f)\n",
    "except:\n",
    "    pass\n",
    "    # data_search_llm = [{\n",
    "    #     \"claim\": i[\"claim\"],\n",
    "    #     \"claimant\": i[\"claimant\"],\n",
    "    #     \"label\": i[\"label\"],\n",
    "    #     \"date\": i[\"date\"],\n",
    "    # } for i in data_search]\n",
    "    # with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"w\") as f:\n",
    "    #     json.dump(data_search_llm, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.update_train_search_llm( \n",
    "#     \"SOLAR-10.7B-Instruct-v1.0\", \"solar\", port=8001, \n",
    "#     data_search=data_search, data_search_llm=data_search_llm) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并多个文件的先验知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对prior_knowledge做修改\n",
    "# sort = False\n",
    "# prior_knowledge_list = []\n",
    "\n",
    "# K = 5\n",
    "# prior_knowledge_version = \"1\"\n",
    "# prior_knowledge_version_adjust = prior_knowledge_version + \".2\"\n",
    "# model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     prior_knowledge = item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"]\n",
    "    \n",
    "#     find_list = [\n",
    "#         \"Information Expansion and Summary:\",\n",
    "#         # \"Information Summary:\",\n",
    "#         # \"Expanded Information Summary:\",\n",
    "#         \"Claim Analysis:\",\n",
    "#         # \"Claim Verification\",\n",
    "#         # \"Claim Analysis and Judgement:\"\n",
    "#     ]\n",
    "\n",
    "\n",
    "#     for s in find_list:\n",
    "#         pos = prior_knowledge.find(s)\n",
    "#         if pos == -1:\n",
    "#             continue\n",
    "        \n",
    "#         num_extra = 2\n",
    "#         if pos!=0 and prior_knowledge[pos-1] == '\\n':\n",
    "#             pos -= 1\n",
    "#             num_extra += 1\n",
    "#         prior_knowledge = prior_knowledge[:pos] + prior_knowledge[pos + len(s) + num_extra :]\n",
    "\n",
    "  \n",
    "#     item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version_adjust}_K={K}\"] = prior_knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing search llm\n",
    "# v2: k = 5\n",
    "# v3: 不对时间排序\n",
    "\n",
    "# brave search llm\n",
    "\n",
    "# Solar\n",
    "# v1: k = 5\n",
    "# v2: k = 5 随机选取\n",
    "\n",
    "# Mixtral\n",
    "# v1: k = 5\n",
    "# v1.1: 删除结构化内容（Information Expansion and Summary、Claim Analysis）\n",
    "\n",
    "sort = False\n",
    "prior_knowledge_list = []\n",
    "\n",
    "K = 5\n",
    "prior_knowledge_version = \"1\"\n",
    "model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# with open(f\"train_search_llm_tmp.json\", \"r\") as f:\n",
    "#     prior_knowledge_list = json.load(f)\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     if item[\"claim\"] != prior_knowledge_list[i][\"claim\"].strip():\n",
    "#         print(i)\n",
    "#         print(item[\"claim\"])\n",
    "#         print(prior_knowledge_list[i][\"claim\"])\n",
    "#         raise Exception()\n",
    "#     else:\n",
    "#         # vv = \"\"\n",
    "#         # if prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}3\") is not None:\n",
    "#         #     vv = \"3\"\n",
    "#         # elif prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}2\") is not None:\n",
    "#         #     vv = \"2\"\n",
    "\n",
    "#         item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"] = prior_knowledge_list[i][f\"prior_knowledge_{model_name}\"]\n",
    "\n",
    "# data_search_llm[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.save_search_llm(data_search_llm, search_engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建数据（带有先验知识的Prompt）以微调LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list = []\n",
    "\n",
    "# data_version = \"2\"\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "    \n",
    "#     if int(item[\"label\"]) != 1:\n",
    "#         prompt = prompt_rag.get_prompt_with_prior_knowledge(\n",
    "#             item[\"claim\"], \n",
    "#             search_engine,\n",
    "#             data_search[i][f\"{search_engine}_search_results\"], \n",
    "#             item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"], \n",
    "#             K=K,\n",
    "#             claim_date=item[\"date\"],\n",
    "#             sort=sort,\n",
    "#             known_info=False, # 不含已知信息\n",
    "#             ids=None \n",
    "#         )\n",
    "#         label = \"TRUE.\" if int(item[\"label\"]) == 2 else \"FALSE.\"\n",
    "#         dict_list.append({\"query\": prompt, \"response\": label})\n",
    "# print(dict_list[0][\"query\"])\n",
    "# len(dict_list), dict_list[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_dir = \"/home/hanlv/workspace/code/research/infodemic/LLM/\"\n",
    "# with jsonlines.open(\n",
    "#     LLM_dir + \\\n",
    "#     f\"swift/examples/pytorch/llm/my_data/with_{model_name}_info/{search_engine}/data{data_version}.jsonl\", mode=\"w\") as file_jsonl:\n",
    "#     for line in dict_list:\n",
    "#         file_jsonl.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型的先验知识生成效果：一次提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 04:42:57,056 - modelscope - INFO - PyTorch version 2.3.0 Found.\n",
      "2024-06-14 04:42:57,058 - modelscope - INFO - Loading ast index from /home/hanlv/.cache/modelscope/ast_indexer\n",
      "2024-06-14 04:42:57,093 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 21bc0b9ccf26bcf3f4ca2e675ec8875d and a total number of 980 components indexed\n",
      "[INFO:swift] Successfully registered `/home/hanlv/workspace/code/research/infodemic/LLM/swift/swift/llm/data/dataset_info.json`\n",
      "[INFO:swift] Loading the model using model_dir: /home/css/models/llama-3-70b-instruct-awq\n",
      "[INFO:swift] Setting torch_dtype: torch.float16\n",
      "[INFO:swift] model_config: LlamaConfig {\n",
      "  \"_name_or_path\": \"/home/css/models/llama-3-70b-instruct-awq\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 8192,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 28672,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 64,\n",
      "  \"num_hidden_layers\": 80,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"bits\": 4,\n",
      "    \"group_size\": 128,\n",
      "    \"modules_to_not_convert\": null,\n",
      "    \"quant_method\": \"awq\",\n",
      "    \"version\": \"gemm\",\n",
      "    \"zero_point\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 06-14 04:42:57 config.py:216] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 04:42:59,296\tINFO worker.py:1753 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-14 04:43:00 config.py:623] Defaulting to use mp for distributed inference\n",
      "INFO 06-14 04:43:00 llm_engine.py:161] Initializing an LLM engine (v0.5.0) with config: model='/home/css/models/llama-3-70b-instruct-awq', speculative_config=None, tokenizer='/home/css/models/llama-3-70b-instruct-awq', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=42, served_model_name=/home/css/models/llama-3-70b-instruct-awq)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:02 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 06-14 04:43:03 utils.py:623] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:03 utils.py:623] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:03 pynccl.py:65] vLLM is using nccl==2.20.5\n",
      "INFO 06-14 04:43:03 pynccl.py:65] vLLM is using nccl==2.20.5\n",
      "INFO 06-14 04:43:03 custom_all_reduce_utils.py:179] reading GPU P2P access cache from /home/hanlv/.config/vllm/gpu_p2p_access_cache_for_1,2.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:03 custom_all_reduce_utils.py:179] reading GPU P2P access cache from /home/hanlv/.config/vllm/gpu_p2p_access_cache_for_1,2.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m WARNING 06-14 04:43:03 custom_all_reduce.py:179] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 06-14 04:43:03 custom_all_reduce.py:179] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/multiprocessing/resource_tracker.py\", line 239, in main\n",
      "    cache[rtype].remove(name)\n",
      "KeyError: '/psm_0bff00e9'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:09 model_runner.py:159] Loading model weights took 18.5481 GB\n",
      "INFO 06-14 04:43:09 model_runner.py:159] Loading model weights took 18.5481 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:43:09,209 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171774976; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-14 04:43:13 distributed_gpu_executor.py:56] # GPU blocks: 590, # CPU blocks: 1638\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:15 model_runner.py:878] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:15 model_runner.py:882] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-14 04:43:15 model_runner.py:878] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-14 04:43:15 model_runner.py:882] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:43:19,217 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171721728; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:43:29,224 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171693056; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=3298961)\u001b[0;0m INFO 06-14 04:43:30 model_runner.py:954] Graph capturing finished in 14 secs.\n",
      "INFO 06-14 04:43:31 model_runner.py:954] Graph capturing finished in 16 secs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n",
    "\n",
    "dirs = [\"../..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "\n",
    "from swift.llm import (\n",
    "    ModelType, get_vllm_engine, get_default_template_type,\n",
    "    get_template, inference_vllm, VllmGenerationConfig\n",
    ")\n",
    "from custom import CustomModelType, CustomTemplateType\n",
    "\n",
    "# model_type = ModelType.mixtral_moe_7b_instruct\n",
    "\n",
    "model_type = CustomModelType.llama_3_70b_instruct_awq\n",
    "# model_type = CustomModelType.mixtral_moe_7b_instruct_awq\n",
    "# model_type = CustomModelType.solar_instruct_10_7b\n",
    "\n",
    "llm_engine = get_vllm_engine(\n",
    "    model_type, \n",
    "    # torch_dtype=torch.float16,  # 检查正确的数据类型！！！！\n",
    "    tensor_parallel_size=2,\n",
    "    max_model_len=4096,\n",
    "    # gpu_memory_utilization=0.92,\n",
    "    # model_id_or_path=\"/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\",\n",
    "    engine_kwargs = {\n",
    "        # \"enforce_eager\": True,\n",
    "        \"max_num_seqs\": 64,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "template_type = get_default_template_type(model_type)\n",
    "template = get_template(template_type, llm_engine.hf_tokenizer)\n",
    "\n",
    "generation_config = VllmGenerationConfig(\n",
    "    max_new_tokens=2048,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "get_resp_list = lambda request_list : inference_vllm(\n",
    "    llm_engine, template, request_list, \n",
    "    generation_config=generation_config, \n",
    "    use_tqdm=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] how are you [/INST] I'm just a computer program, so I don't have feelings or emotions. I simply exist to process inputs and provide outputs. How can I assist you today? Is there something you would like to talk about or a question you would like to ask? I'm here to help!</s>\n"
     ]
    }
   ],
   "source": [
    "# get_resp_list = lambda request_list : inference_vllm(\n",
    "#     llm_engine, template, request_list, \n",
    "#     generation_config=generation_config, \n",
    "#     use_tqdm=False, \n",
    "#     verbose=True, prompt_prefix=\"\", output_prefix=\"\"\n",
    "# )\n",
    "\n",
    "s = \"Information Summary:\\n\\nInformation 1, published on 2020-12-01, discusses a false claim about a Covid-19 vaccine having the ability to \\\"transfer genetic material\\\" and manipulate human genes. The claim was shared hundreds of times on Facebook, but experts, such as Dr. Kirsty Short, have confirmed that the mRNA vaccine cannot enter the human genome. Information 2, published on 2020-05-19, mentions false claims about a future Covid-19 vaccine genetically modifying humans. Information 3, with no specific publication date, states that Covid-19 vaccines do not change a person's genes and use messenger RNA or modified adenovirus to trigger an immune response. Information 4, published on 2023-11-01, reiterates that Covid-19 vaccines cannot alter a person's genome and debunks false claims about DNA contamination leading to harmful effects. Information 5, with no specific publication date, highlights the importance of monitoring and addressing vaccine misinformation to prevent vaccine hesitancy.\\n\\nRestated Claim:\\nOn 2020-12-01, experts refuted the false claim that a Covid-19 vaccine can manipulate human genes.\\n\\nGiven the information available, the claim is TRUE. The Covid-19 vaccines developed by Pfizer-BioNTech, Moderna, and Johnson & Johnson do not have the ability to manipulate human genes, as confirmed by various experts and sources. These vaccines either use messenger RNA or modified adenovirus to trigger an immune response, but they cannot alter human DNA.\"\n",
    "\n",
    "prompt_list = [\"how are you\"] * 1\n",
    "\n",
    "resp_list = get_resp_list([{'query': prompt} for prompt in prompt_list])\n",
    "\n",
    "# for resp in resp_list:\n",
    "#     print(resp[\"response\"])\n",
    "\n",
    "# print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\n",
      "\n",
      "INFORMATION:\n",
      "Information 1:\n",
      "Publication date: 2020-12-16\n",
      "Title: Fact check: A 2010 study on vaccines did not show that one in forty ...\n",
      "Content:\n",
      "A video posted on Facebook by an anti-lockdown activist, citing a 2010 vaccination study, claims that one in forty have “vaccine damage.” A doctor who worked on the study said that the claim in the video misinterpreted the study’s findings, which included medical events not related to vaccines.\n",
      "I’m sure that people who have a dead or damaged child as a result of vaccines think that too ... I’m sure they think they are an absolute scientific wonder that they have one less child, or that they now have a child who is now so completely disabled. Yeah, they are a scientific wonder. Of course, them instances are rare. Them instances are rare. No. They’re one in forty.\n",
      "I’m sure they think they are an absolute scientific wonder that they have one less child, or that they now have a child who is now so completely disabled. Yeah, they are a scientific wonder. Of course, them instances are rare. Them instances are rare. No. They’re one in forty. One in forty have vaccine damage according to a 2010 study”.\n",
      "For example, according to WHO reports, about one in every 500,000 live attenuated influenza vaccines given can cause an allergic reaction (here) while no evidence of severe reactions could be attributed to the hepatitis A (here) or HPV vaccines (here). False. The 2010 study did not show that one in forty vaccine recipients suffered “vaccine damage”, That study counted whether there had been medical events detected in the 30 days after a patient received a vaccine, and did not attempt to infer causal links.\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: Global impact of the first year of COVID-19 vaccination: a ...\n",
      "Content:\n",
      "COVID-19 <strong>vaccination</strong> has substantially altered the course of the pandemic, saving tens of millions of lives globally. However, inadequate access to <strong>vaccines</strong> <strong>in</strong> low-income countries has limited the impact in these settings, reinforcing the need for global <strong>vaccine</strong> equity and coverage.\n",
      "Information 3:\n",
      "Publication date: None\n",
      "Title: Historical Safety Concerns | Vaccine Safety | CDC\n",
      "Content:\n",
      "In 2014, CDC published a study on the association between 2009 H1N1 influenza vaccines, 2010/2011 seasonal influenza vaccines, and narcolepsy. The study found that vaccination was not associated with an increased risk for narcolepsy.\n",
      "Porcine circovirus (PCV) is a common virus found in pigs. In 2010, it was discovered that both rotavirus vaccines licensed in the U.S.- Rotarix and RotaTeq- contained PCV type 1. PCV1 is not known to cause disease in animals or humans. In fact, PCV is common in healthy pigs, and humans are routinely exposed to the virus by eating pork.\n",
      "H1N1 Influenza Vaccine and Narcolepsy - 2009 – 2010 · An increased risk of narcolepsy (a chronic sleep disorder) was found following vaccination with Pandemrix, a monovalent 2009 H1N1 influenza vaccine that was used in several European countries during the H1N1 influenza pandemic.\n",
      "Hmeljak J, Kern I, Cör A. No implication of Simian virus 40 in pathogenesis of malignant pleural mesothelioma in Slovenia. Tumori. 2010 Sep-Oct;96(5):667-73.https://www.ncbi.nlm.nih.gov/pubmed/21302609external icon\n",
      "Information 4:\n",
      "Publication date: 2020-02-11\n",
      "Title: Selected Adverse Events Reported after COVID-19 Vaccination | CDC\n",
      "Content:\n",
      "Rare instances of adverse events following COVID-19 vaccinations have been reported to the Vaccine Adverse Event Reporting System.\n",
      "Information 5:\n",
      "Publication date: None\n",
      "Title: The contribution of vaccination to global health: past, present ...\n",
      "Content:\n",
      "2. Allen A. 2007. Vaccine—the controversial story of medicine's greatest lifesaver. New York, NY: W.W. Norton & Co. [Google Scholar] 3. Weber TP. 2010. Alfred Russel Wallace and the antivaccination movement in Victorian England. Emerg. Infect. Dis. 16, 664–668.\n",
      "3. Weber TP. 2010. Alfred Russel Wallace and the antivaccination movement in Victorian England. Emerg. Infect. Dis. 16, 664–668. ( 10.3201/eid1604.090434) [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n",
      "11. Lu YJ, et al. 2010. GMP-grade pneumococcal whole-cell vaccine injected subcutaneously protects mice from nasphayngeal colonization and fatal aspiration-sepsis. Vaccine 28, 7468–7475. ( 10.1016/j.vaccine.2010.09.031) [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n",
      "\n",
      "CLAIM: \n",
      "Publication date: 2020-12-16\n",
      "Content: A 2010 study on vaccines did not show that one in forty were damaged by vaccination\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Summary:\n",
      "\n",
      "Information 1 discusses a Facebook video claiming that a 2010 study showed that one in forty people suffered \"vaccine damage.\" The claim is false, as the study did not attempt to infer causal links between vaccines and medical events. Information 2 highlights the global impact of COVID-19 vaccination, saving tens of millions of lives while emphasizing the need for global vaccine equity. Information 3 provides background on historical safety concerns related to vaccines, including a 2014 study on the association between 2009 H1N1 influenza vaccines and narcolepsy. Information 4 mentions rare instances of adverse events following COVID-19 vaccinations reported to the Vaccine Adverse Event Reporting System. Information 5 focuses on the contribution of vaccination to global health.\n",
      "\n",
      "Claim Restatement:\n",
      "A 2010 study on vaccines did not find evidence that one in forty people were damaged by vaccination.\n",
      "\n",
      "Judgment on Claim:\n",
      "\n",
      "The claim is TRUE based on Information 1, which states that a doctor involved in the 2010 study clarified that the study did not show a causal link between vaccines and medical events, and that the claim of one in forty people being damaged by vaccines is a misinterpretation of the study's findings. Additionally, Information 3 provides context on historical safety concerns related to vaccines, further supporting the claim's accuracy.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Information Summary:\\n\\nInformation 1 discusses a Facebook video claiming that a 2010 study showed that one in forty people suffered \"vaccine damage.\" The claim is false, as the study did not attempt to infer causal links between vaccines and medical events. Information 2 highlights the global impact of COVID-19 vaccination, saving tens of millions of lives while emphasizing the need for global vaccine equity. Information 3 provides background on historical safety concerns related to vaccines, including a 2014 study on the association between 2009 H1N1 influenza vaccines and narcolepsy. Information 4 mentions rare instances of adverse events following COVID-19 vaccinations reported to the Vaccine Adverse Event Reporting System. Information 5 focuses on the contribution of vaccination to global health.\\n\\nClaim Restatement:\\nA 2010 study on vaccines did not find evidence that one in forty people were damaged by vaccination.\\n\\nJudgment on Claim:\\n\\nThe claim is TRUE based on Information 1, which states that a doctor involved in the 2010 study clarified that the study did not show a causal link between vaccines and medical events, and that the claim of one in forty people being damaged by vaccines is a misinterpretation of the study\\'s findings. Additionally, Information 3 provides context on historical safety concerns related to vaccines, further supporting the claim\\'s accuracy.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prompt_for_generating_prior_knowledge(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    sort: 对search result 按时间进行排序\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # v1\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        # v2\n",
    "        # pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        \n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = \"CLAIM: \" + prompt_rag.get_claim_with_date(claim, claim_date)\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + info + text\n",
    "\n",
    "def get_claim_with_date(claim, claim_date=None):\n",
    "    if claim_date is None:\n",
    "        return \" \" + claim\n",
    "    \n",
    "    # res = \"\\n\"\n",
    "    res = claim + \"\\nPublication date: \" + claim_date\n",
    "    return res\n",
    "\n",
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_search)):\n",
    "        if claim.strip() in data_search[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "# i = 0\n",
    "i = get_id(\"False claim circulates that Pakistani plane transported Sri Lankan students home after COVID-19 lockdown\")\n",
    "\n",
    "claim = data_search[i][\"claim\"]\n",
    "search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "\n",
    "model_name = 'mixtral'\n",
    "prompt_list1 = [\n",
    "    get_prompt_for_generating_prior_knowledge(\n",
    "        claim, data_search[i][\"date\"], search_engine, search_results, model_name,\n",
    "        K=K, sort=False, \n",
    "        # ids=data_search[i][\"random_ids\"],\n",
    "        ids=None\n",
    "    ),\n",
    "]\n",
    "\n",
    "request_list1 = [{'query': prompt} for prompt in prompt_list1]\n",
    "\n",
    "print(prompt_list1[0])\n",
    "print()\n",
    "\n",
    "resp_list1 = get_resp_list(request_list1)\n",
    "print(resp_list1[0][\"response\"].strip())\n",
    "print()\n",
    "resp_list1[0][\"response\"].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.34s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:43:39,231 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171623424; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:43:49,238 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171598848; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:43:59,246 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171533312; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:44:09,252 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171222016; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:44:19,259 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171213824; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:44:29,267 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171185152; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:44:39,275 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171156480; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:44:49,282 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171127808; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:44:59,289 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46171078656; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:45:09,295 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46170787840; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-14 04:45:19,302 E 3295357 3295389] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-14_04-42-57_847038_3295011 is over 95% full, available space: 46170771456; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "def get_prompt_for_generating_prior_knowledge2(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    pre + info + text\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        # pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        \n",
    "        pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "    \n",
    "    elif model_name == \"llama3\":\n",
    "        # pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        if model_name == \"mixtral\":\n",
    "            text = \"<CLAIM>: \"\n",
    "        elif model_name == \"llama3\":\n",
    "            text = \"<CLAIM>: \"\n",
    "        text += get_claim_with_date(claim, claim_date)\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + info + text\n",
    "\n",
    "def get_prompt_for_generating_prior_knowledge1(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    pre + text + info\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "\n",
    "\n",
    "        pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        pre += \"CLAIM: \"\n",
    "\n",
    "        # pre = \"Below is a <CLAIM> and some INFORMATION searched online. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        # pre += \"<CLAIM>: \"\n",
    "\n",
    "    elif model_name == \"llama3\":\n",
    "\n",
    "        pre = \"Below is a <CLAIM> and some INFORMATION searched online. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        pre += \"<CLAIM>: \"\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = get_claim_with_date(claim, claim_date) + '\\n\\n'\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + text + info\n",
    "    \n",
    "def get_claim_with_date(claim, claim_date=None):\n",
    "    if claim_date is None:\n",
    "        return \" \" + claim\n",
    "    \n",
    "    # res = \"\\n\"\n",
    "    res = claim + \"\\nPublication date: \" + claim_date\n",
    "    return res\n",
    "\n",
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_search)):\n",
    "        if claim.strip() in data_search[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "# i = 0\n",
    "i = get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\")\n",
    "\n",
    "# ids = [194]\n",
    "ids1 = [19, 36, 57, 85, 98, 107, 116, 117, 125, 129, 194, 195, 204, 208, 212, 235, 279, 324, 328]\n",
    "# ids1 = [\n",
    "#     get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\"),\n",
    "#     get_id(\"Myth spreads online that Australian supermarkets have banned Chinese nationals during COVID-19 pandemic\"),\n",
    "#     get_id(\"Trump makes false claims about COVID-19 testing\"),\n",
    "#     get_id(\"UNHCR condemns fake notice which claimed refugees in Malaysia are resisting COVID-19 tests\"),\n",
    "#     get_id(\"Hospitals in Ohio were not set on fire during protests\"),\n",
    "#     get_id(\"A 2010 study on vaccines did not show that one in forty were damaged by vaccination\"),\n",
    "#     get_id(\"The Philippine health department said it did not issue this 'checklist' for COVID-19 symptoms\"),\n",
    "#     get_id(\"Contaminated CDC COVID-19 test kits recalled and did not spread virus\"),\n",
    "#     get_id(\"Experts refute false claim that Covid-19 vaccine can 'manipulate' human genes\"),\n",
    "#     get_id(\"Countries were not buying Covid-19 test kits in 2018\"),\n",
    "#     get_id(\"False claim circulates that Pakistani plane transported Sri Lankan students home after COVID-19 lockdown\"),\n",
    "#     get_id(\"People will not have to be vaccinated against COVID-19 to receive food stamps and rent assistance\"),\n",
    "#     get_id(\"Britain has not awarded a contract to develop a vaccine passport\"),\n",
    "#     get_id(\"World Health Organization says COVID-19 means ‘coronavirus disease 2019’ – not 'China outbreak virus'\"),\n",
    "#     get_id(\"The common cold is not the same as COVID-19 and the NHS is not saying it is\"),\n",
    "#     get_id(\"Philippine authorities did not issue this warning after the novel coronavirus outbreak\"),\n",
    "#     get_id(\"No tourists have been allowed to visit New Zealand since March 2020 -- this photo has circulated online since 2016\"),\n",
    "#     get_id(\"This video does not show social distancing failure on an Air India flight during the coronavirus pandemic\"),\n",
    "#     get_id(\"This photo shows a Sri Lankan airline pilot who tested positive for the novel coronavirus.\"), # fALSE\n",
    "# ]\n",
    "\n",
    "ids2 = [\n",
    "    get_id(\"Gynecological Cancers Not Tied to Severe COVID-19\"),\n",
    "    get_id(\"In February 2021, the Centers for Disease Control and Prevention (CDC) advised U.S. travelers to \\u201cavoid all travel to Mexico.\\u201d\"),\n",
    "    get_id(\"The U.S. CDC encourages the use of a \\u201c[COVID-19] flu shot\\u201d on children.\"),\n",
    "    get_id(\"An announcement was made on March 9 that all classes in the Basque Country were canceled due to the coronavirus.\"),\n",
    "    get_id(\"Rita Wilson, Tom Hanks’ wife, stated in an interview at CBS that “she wouldn’t be alive if not for chloroquine”\"),\n",
    "    get_id(\"Japan’s Nobel Prize winning Professor of Medicine, Professor Dr Tasuku Honjo has claimed that the coronavirus is not natural and that China manufactured it.\"),\n",
    "    get_id(\"Lies spread by Serbian authorities about COVID-19. For example, the virus does not affect pregnant women, children and young people; no newborn is infected with the coronavirus; the virus does not last long on objects; the number of respiratory machines that Serbia possesses, etc.\"),\n",
    "    get_id(\"Chief Secretary of West Bengal was not following relaxing while the state was performing poorly as it fought COVID-19.\"),\n",
    "    get_id(\"Businessman Ratan Tata has said that 2020 is the year to survive and not care about profits and losses.\"),\n",
    "    get_id(\"Celebrities spreading misinformation about coronavirus and the Janata curfew in India.\"),\n",
    "    get_id(\"This 3 year old girl is fighting for her life after getting the coronavirus.\"),\n",
    "    get_id(\"President Vucic claims that no one said coronavirus is the “funniest” virus.\"),\n",
    "    get_id(\"News photo from stay-at-home protest was doctored to add Confederate flag.\"),\n",
    "    get_id(\"President Donald Trump referred to the coronavirus as a “hoax” or “political conspiracy.”\"),\n",
    "    get_id(\"President Trump refers to the coronavirus as a hoax in an audio clip.\"),\n",
    "    get_id(\"A false image says that President Duque will declare a shutdown on November 1st.\"),\n",
    "    get_id(\"Professor Perronne makes several false claims on PCR tests, HCQ and hospitals.\"),\n",
    "    get_id(\"Audio of Biden calling the coronavirus a hoax.\"),\n",
    "    get_id(\"President Trump’s claim that he inherited no ventilators from the Obama administration.\"),\n",
    "    get_id(\"Video shows President Donald Trump saying COVID-19 is Democrats’ “new hoax.”\"),\n",
    "    get_id(\"Fauci Wasn't Involved in New Testing Guidelines\"),\n",
    "    get_id(\"This movie “Songbird” has been made before Covid. We’ve seen a lot of similar movies, yes. But, it is interesting that in the movie the virus is called COVID-23. Stop the scene when there is news on TV and you will see. Coincidence?\"),\n",
    "    get_id(\"Images of the newspaper front pages sharing vaccine misinformation\"),\n",
    "    get_id(\"I don't believe illegal casinos are operating in Bangkok, but if the doctor knows about it, he can inform the authorities.\"),\n",
    "    get_id(\"Facebook posts promote false conspiracy that coronavirus testing patent was submitted in 2015\"),\n",
    "    get_id(\"Misleading description of Canada\\u2019s quarantine sites feeds Covid-19 conspiracy\"),\n",
    "    get_id(\"Video repeats COVID-19 conspiracy theories\"),\n",
    "    get_id(\"The post contains a COVID-19 conspiracy theory written by former South Carolina Rep. Trey Gowdy.\"),\n",
    "    get_id(\"A long conspiracy video claims that: vaccines can alter a person’s DNA, nanorobots are inserted with the vaccine to collect biometric data, Bill Gates already owns this data and the body can receive 5G signal after the vaccine is taken\"),\n",
    "    get_id(\"Jorge Luis Sonnante published a 16-minute video that went viral on networks. In the video, Sonnante (who describes himself as a \\u201cdeacon\\u201d, but gives falsified evidence of this charge) mixes several conspiracy theories, some meaningless, others already denied, about the pandemic caused by the SARS coronavirus -CoV-2.\"),\n",
    "    get_id(\"Trump touts testing as \\\"greatest capacity in the world,\\\" but says people \\\"shouldn't want to get tested\\\"\"),\n",
    "    get_id(\"Alberto Fernández, about the coronavirus: “Mortality in people over 65 is 80%”.\"),\n",
    "    get_id(\"An English man received a COVID-19 vaccine through his shirt\"),\n",
    "    get_id(\"The first recipient of the COVID-19 trial vaccine is dead.\"),\n",
    "    get_id(\"ICUs are not overwhelmed\"),\n",
    "    get_id(\"Coronavirus tests do not work to diagnose COVID-19. Red Bull tests positive.\"),\n",
    "    get_id(\"Rapidly developed pharmaceuticals such as the Covid-19 vaccines compared to a sedative from the 1950s that caused serious birth defects.\"),\n",
    "    get_id(\"The major cause of death in Covid-19 is thrombosis or blood clot and not pneumonia.\"),\n",
    "    get_id(\"The COVID-19 virus was artificially created by the U.S. military and placed in a capsule.\"),\n",
    "    get_id(\"A video of a girl collapsing in a store is being shared widely on social media with a claim that the girl died of Coronavirus.\"),\n",
    "    get_id(\"Italy\\u2019s prime minister cries and declares that his country \\u201clost the battle\\u201d against the coronavirus.\"),\n",
    "    get_id(\"Black people are not being targeted for UK coronavirus vaccine trials\"),\n",
    "    get_id(\"In September 2019, a train named COVID-19 appeared in the United States, carrying gases that cause COVID-19.\"),\n",
    "    get_id(\"If you take the vaccine, you'll be enrolled in a pharmacovigilance tracking system. It means that you've enrolled yourself in a medical trial.\"),\n",
    "    get_id(\"Henry Kissinger quote about mandatory vaccinations\"),\n",
    "    get_id(\"RECEIVE FOOD AID SOCIAL PLAN 2020\"),\n",
    "    get_id(\"Post claims the video clip is last message of deceased Pakistani doctor Osama Riyaz who had contracted Coronavirus while treating patients\"),\n",
    "    get_id(\"For a few days now, an image has been circulating on Facebook claiming that COVID-19 can be cured with Dolex Gripa, \\\"Noraver\\\" night, and gargling with warm water and lemon.\"),\n",
    "    get_id(\"A magic remedy to prevent COVID-19: mix brown sugar, ginger, garlic, and Chinese leek, boil them and drink it.\"),\n",
    "    get_id(\"Some statements by the American political scientist and activist Susan George in which she says that “Spaniards are laboratory rats: let’s see how much punishment they tolerate without rebelling.” The phrase is shared related to the current coronavirus pandemic.\"),\n",
    "    get_id(\"Saddam Hussein explains what the coronavirus is.\"),\n",
    "    get_id(\"A Facebook post is spreading the false claim that former President Barack Obama gave $3.8 million to a lab in Wuhan, China.\"),\n",
    "    get_id(\"\\u2019No discrimination\\u2019 against Africans amid pandemic.\")\n",
    "]\n",
    "\n",
    "ids_x = [ids2[3],]\n",
    "\n",
    "prompt_list = []\n",
    "model_name = 'llama3'\n",
    "\n",
    "\n",
    "# [ids2[ii] for ii in ids_filtered]:\n",
    "for i in ids_x: \n",
    "    claim = data_search[i][\"claim\"]\n",
    "    search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "    prompt_list.append(get_prompt_for_generating_prior_knowledge2(\n",
    "            claim, data_search[i][\"date\"], search_engine, search_results, model_name,\n",
    "            K=K, sort=False, \n",
    "            # ids=data_search[i][\"random_ids\"],\n",
    "            ids=None\n",
    "        ))\n",
    "request_list = [{'query': prompt} for prompt in prompt_list]\n",
    "\n",
    "resp_list = get_resp_list(request_list)\n",
    "# print(resp_list[0][\"response\"].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "Here is a clear summary of the given INFORMATION:\n",
      "\n",
      "Information 1 (2020-03-09) reports that the Basque Country in northern Spain has been severely affected by the coronavirus, with nearly 150 confirmed cases and 24 deaths. As a result, all education activities in the city of Vitoria were suspended for two weeks, affecting tens of thousands of pupils.\n",
      "\n",
      "Information 2 (no publication date) mentions that the Tour of Romandy and Tour of the Basque Country, two cycling events, were cancelled due to the coronavirus pandemic.\n",
      "\n",
      "Information 3 (2020-03-16) states that the regional elections in the Basque Country and Galicia, originally scheduled for April 5, were postponed due to the coronavirus crisis.\n",
      "\n",
      "Information 4 (2024-06-06) provides general information about the Basque people, their history, and culture, but does not mention the coronavirus or any specific events related to the pandemic.\n",
      "\n",
      "Information 5 (no publication date) appears to be a webpage about the COVID-19 crisis in the Basque Country, but the content is not specific enough to provide any relevant information.\n",
      "\n",
      "Based on the available information, the <CLAIM> that an announcement was made on March 9 that all classes in the Basque Country were canceled due to the coronavirus is classified as TRUE. Information 1 confirms that on March 9, authorities in the Basque Country announced the closure of schools and universities in the region due to the spread of the coronavirus.\n"
     ]
    }
   ],
   "source": [
    "# llama-3-70b\n",
    "# CLAIM + info wrong: 1, 18\n",
    "# info + CLAIM wrong: 18\n",
    "\n",
    "# CLAIM + info wrong: 1, 2, 3, 7, 11, 15, 20, 30, 45, 51\n",
    "# info + CLAIM wrong: 1, 2, $3, 7, 11, 20, 45  √√√√√√√√√√√\n",
    "\n",
    "\n",
    "# mixtral-8x7b\n",
    "# claim wrong: 0, 1, 8, 10, 12 \n",
    "# <claim>:0, 1, 2\n",
    "\n",
    "# claim: 1, 2, 7, 15, 16, 18, 20, 24, 25, (27), 29, 30, (35), (46), (52)\n",
    "\n",
    "# <claim>: \n",
    "print(len(ids_x))\n",
    "nn = 0\n",
    "# print(prompt_list[nn])\n",
    "# print('*'*50)\n",
    "print(data_search[ids_x[nn]][\"label\"])\n",
    "print(resp_list[nn][\"response\"].strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
