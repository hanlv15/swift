{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import sys\n",
    "import prompt_rag\n",
    "\n",
    "search_engine = \"brave\"\n",
    "\n",
    "with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-2024/train_{search_engine}_search.json\", \"r\") as f:\n",
    "    data_search = json.load(f)\n",
    "\n",
    "try:\n",
    "    with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-2024/train_{search_engine}_search_llm.json\", \"r\") as f:\n",
    "        data_search_llm = json.load(f)\n",
    "except:\n",
    "    pass\n",
    "    # data_search_llm = [{\n",
    "    #     \"claim\": i[\"claim\"],\n",
    "    #     \"claimant\": i[\"claimant\"],\n",
    "    #     \"label\": i[\"label\"],\n",
    "    #     \"date\": i[\"date\"],\n",
    "    # } for i in data_search]\n",
    "    # with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"w\") as f:\n",
    "    #     json.dump(data_search_llm, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.update_train_search_llm( \n",
    "#     \"SOLAR-10.7B-Instruct-v1.0\", \"solar\", port=8001, \n",
    "#     data_search=data_search, data_search_llm=data_search_llm) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并多个文件的先验知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对prior_knowledge做修改\n",
    "# sort = False\n",
    "# prior_knowledge_list = []\n",
    "\n",
    "# K = 5\n",
    "# prior_knowledge_version = \"1\"\n",
    "# prior_knowledge_version_adjust = prior_knowledge_version + \".2\"\n",
    "# model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     prior_knowledge = item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"]\n",
    "    \n",
    "#     find_list = [\n",
    "#         \"Information Expansion and Summary:\",\n",
    "#         # \"Information Summary:\",\n",
    "#         # \"Expanded Information Summary:\",\n",
    "#         \"Claim Analysis:\",\n",
    "#         # \"Claim Verification\",\n",
    "#         # \"Claim Analysis and Judgement:\"\n",
    "#     ]\n",
    "\n",
    "\n",
    "#     for s in find_list:\n",
    "#         pos = prior_knowledge.find(s)\n",
    "#         if pos == -1:\n",
    "#             continue\n",
    "        \n",
    "#         num_extra = 2\n",
    "#         if pos!=0 and prior_knowledge[pos-1] == '\\n':\n",
    "#             pos -= 1\n",
    "#             num_extra += 1\n",
    "#         prior_knowledge = prior_knowledge[:pos] + prior_knowledge[pos + len(s) + num_extra :]\n",
    "\n",
    "  \n",
    "#     item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version_adjust}_K={K}\"] = prior_knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing search llm\n",
    "# v2: k = 5\n",
    "# v3: 不对时间排序\n",
    "\n",
    "# brave search llm\n",
    "\n",
    "# Solar\n",
    "# v1: k = 5\n",
    "# v2: k = 5 随机选取\n",
    "\n",
    "# Mixtral\n",
    "# v1: k = 5\n",
    "# v1.1: 删除结构化内容（Information Expansion and Summary、Claim Analysis）\n",
    "\n",
    "sort = False\n",
    "prior_knowledge_list = []\n",
    "\n",
    "K = 5\n",
    "prior_knowledge_version = \"1\"\n",
    "model_name = \"mixtral\"\n",
    "\n",
    "\n",
    "# with open(f\"train_search_llm_tmp.json\", \"r\") as f:\n",
    "#     prior_knowledge_list = json.load(f)\n",
    "\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "#     if item[\"claim\"] != prior_knowledge_list[i][\"claim\"].strip():\n",
    "#         print(i)\n",
    "#         print(item[\"claim\"])\n",
    "#         print(prior_knowledge_list[i][\"claim\"])\n",
    "#         raise Exception()\n",
    "#     else:\n",
    "#         # vv = \"\"\n",
    "#         # if prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}3\") is not None:\n",
    "#         #     vv = \"3\"\n",
    "#         # elif prior_knowledge_list[i].get(f\"prior_knowledge_{model_name}2\") is not None:\n",
    "#         #     vv = \"2\"\n",
    "\n",
    "#         item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"] = prior_knowledge_list[i][f\"prior_knowledge_{model_name}\"]\n",
    "\n",
    "# data_search_llm[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_rag.save_search_llm(data_search_llm, search_engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建数据（带有先验知识的Prompt）以微调LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list = []\n",
    "\n",
    "# data_version = \"2\"\n",
    "# for i, item in enumerate(data_search_llm):\n",
    "    \n",
    "#     if int(item[\"label\"]) != 1:\n",
    "#         prompt = prompt_rag.get_prompt_with_prior_knowledge(\n",
    "#             item[\"claim\"], \n",
    "#             search_engine,\n",
    "#             data_search[i][f\"{search_engine}_search_results\"], \n",
    "#             item[f\"prior_knowledge_{model_name}_v{prior_knowledge_version}_K={K}\"], \n",
    "#             K=K,\n",
    "#             claim_date=item[\"date\"],\n",
    "#             sort=sort,\n",
    "#             known_info=False, # 不含已知信息\n",
    "#             ids=None \n",
    "#         )\n",
    "#         label = \"TRUE.\" if int(item[\"label\"]) == 2 else \"FALSE.\"\n",
    "#         dict_list.append({\"query\": prompt, \"response\": label})\n",
    "# print(dict_list[0][\"query\"])\n",
    "# len(dict_list), dict_list[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_dir = \"/home/hanlv/workspace/code/research/infodemic/LLM/\"\n",
    "# with jsonlines.open(\n",
    "#     LLM_dir + \\\n",
    "#     f\"swift/examples/pytorch/llm/my_data/with_{model_name}_info/{search_engine}/data{data_version}.jsonl\", mode=\"w\") as file_jsonl:\n",
    "#     for line in dict_list:\n",
    "#         file_jsonl.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型的先验知识生成效果：一次提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 17:49:53,589 - modelscope - INFO - PyTorch version 2.3.0 Found.\n",
      "2024-06-12 17:49:53,591 - modelscope - INFO - Loading ast index from /home/hanlv/.cache/modelscope/ast_indexer\n",
      "2024-06-12 17:49:53,616 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 51e6103eebe44a6d184c658bbd52ad08 and a total number of 980 components indexed\n",
      "[INFO:swift] Successfully registered `/home/hanlv/workspace/code/research/infodemic/LLM/swift/swift/llm/data/dataset_info.json`\n",
      "[INFO:swift] Loading the model using model_dir: /home/css/models/llama-3-70b-instruct-awq\n",
      "[INFO:swift] Setting torch_dtype: torch.float16\n",
      "[INFO:swift] model_config: LlamaConfig {\n",
      "  \"_name_or_path\": \"/home/css/models/llama-3-70b-instruct-awq\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 8192,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 28672,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 64,\n",
      "  \"num_hidden_layers\": 80,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"bits\": 4,\n",
      "    \"group_size\": 128,\n",
      "    \"modules_to_not_convert\": null,\n",
      "    \"quant_method\": \"awq\",\n",
      "    \"version\": \"gemm\",\n",
      "    \"zero_point\": true\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 06-12 17:49:54 config.py:213] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 17:49:56,973\tINFO worker.py:1749 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-12 17:49:58 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='/home/css/models/llama-3-70b-instruct-awq', speculative_config=None, tokenizer='/home/css/models/llama-3-70b-instruct-awq', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=42, served_model_name=/home/css/models/llama-3-70b-instruct-awq)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-12 17:50:03 utils.py:618] Found nccl from library libnccl.so.2\n",
      "INFO 06-12 17:50:03 pynccl.py:65] vLLM is using nccl==2.20.5\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m INFO 06-12 17:50:03 utils.py:618] Found nccl from library libnccl.so.2\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m INFO 06-12 17:50:03 pynccl.py:65] vLLM is using nccl==2.20.5\n",
      "INFO 06-12 17:50:03 custom_all_reduce_utils.py:179] reading GPU P2P access cache from /home/hanlv/.config/vllm/gpu_p2p_access_cache_for_1,2.json\n",
      "WARNING 06-12 17:50:03 custom_all_reduce.py:167] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m INFO 06-12 17:50:03 custom_all_reduce_utils.py:179] reading GPU P2P access cache from /home/hanlv/.config/vllm/gpu_p2p_access_cache_for_1,2.json\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m WARNING 06-12 17:50:03 custom_all_reduce.py:167] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 17:50:06,872 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861948416; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-12 17:50:09 model_runner.py:146] Loading model weights took 18.5481 GB\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m INFO 06-12 17:50:13 model_runner.py:146] Loading model weights took 18.5481 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 17:50:16,883 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861874688; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-12 17:50:17 distributed_gpu_executor.py:56] # GPU blocks: 590, # CPU blocks: 1638\n",
      "INFO 06-12 17:50:20 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-12 17:50:20 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m INFO 06-12 17:50:20 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m INFO 06-12 17:50:20 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 17:50:26,893 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861833728; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m INFO 06-12 17:50:28 model_runner.py:924] Graph capturing finished in 7 secs.\n",
      "INFO 06-12 17:50:28 model_runner.py:924] Graph capturing finished in 8 secs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148] Error executing method start_worker_execution_loop. This might cause deadlock in distributed execution.\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148] Traceback (most recent call last):\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/worker/worker_base.py\", line 140, in execute_method\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     return executor(*args, **kwargs)\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     return func(*args, **kwargs)\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/worker/worker.py\", line 286, in start_worker_execution_loop\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     while self._execute_model_non_driver():\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/worker/worker.py\", line 295, in _execute_model_non_driver\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     data = broadcast_tensor_dict(src=0)\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/distributed/communication_op.py\", line 284, in broadcast_tensor_dict\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     torch.distributed.broadcast_object_list(recv_metadata_list,\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     return func(*args, **kwargs)\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 2649, in broadcast_object_list\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     broadcast(object_sizes_tensor, src=src, group=group)\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     return func(*args, **kwargs)\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]   File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 2144, in broadcast\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148]     work.wait()\n",
      "\u001b[36m(RayWorkerWrapper pid=2812629)\u001b[0m ERROR 06-12 18:26:55 worker_base.py:148] RuntimeError: [../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 1800000ms for recv operation to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:26:59,389 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31841177600; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:27:09,402 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31841136640; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:27:19,414 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31841107968; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:27:29,425 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31841075200; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:27:39,435 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31841050624; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:27:49,446 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31841026048; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:27:59,457 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840616448; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:28:09,468 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840591872; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:28:19,478 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840563200; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:28:29,490 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840526336; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:28:39,501 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840501760; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:28:49,511 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840460800; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:28:59,521 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840108544; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:29:09,534 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840079872; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:29:19,546 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31840038912; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:29:29,557 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31839993856; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:29:39,568 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31865683968; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:29:49,578 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31865659392; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:29:59,589 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31865069568; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:30:09,600 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31865020416; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:30:19,611 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864975360; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:30:29,621 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864958976; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:30:39,633 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864930304; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:30:49,644 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864889344; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:30:59,655 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864528896; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:31:09,665 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864479744; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:31:19,676 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864463360; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:31:29,686 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864414208; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:31:39,697 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864385536; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:31:49,708 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31864356864; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:31:59,720 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863988224; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:32:09,731 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863930880; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:32:19,743 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863894016; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:32:29,754 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863861248; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:32:39,766 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863824384; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:32:49,777 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863799808; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:32:59,787 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863189504; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:33:09,799 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863156736; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:33:19,811 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863107584; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:33:29,823 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863087104; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:33:39,835 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863066624; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:33:49,846 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31863021568; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:33:59,857 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31862636544; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:34:09,867 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31862603776; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:34:19,879 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31862583296; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:34:29,892 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31862534144; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:34:39,904 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31862480896; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:34:49,915 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31862456320; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:34:59,926 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31862013952; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:35:09,938 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861960704; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:35:19,949 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861936128; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:35:29,960 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861891072; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:35:39,971 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861846016; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:35:49,982 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861792768; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:35:59,994 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861260288; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:36:10,004 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861202944; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:36:20,016 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861178368; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:36:30,027 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861129216; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:36:40,038 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861104640; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:36:50,050 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31861059584; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:37:00,062 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31860723712; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:37:10,072 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31860674560; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:37:20,084 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31860654080; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:37:30,096 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31860596736; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:37:40,107 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31860576256; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:37:50,120 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31860506624; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:38:00,140 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31859232768; capacity: 1967317549056. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-12 18:38:10,152 E 2808937 2808969] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-06-12_17-49-54_569498_2808528 is over 95% full, available space: 31859183616; capacity: 1967317549056. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n",
    "\n",
    "dirs = [\"../..\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "\n",
    "from swift.llm import (\n",
    "    ModelType, get_vllm_engine, get_default_template_type,\n",
    "    get_template, inference_vllm, VllmGenerationConfig\n",
    ")\n",
    "from custom import CustomModelType, CustomTemplateType\n",
    "\n",
    "# model_type = ModelType.mixtral_moe_7b_instruct\n",
    "\n",
    "model_type = CustomModelType.llama_3_70b_instruct_awq\n",
    "# model_type = CustomModelType.mixtral_moe_7b_instruct_gptq_int4\n",
    "# model_type = CustomModelType.solar_instruct_10_7b\n",
    "\n",
    "llm_engine = get_vllm_engine(\n",
    "    model_type, \n",
    "    # torch_dtype=torch.float16,  # 检查正确的数据类型！！！！\n",
    "    tensor_parallel_size=2,\n",
    "    max_model_len=4096,\n",
    "    # gpu_memory_utilization=0.92,\n",
    "    # model_id_or_path=\"/home/css/models/Mixtral-8x7B-Instruct-v0.1-GPTQ-int4\",\n",
    "    engine_kwargs = {\n",
    "        # \"enforce_eager\": True,\n",
    "        \"max_num_seqs\": 64,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "template_type = get_default_template_type(model_type)\n",
    "template = get_template(template_type, llm_engine.hf_tokenizer)\n",
    "\n",
    "generation_config = VllmGenerationConfig(\n",
    "    max_new_tokens=2048,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "get_resp_list = lambda request_list : inference_vllm(\n",
    "    llm_engine, template, request_list, \n",
    "    generation_config=generation_config, \n",
    "    use_tqdm=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Information Summary:\\n\\nInformation 1, published on 2020-12-01, discusses a false claim about a Covid-19 vaccine having the ability to \\\"transfer genetic material\\\" and manipulate human genes. The claim was shared hundreds of times on Facebook, but experts, such as Dr. Kirsty Short, have confirmed that the mRNA vaccine cannot enter the human genome. Information 2, published on 2020-05-19, mentions false claims about a future Covid-19 vaccine genetically modifying humans. Information 3, with no specific publication date, states that Covid-19 vaccines do not change a person's genes and use messenger RNA or modified adenovirus to trigger an immune response. Information 4, published on 2023-11-01, reiterates that Covid-19 vaccines cannot alter a person's genome and debunks false claims about DNA contamination leading to harmful effects. Information 5, with no specific publication date, highlights the importance of monitoring and addressing vaccine misinformation to prevent vaccine hesitancy.\\n\\nRestated Claim:\\nOn 2020-12-01, experts refuted the false claim that a Covid-19 vaccine can manipulate human genes.\\n\\nGiven the information available, the claim is TRUE. The Covid-19 vaccines developed by Pfizer-BioNTech, Moderna, and Johnson & Johnson do not have the ability to manipulate human genes, as confirmed by various experts and sources. These vaccines either use messenger RNA or modified adenovirus to trigger an immune response, but they cannot alter human DNA.\"\n",
    "\n",
    "prompt_list = [\"how are you\"] * 10\n",
    "\n",
    "# resp_list = get_resp_list([{'query': prompt} for prompt in prompt_list])\n",
    "\n",
    "# for resp in resp_list:\n",
    "#     print(resp[\"response\"])\n",
    "\n",
    "# print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\n",
      "\n",
      "INFORMATION:\n",
      "Information 1:\n",
      "Publication date: 2020-12-16\n",
      "Title: Fact check: A 2010 study on vaccines did not show that one in forty ...\n",
      "Content:\n",
      "A video posted on Facebook by an anti-lockdown activist, citing a 2010 vaccination study, claims that one in forty have “vaccine damage.” A doctor who worked on the study said that the claim in the video misinterpreted the study’s findings, which included medical events not related to vaccines.\n",
      "I’m sure that people who have a dead or damaged child as a result of vaccines think that too ... I’m sure they think they are an absolute scientific wonder that they have one less child, or that they now have a child who is now so completely disabled. Yeah, they are a scientific wonder. Of course, them instances are rare. Them instances are rare. No. They’re one in forty.\n",
      "I’m sure they think they are an absolute scientific wonder that they have one less child, or that they now have a child who is now so completely disabled. Yeah, they are a scientific wonder. Of course, them instances are rare. Them instances are rare. No. They’re one in forty. One in forty have vaccine damage according to a 2010 study”.\n",
      "For example, according to WHO reports, about one in every 500,000 live attenuated influenza vaccines given can cause an allergic reaction (here) while no evidence of severe reactions could be attributed to the hepatitis A (here) or HPV vaccines (here). False. The 2010 study did not show that one in forty vaccine recipients suffered “vaccine damage”, That study counted whether there had been medical events detected in the 30 days after a patient received a vaccine, and did not attempt to infer causal links.\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: Global impact of the first year of COVID-19 vaccination: a ...\n",
      "Content:\n",
      "COVID-19 <strong>vaccination</strong> has substantially altered the course of the pandemic, saving tens of millions of lives globally. However, inadequate access to <strong>vaccines</strong> <strong>in</strong> low-income countries has limited the impact in these settings, reinforcing the need for global <strong>vaccine</strong> equity and coverage.\n",
      "Information 3:\n",
      "Publication date: None\n",
      "Title: Historical Safety Concerns | Vaccine Safety | CDC\n",
      "Content:\n",
      "In 2014, CDC published a study on the association between 2009 H1N1 influenza vaccines, 2010/2011 seasonal influenza vaccines, and narcolepsy. The study found that vaccination was not associated with an increased risk for narcolepsy.\n",
      "Porcine circovirus (PCV) is a common virus found in pigs. In 2010, it was discovered that both rotavirus vaccines licensed in the U.S.- Rotarix and RotaTeq- contained PCV type 1. PCV1 is not known to cause disease in animals or humans. In fact, PCV is common in healthy pigs, and humans are routinely exposed to the virus by eating pork.\n",
      "H1N1 Influenza Vaccine and Narcolepsy - 2009 – 2010 · An increased risk of narcolepsy (a chronic sleep disorder) was found following vaccination with Pandemrix, a monovalent 2009 H1N1 influenza vaccine that was used in several European countries during the H1N1 influenza pandemic.\n",
      "Hmeljak J, Kern I, Cör A. No implication of Simian virus 40 in pathogenesis of malignant pleural mesothelioma in Slovenia. Tumori. 2010 Sep-Oct;96(5):667-73.https://www.ncbi.nlm.nih.gov/pubmed/21302609external icon\n",
      "Information 4:\n",
      "Publication date: 2020-02-11\n",
      "Title: Selected Adverse Events Reported after COVID-19 Vaccination | CDC\n",
      "Content:\n",
      "Rare instances of adverse events following COVID-19 vaccinations have been reported to the Vaccine Adverse Event Reporting System.\n",
      "Information 5:\n",
      "Publication date: None\n",
      "Title: The contribution of vaccination to global health: past, present ...\n",
      "Content:\n",
      "2. Allen A. 2007. Vaccine—the controversial story of medicine's greatest lifesaver. New York, NY: W.W. Norton & Co. [Google Scholar] 3. Weber TP. 2010. Alfred Russel Wallace and the antivaccination movement in Victorian England. Emerg. Infect. Dis. 16, 664–668.\n",
      "3. Weber TP. 2010. Alfred Russel Wallace and the antivaccination movement in Victorian England. Emerg. Infect. Dis. 16, 664–668. ( 10.3201/eid1604.090434) [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n",
      "11. Lu YJ, et al. 2010. GMP-grade pneumococcal whole-cell vaccine injected subcutaneously protects mice from nasphayngeal colonization and fatal aspiration-sepsis. Vaccine 28, 7468–7475. ( 10.1016/j.vaccine.2010.09.031) [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n",
      "\n",
      "CLAIM: \n",
      "Publication date: 2020-12-16\n",
      "Content: A 2010 study on vaccines did not show that one in forty were damaged by vaccination\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Summary:\n",
      "\n",
      "Information 1 discusses a Facebook video claiming that a 2010 study showed that one in forty people suffered \"vaccine damage.\" The claim is false, as the study did not attempt to infer causal links between vaccines and medical events. Information 2 highlights the global impact of COVID-19 vaccination, saving tens of millions of lives while emphasizing the need for global vaccine equity. Information 3 provides background on historical safety concerns related to vaccines, including a 2014 study on the association between 2009 H1N1 influenza vaccines and narcolepsy. Information 4 mentions rare instances of adverse events following COVID-19 vaccinations reported to the Vaccine Adverse Event Reporting System. Information 5 focuses on the contribution of vaccination to global health.\n",
      "\n",
      "Claim Restatement:\n",
      "A 2010 study on vaccines did not find evidence that one in forty people were damaged by vaccination.\n",
      "\n",
      "Judgment on Claim:\n",
      "\n",
      "The claim is TRUE based on Information 1, which states that a doctor involved in the 2010 study clarified that the study did not show a causal link between vaccines and medical events, and that the claim of one in forty people being damaged by vaccines is a misinterpretation of the study's findings. Additionally, Information 3 provides context on historical safety concerns related to vaccines, further supporting the claim's accuracy.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Information Summary:\\n\\nInformation 1 discusses a Facebook video claiming that a 2010 study showed that one in forty people suffered \"vaccine damage.\" The claim is false, as the study did not attempt to infer causal links between vaccines and medical events. Information 2 highlights the global impact of COVID-19 vaccination, saving tens of millions of lives while emphasizing the need for global vaccine equity. Information 3 provides background on historical safety concerns related to vaccines, including a 2014 study on the association between 2009 H1N1 influenza vaccines and narcolepsy. Information 4 mentions rare instances of adverse events following COVID-19 vaccinations reported to the Vaccine Adverse Event Reporting System. Information 5 focuses on the contribution of vaccination to global health.\\n\\nClaim Restatement:\\nA 2010 study on vaccines did not find evidence that one in forty people were damaged by vaccination.\\n\\nJudgment on Claim:\\n\\nThe claim is TRUE based on Information 1, which states that a doctor involved in the 2010 study clarified that the study did not show a causal link between vaccines and medical events, and that the claim of one in forty people being damaged by vaccines is a misinterpretation of the study\\'s findings. Additionally, Information 3 provides context on historical safety concerns related to vaccines, further supporting the claim\\'s accuracy.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prompt_for_generating_prior_knowledge(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    sort: 对search result 按时间进行排序\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # v1\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        # v2\n",
    "        # pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        \n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = \"CLAIM: \" + prompt_rag.get_claim_with_date(claim, claim_date)\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + info + text\n",
    "\n",
    "def get_claim_with_date(claim, claim_date=None):\n",
    "    if claim_date is None:\n",
    "        return \" \" + claim\n",
    "    \n",
    "    # res = \"\\n\"\n",
    "    res = claim + \"\\nPublication date: \" + claim_date\n",
    "    return res\n",
    "\n",
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_search)):\n",
    "        if claim.strip() in data_search[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "# i = 0\n",
    "i = get_id(\"False claim circulates that Pakistani plane transported Sri Lankan students home after COVID-19 lockdown\")\n",
    "\n",
    "claim = data_search[i][\"claim\"]\n",
    "search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "\n",
    "model_name = 'mixtral'\n",
    "prompt_list1 = [\n",
    "    get_prompt_for_generating_prior_knowledge(\n",
    "        claim, data_search[i][\"date\"], search_engine, search_results, model_name,\n",
    "        K=K, sort=False, \n",
    "        # ids=data_search[i][\"random_ids\"],\n",
    "        ids=None\n",
    "    ),\n",
    "]\n",
    "\n",
    "request_list1 = [{'query': prompt} for prompt in prompt_list1]\n",
    "\n",
    "print(prompt_list1[0])\n",
    "print()\n",
    "\n",
    "resp_list1 = get_resp_list(request_list1)\n",
    "print(resp_list1[0][\"response\"].strip())\n",
    "print()\n",
    "resp_list1[0][\"response\"].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:19<00:00, 19.73s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_prompt_for_generating_prior_knowledge2(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    pre + info + text\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "        # pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a detailed summary of the given INFORMATION and restate the CLAIM. Then reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge. In reasoning, it is necessary to consider the sequential relationship between the date of publication of the CLAIM and the date of publication of the INFORMATION.\\n\\n\"\n",
    "    elif model_name == \"llama3\":\n",
    "        pre = \"Below is some INFORMATION searched online and a <CLAIM>. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = \"<CLAIM>: \" + get_claim_with_date(claim, claim_date)\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet + '\\n'\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + info + text\n",
    "\n",
    "def get_prompt_for_generating_prior_knowledge1(\n",
    "        claim, claim_date, search_engine, search_results, model_name,\n",
    "        K=5, sort=False, ids=None, without_info=False, without_claim_date=False):\n",
    "    \"\"\"\n",
    "    pre + text + info\n",
    "    \"\"\"\n",
    "\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if model_name == \"solar\":\n",
    "        pre = \"Below is some INFORMATION searched online and a CLAIM. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first expand on the given INFORMATION and provide a detailed summary of it. Then analyze, reason, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge, and finally generate prior knowledge that helps classify the CLAIM.\\n\\n\"\n",
    "    elif model_name == \"mixtral\":\n",
    "\n",
    "\n",
    "        pre = \"Below is a CLAIM and some INFORMATION searched online. These pieces of INFORMATION are relevant to the CLAIM. This CLAIM and all INFORMATION include their respective publication dates and contents. To classify the CLAIM more accurately (if the content described by the CLAIM is correct, it will be classified as TRUE; if the content described by the CLAIM is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the CLAIM, and provide reasonable evidence to judge the correctness of the CLAIM based on the available information and your knowledge.\\n\\n\"\n",
    "        pre += \"CLAIM: \"\n",
    "\n",
    "        # pre = \"Below is a <CLAIM> and some INFORMATION searched online. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        # pre += \"<CLAIM>: \"\n",
    "\n",
    "    elif model_name == \"llama3\":\n",
    "\n",
    "        pre = \"Below is a <CLAIM> and some INFORMATION searched online. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\\n\\n\"\n",
    "        pre += \"<CLAIM>: \"\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"model_name 只能从solar，mixtral中选择\")\n",
    "    \n",
    "    if without_claim_date:\n",
    "        text = \"CLAIM: \" + claim\n",
    "    else:\n",
    "        text = get_claim_with_date(claim, claim_date) + '\\n\\n'\n",
    "\n",
    "    if search_engine == \"bing\":\n",
    "        snippet = prompt_rag.get_bing_snippet_v2(search_results, K=K, claim_date=claim_date, sort=sort)\n",
    "    elif search_engine == \"brave\":\n",
    "        if ids is None:\n",
    "            ids = slice(0, K)\n",
    "        snippet = prompt_rag.get_brave_snippet(search_results, ids=ids)\n",
    "    else:\n",
    "        raise Exception(\"Select search engines in [\\\"bing\\\", \\\"brave\\\"].\")\n",
    "    \n",
    "    info = \"INFORMATION:\\n\" + snippet\n",
    "\n",
    "    if without_info:\n",
    "        return (pre + text).strip()\n",
    "    else:\n",
    "        return pre + text + info\n",
    "    \n",
    "def get_claim_with_date(claim, claim_date=None):\n",
    "    if claim_date is None:\n",
    "        return \" \" + claim\n",
    "    \n",
    "    # res = \"\\n\"\n",
    "    res = claim + \"\\nPublication date: \" + claim_date\n",
    "    return res\n",
    "\n",
    "K = 5\n",
    "def get_id(claim):\n",
    "    for i in range(len(data_search)):\n",
    "        if claim.strip() in data_search[i][\"claim\"].strip():\n",
    "            return i\n",
    "\n",
    "# i = 0\n",
    "i = get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\")\n",
    "\n",
    "# ids = [194]\n",
    "ids1 = [19, 36, 57, 85, 98, 107, 116, 117, 125, 129, 194, 195, 204, 208, 212, 235, 279, 324, 328]\n",
    "# ids1 = [\n",
    "#     get_id(\"Pfizer and Moderna do call their COVID-19 shot a ‘vaccine’\"),\n",
    "#     get_id(\"Myth spreads online that Australian supermarkets have banned Chinese nationals during COVID-19 pandemic\"),\n",
    "#     get_id(\"Trump makes false claims about COVID-19 testing\"),\n",
    "#     get_id(\"UNHCR condemns fake notice which claimed refugees in Malaysia are resisting COVID-19 tests\"),\n",
    "#     get_id(\"Hospitals in Ohio were not set on fire during protests\"),\n",
    "#     get_id(\"A 2010 study on vaccines did not show that one in forty were damaged by vaccination\"),\n",
    "#     get_id(\"The Philippine health department said it did not issue this 'checklist' for COVID-19 symptoms\"),\n",
    "#     get_id(\"Contaminated CDC COVID-19 test kits recalled and did not spread virus\"),\n",
    "#     get_id(\"Experts refute false claim that Covid-19 vaccine can 'manipulate' human genes\"),\n",
    "#     get_id(\"Countries were not buying Covid-19 test kits in 2018\"),\n",
    "#     get_id(\"False claim circulates that Pakistani plane transported Sri Lankan students home after COVID-19 lockdown\"),\n",
    "#     get_id(\"People will not have to be vaccinated against COVID-19 to receive food stamps and rent assistance\"),\n",
    "#     get_id(\"Britain has not awarded a contract to develop a vaccine passport\"),\n",
    "#     get_id(\"World Health Organization says COVID-19 means ‘coronavirus disease 2019’ – not 'China outbreak virus'\"),\n",
    "#     get_id(\"The common cold is not the same as COVID-19 and the NHS is not saying it is\"),\n",
    "#     get_id(\"Philippine authorities did not issue this warning after the novel coronavirus outbreak\"),\n",
    "#     get_id(\"No tourists have been allowed to visit New Zealand since March 2020 -- this photo has circulated online since 2016\"),\n",
    "#     get_id(\"This video does not show social distancing failure on an Air India flight during the coronavirus pandemic\"),\n",
    "#     get_id(\"This photo shows a Sri Lankan airline pilot who tested positive for the novel coronavirus.\"), # fALSE\n",
    "# ]\n",
    "\n",
    "ids2 = [\n",
    "    get_id(\"Gynecological Cancers Not Tied to Severe COVID-19\"),\n",
    "    get_id(\"In February 2021, the Centers for Disease Control and Prevention (CDC) advised U.S. travelers to \\u201cavoid all travel to Mexico.\\u201d\"),\n",
    "    get_id(\"The U.S. CDC encourages the use of a \\u201c[COVID-19] flu shot\\u201d on children.\"),\n",
    "    get_id(\"An announcement was made on March 9 that all classes in the Basque Country were canceled due to the coronavirus.\"),\n",
    "    get_id(\"Rita Wilson, Tom Hanks’ wife, stated in an interview at CBS that “she wouldn’t be alive if not for chloroquine”\"),\n",
    "    get_id(\"Japan’s Nobel Prize winning Professor of Medicine, Professor Dr Tasuku Honjo has claimed that the coronavirus is not natural and that China manufactured it.\"),\n",
    "    get_id(\"Lies spread by Serbian authorities about COVID-19. For example, the virus does not affect pregnant women, children and young people; no newborn is infected with the coronavirus; the virus does not last long on objects; the number of respiratory machines that Serbia possesses, etc.\"),\n",
    "    get_id(\"Chief Secretary of West Bengal was not following relaxing while the state was performing poorly as it fought COVID-19.\"),\n",
    "    get_id(\"Businessman Ratan Tata has said that 2020 is the year to survive and not care about profits and losses.\"),\n",
    "    get_id(\"Celebrities spreading misinformation about coronavirus and the Janata curfew in India.\"),\n",
    "    get_id(\"This 3 year old girl is fighting for her life after getting the coronavirus.\"),\n",
    "    get_id(\"President Vucic claims that no one said coronavirus is the “funniest” virus.\"),\n",
    "    get_id(\"News photo from stay-at-home protest was doctored to add Confederate flag.\"),\n",
    "    get_id(\"President Donald Trump referred to the coronavirus as a “hoax” or “political conspiracy.”\"),\n",
    "    get_id(\"President Trump refers to the coronavirus as a hoax in an audio clip.\"),\n",
    "    get_id(\"A false image says that President Duque will declare a shutdown on November 1st.\"),\n",
    "    get_id(\"Professor Perronne makes several false claims on PCR tests, HCQ and hospitals.\"),\n",
    "    get_id(\"Audio of Biden calling the coronavirus a hoax.\"),\n",
    "    get_id(\"President Trump’s claim that he inherited no ventilators from the Obama administration.\"),\n",
    "    get_id(\"Video shows President Donald Trump saying COVID-19 is Democrats’ “new hoax.”\"),\n",
    "    get_id(\"Fauci Wasn't Involved in New Testing Guidelines\"),\n",
    "    get_id(\"This movie “Songbird” has been made before Covid. We’ve seen a lot of similar movies, yes. But, it is interesting that in the movie the virus is called COVID-23. Stop the scene when there is news on TV and you will see. Coincidence?\"),\n",
    "    get_id(\"Images of the newspaper front pages sharing vaccine misinformation\"),\n",
    "    get_id(\"I don't believe illegal casinos are operating in Bangkok, but if the doctor knows about it, he can inform the authorities.\"),\n",
    "    get_id(\"Facebook posts promote false conspiracy that coronavirus testing patent was submitted in 2015\"),\n",
    "    get_id(\"Misleading description of Canada\\u2019s quarantine sites feeds Covid-19 conspiracy\"),\n",
    "    get_id(\"Video repeats COVID-19 conspiracy theories\"),\n",
    "    get_id(\"The post contains a COVID-19 conspiracy theory written by former South Carolina Rep. Trey Gowdy.\"),\n",
    "    get_id(\"A long conspiracy video claims that: vaccines can alter a person’s DNA, nanorobots are inserted with the vaccine to collect biometric data, Bill Gates already owns this data and the body can receive 5G signal after the vaccine is taken\"),\n",
    "    get_id(\"Jorge Luis Sonnante published a 16-minute video that went viral on networks. In the video, Sonnante (who describes himself as a \\u201cdeacon\\u201d, but gives falsified evidence of this charge) mixes several conspiracy theories, some meaningless, others already denied, about the pandemic caused by the SARS coronavirus -CoV-2.\"),\n",
    "    get_id(\"Trump touts testing as \\\"greatest capacity in the world,\\\" but says people \\\"shouldn't want to get tested\\\"\"),\n",
    "    get_id(\"Alberto Fernández, about the coronavirus: “Mortality in people over 65 is 80%”.\"),\n",
    "    get_id(\"An English man received a COVID-19 vaccine through his shirt\"),\n",
    "    get_id(\"The first recipient of the COVID-19 trial vaccine is dead.\"),\n",
    "    get_id(\"ICUs are not overwhelmed\"),\n",
    "    get_id(\"Coronavirus tests do not work to diagnose COVID-19. Red Bull tests positive.\"),\n",
    "    get_id(\"Rapidly developed pharmaceuticals such as the Covid-19 vaccines compared to a sedative from the 1950s that caused serious birth defects.\"),\n",
    "    get_id(\"The major cause of death in Covid-19 is thrombosis or blood clot and not pneumonia.\"),\n",
    "    get_id(\"The COVID-19 virus was artificially created by the U.S. military and placed in a capsule.\"),\n",
    "    get_id(\"A video of a girl collapsing in a store is being shared widely on social media with a claim that the girl died of Coronavirus.\"),\n",
    "    get_id(\"Italy\\u2019s prime minister cries and declares that his country \\u201clost the battle\\u201d against the coronavirus.\"),\n",
    "    get_id(\"Black people are not being targeted for UK coronavirus vaccine trials\"),\n",
    "    get_id(\"In September 2019, a train named COVID-19 appeared in the United States, carrying gases that cause COVID-19.\"),\n",
    "    get_id(\"If you take the vaccine, you'll be enrolled in a pharmacovigilance tracking system. It means that you've enrolled yourself in a medical trial.\"),\n",
    "    get_id(\"Henry Kissinger quote about mandatory vaccinations\"),\n",
    "    get_id(\"RECEIVE FOOD AID SOCIAL PLAN 2020\"),\n",
    "    get_id(\"Post claims the video clip is last message of deceased Pakistani doctor Osama Riyaz who had contracted Coronavirus while treating patients\"),\n",
    "    get_id(\"For a few days now, an image has been circulating on Facebook claiming that COVID-19 can be cured with Dolex Gripa, \\\"Noraver\\\" night, and gargling with warm water and lemon.\"),\n",
    "    get_id(\"A magic remedy to prevent COVID-19: mix brown sugar, ginger, garlic, and Chinese leek, boil them and drink it.\"),\n",
    "    get_id(\"Some statements by the American political scientist and activist Susan George in which she says that “Spaniards are laboratory rats: let’s see how much punishment they tolerate without rebelling.” The phrase is shared related to the current coronavirus pandemic.\"),\n",
    "    get_id(\"Saddam Hussein explains what the coronavirus is.\"),\n",
    "    get_id(\"A Facebook post is spreading the false claim that former President Barack Obama gave $3.8 million to a lab in Wuhan, China.\"),\n",
    "    get_id(\"\\u2019No discrimination\\u2019 against Africans amid pandemic.\")\n",
    "]\n",
    "\n",
    "ids_x = [ids2[7]]\n",
    "\n",
    "prompt_list = []\n",
    "model_name = 'llama3'\n",
    "\n",
    "\n",
    "# [ids2[ii] for ii in ids_filtered]:\n",
    "for i in ids_x: \n",
    "    claim = data_search[i][\"claim\"]\n",
    "    search_results = data_search[i][f\"{search_engine}_search_results\"]\n",
    "    prompt_list.append(get_prompt_for_generating_prior_knowledge1(\n",
    "            claim, data_search[i][\"date\"], search_engine, search_results, model_name,\n",
    "            K=K, sort=False, \n",
    "            # ids=data_search[i][\"random_ids\"],\n",
    "            ids=None\n",
    "        ))\n",
    "request_list = [{'query': prompt} for prompt in prompt_list]\n",
    "\n",
    "resp_list = get_resp_list(request_list)\n",
    "# print(resp_list[0][\"response\"].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Below is a <CLAIM> and some INFORMATION searched online. These pieces of INFORMATION are relevant to the <CLAIM>. This <CLAIM> and all INFORMATION include their respective publication dates and contents. To classify the <CLAIM> more accurately (if the content described by the <CLAIM> is correct, it will be classified as TRUE; if the content described by the <CLAIM> is incorrect, it will be classified as FALSE), please first provide a clear summary of the given INFORMATION, restate the <CLAIM>, reason appropriately, and provide reasonable evidence to judge the correctness of the <CLAIM> based on the available information and your knowledge.\n",
      "\n",
      "<CLAIM>: Chief Secretary of West Bengal was not following relaxing while the state was performing poorly as it fought COVID-19.\n",
      "Publication date: 2020-05-08\n",
      "\n",
      "INFORMATION:\n",
      "Information 1:\n",
      "Publication date: None\n",
      "Title: Government of West Bengal - Egiye Bangla\n",
      "Content:\n",
      "Hon'ble Chief Minister Mamata Banerjee at the ceremonial event conducted for World Adivasi Day Previous Next ... The West Bengal Government appeals ALL to contribute in West Bengal State Emergency Relief Fund and assist the State Government in prevention and control of situation arising out of unforeseen emergencies like · COVID-19 (CORONA).\n",
      "The West Bengal Government appeals ALL to contribute in West Bengal State Emergency Relief Fund and assist the State Government in prevention and control of situation arising out of unforeseen emergencies like · COVID-19 (CORONA). Contribution to this fund entitles you to claim 100% deduction under section 80G of the Income Tax Act. ... A/c Name : West Bengal State Emergency Relief Fund Bank: ICICI Bank Ltd., Branch: Howrah, A/c No: 628005501339, IFS Code: ICIC0006280, Swift Code:ICICINBBCTS, MICR Code: 700229010\n",
      "Hon'ble Chief Minister Mamata Banerjee at the grand procession which was organised on September 1, 2022, to felicitate UNESCO representatives, for inscribing Bengal’s Durga Puja as Intangible Cultural Heritage of Humanity · Hon'ble Chief Minister Mamata Banerjee at the grand procession which was organised on September 1, 2022, to felicitate UNESCO representatives, for inscribing Bengal’s Durga Puja as Intangible Cultural Heritage of Humanity\n",
      "Hon'ble Chief Minister Mamata Banerjee at the grand procession which was organised on September 1, 2022, to felicitate UNESCO representatives, for inscribing Bengal’s Durga Puja as Intangible Cultural Heritage of Humanity · Hon'ble Chief Minister Mamata Banerjee at the Bangabibhusan, Bangabhusan and Mahanayak Samman Award Ceremony 2022\n",
      "Information 2:\n",
      "Publication date: None\n",
      "Title: Welcome to WB HEALTH Portal\n",
      "Content:\n",
      "Designed &amp; Developed by Department of Health &amp; Family Welfare (GOVT. of WB) Visitor Counter : 50612794\n",
      "Information 3:\n",
      "Publication date: 2023-12-02\n",
      "Title: COVID-19 pandemic in West Bengal - Wikipedia\n",
      "Content:\n",
      "Chief Minister of West Bengal Mamata Banerjee and her government was widely criticised of the handling of the coronavirus pandemic and was accused of concealing facts by the opposition and critics. The opposition accused Mamata of playing \"appeasement politics\" amid the COVID-19 crisis. On 1 April, Banerjee claimed that the West Bengal Government have already traced 54 people who attended the Tablighi Jamaat religious gathering during the COVID-19 Outbreak, and 44 of them are foreigners.\n",
      "The West Bengal government on Monday released a list, saying four districts, including Kolkata, have been declared as red zones in the wake of the COVID-19 outbreak, and 348 areas as containment zones, out of which Kolkata has 227. There are some districts in Orange & Green zones. The lockdown process will be strict in those Red Zone Containment areas. Some relaxation will be given to Orange zones and Most relaxation will be given to Green Zones. The West Bengal government has been sharing regular updates of the lists of containment zones from 4 May 2020.\n",
      "23 March: West Bengal CM Mamata Banerjee announced Monday that the state government is creating a Rs 200 crore fund to deal with the impact of COVID-19. 24 March: Entire West Bengal was brought under lock down until 31 March. 25 March: West Bengal Government converts Medical College & Hospital, Kolkata, for isolation of people suspected with Coronavirus. 30 March: West Bengal government issues order to authorities of every districts to set up temporary arrangements of shelter and food to migrants and poor. Chief Minister of West Bengal Mamata Banerjee and her government was widely criticised of the handling of the coronavirus pandemic and was accused of concealing facts by the opposition and critics.\n",
      "30 March: West Bengal government issues order to authorities of every districts to set up temporary arrangements of shelter and food to migrants and poor. Chief Minister of West Bengal Mamata Banerjee and her government was widely criticised of the handling of the coronavirus pandemic and was accused of concealing facts by the opposition and critics. The opposition accused Mamata of playing \"appeasement politics\" amid the COVID-19 crisis.\n",
      "Panning of vegetable seller's alternative transportation in Sonarpur due to COVID-19 pandemic in West Bengal · The COVID-19 pandemic was first confirmed in the Indian state of West Bengal on 17 March 2020 in Kolkata. The Health and Family Welfare department of Government of West Bengal has ...\n",
      "Information 4:\n",
      "Publication date: 2021-05-29\n",
      "Title: WB Chief Secretary Alapan Bandyopadhyay Gets Recalled Amid Fresh ...\n",
      "Content:\n",
      "However, West Bengal Chief Minister Mamata Banerjee had written to Prime Minister Narendra Modi urging him to grant Bandyopadhyay an extension for at least six months as he had extensive experience with respect to handling the Covid-19 pandemic, with the threat of Cyclone Yaas also coming in. He was granted a three-month extension following a nod from the Centre. On May 24, Banerjee, while announcing the extension, had said: \"Our chief secretary has got an extension for three months.\n",
      "Bandyopadhyay, a 1987-batch IAS officer of the West Bengal cadre, was scheduled to retire on May 31 after completion of 60 years of age. However, West Bengal Chief Minister Mamata Banerjee had written to Prime Minister Narendra Modi urging him to grant Bandyopadhyay an extension for at least six months as he had extensive experience with respect to handling the Covid-19 pandemic, with the threat of Cyclone Yaas also coming in.\n",
      "The officers, Rajeev Mishra (1996 batch), Praveen Tripathi (2004 batch) and Bholanath Pandey (2011 batch), were directed to report on central deputation in December last year after the West Bengal government refused to send its chief secretary and police chief to Delhi to discuss the law and order situation in the state.\n",
      "Kolkata: Amid a fresh row between the Centre and West Bengal state government, West Bengal Chief Secretary Alapan Bandyopadhyay was asked to report to New Delhi as his services were sought there, a move termed by the ruling Trinamool Congress as \"forced deputation\". This decision came in barely four days after he was granted an extension. ALSO READ | ‘Didi Has Put Arrogance Above Public Welfare’: Amit Shah Slams Mamata Banerjee · Bandyopadhyay, a 1987-batch IAS officer of the West Bengal cadre, was scheduled to retire on May 31 after completion of 60 years of age.\n",
      "Information 5:\n",
      "Publication date: 2020-03-18\n",
      "Title: West Bengal home secy keeps away from office after meeting mother ...\n",
      "Content:\n",
      "West Bengal home secretary Alapan Bandyopadhyay recently had recently received a state bureaucrat who is the mother of a Covid-19 patient (File photo) By Romita Datta: State home secretary Alapan Bandyopadhyay kept away from the state headquarters, Nabanna, on Wednesday. It is yet to be officially confirmed whether he is on home quarantine or not. Insiders in the corridors of power say the chief minister had asked him to be on isolation and home quarantine after it came to light that Bandyopadhyay had a visitor -- a state bureaucrat whose son was a confirmed Covid-19 case.\n",
      "Insiders in the corridors of power say the chief minister had asked him to be on isolation and home quarantine after it came to light that Bandyopadhyay had a visitor -- a state bureaucrat whose son was a confirmed Covid-19 case. Apart from Bandyopadhyay, his wife, CU Vice-Chancellor, Sonali Chakrabarty, was also missing from the university campus. She is also reportedly on home quarantine. ... The home secretary's visitor, a special secretary of Home FNRI department, had called on him on Monday to ask for leave, in the event of his son being advised hospitalisation as a suspected case of Covi-19.\n",
      "\n",
      "2\n",
      "**Summary of Information:**\n",
      "\n",
      "The provided information consists of five sources related to the COVID-19 pandemic in West Bengal, India. The sources include:\n",
      "\n",
      "1. The official website of the Government of West Bengal, which appeals for contributions to the West Bengal State Emergency Relief Fund to combat COVID-19.\n",
      "2. The WB HEALTH Portal, which is a website designed and developed by the Department of Health & Family Welfare, Government of West Bengal.\n",
      "3. A Wikipedia article on the COVID-19 pandemic in West Bengal, which provides information on the government's response to the pandemic, including the declaration of red, orange, and green zones, and the criticism faced by Chief Minister Mamata Banerjee and her government.\n",
      "4. An article from 2021 about West Bengal Chief Secretary Alapan Bandyopadhyay being granted a three-month extension, despite being scheduled to retire, due to his experience in handling the COVID-19 pandemic.\n",
      "5. An article from 2020 about West Bengal home secretary Alapan Bandyopadhyay going into home quarantine after meeting a state bureaucrat whose son was a confirmed COVID-19 case.\n",
      "\n",
      "**Restatement of Claim:**\n",
      "\n",
      "The claim states that the Chief Secretary of West Bengal was not following relaxing while the state was performing poorly as it fought COVID-19.\n",
      "\n",
      "**Reasoning and Evidence:**\n",
      "\n",
      "Based on the provided information, it appears that the Chief Secretary of West Bengal, Alapan Bandyopadhyay, was actively involved in the state's response to the COVID-19 pandemic. In Information 4, it is mentioned that Chief Minister Mamata Banerjee wrote to Prime Minister Narendra Modi to grant Bandyopadhyay an extension for at least six months due to his extensive experience in handling the pandemic. This suggests that Bandyopadhyay was not \"not following\" or neglecting his duties during the pandemic.\n",
      "\n",
      "Additionally, Information 5 indicates that Bandyopadhyay took precautions to prevent the spread of COVID-19 by going into home quarantine after meeting a state bureaucrat whose son was a confirmed COVID-19 case. This demonstrates that he was taking the pandemic seriously and taking steps to ensure his own safety and the safety of others.\n",
      "\n",
      "While the Wikipedia article (Information 3) mentions that the West Bengal government faced criticism for its handling of the pandemic, there is no evidence to suggest that the Chief Secretary was not following protocols or was negligent in his duties.\n",
      "\n",
      "**Classification:**\n",
      "\n",
      "Based on the available information, I would classify the claim as FALSE. The evidence suggests that the Chief Secretary of West Bengal, Alapan Bandyopadhyay, was actively involved in the state's response to the COVID-19 pandemic and took precautions to prevent the spread of the virus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:27:00,495\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::RayWorkerWrapper.execute_method()\u001b[39m (pid=2812629, ip=10.21.16.116, actor_id=1f45643c2ef832c18461751a01000000, repr=<vllm.executor.ray_utils.RayWorkerWrapper object at 0x7f7eb112ad90>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/worker/worker_base.py\", line 149, in execute_method\n",
      "    raise e\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/worker/worker_base.py\", line 140, in execute_method\n",
      "    return executor(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/worker/worker.py\", line 286, in start_worker_execution_loop\n",
      "    while self._execute_model_non_driver():\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/worker/worker.py\", line 295, in _execute_model_non_driver\n",
      "    data = broadcast_tensor_dict(src=0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/vllm/distributed/communication_op.py\", line 284, in broadcast_tensor_dict\n",
      "    torch.distributed.broadcast_object_list(recv_metadata_list,\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 2649, in broadcast_object_list\n",
      "    broadcast(object_sizes_tensor, src=src, group=group)\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hanlv/miniconda3/envs/swift/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 2144, in broadcast\n",
      "    work.wait()\n",
      "RuntimeError: [../third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:81] Timed out waiting 1800000ms for recv operation to complete\n"
     ]
    }
   ],
   "source": [
    "# llama-3-70b\n",
    "# CLAIM + info wrong: 1, 18\n",
    "# info + CLAIM wrong: 1, 18\n",
    "\n",
    "\n",
    "# CLAIM + info wrong: 0, 1, 2, 3, 7, 11, 15, 20, 45\n",
    "# info + CLAIM wrong: 0, 1, 2, 3, 6, 7, 20, 30, 46, 51\n",
    "\n",
    "# mixtral-8x7b\n",
    "# claim wrong: 1, 10, (18)\n",
    "# <claim>: 1, 10, 18\n",
    "\n",
    "# claim: 0, 1, 2, 11, 15, 19, (20), 25, 30  √√√√√√√√√√√\n",
    "# <claim>: 0, 1, 3, 7, 15, 19, 20, 23, 24, 25, 45 xxxxxxxxxxx\n",
    "\n",
    "print(len(ids_x))\n",
    "\n",
    "\n",
    "nn = 0\n",
    "print(prompt_list[nn])\n",
    "# print('*'*50)\n",
    "print(data_search[ids_x[nn]][\"label\"])\n",
    "print(resp_list[nn][\"response\"].strip())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
