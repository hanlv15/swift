{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查每个claim，第一个检索结果如果是 factcheck.afp.com 或者 reuters.com ，\n",
    "然后再核对title是否对应的上claim：\n",
    "找claim第一个单词，再title里找到对应的起始位置，然后终止位置为...\n",
    "查看title是否在claim中出现，如果是，那么FALSE改为TRUE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "dirs = [\"../..\", \"../create_prompt_llm\"]\n",
    "for _dir in dirs:\n",
    "    if _dir not in sys.path:\n",
    "        sys.path.append(_dir)\n",
    "import prompt_rag\n",
    "\n",
    "search_engine = \"brave\"\n",
    "\n",
    "def load_train_bak():\n",
    "    with open(\"covmis_data/train.json.bak\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def load_train():\n",
    "    with open(\"covmis_data/train.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def load_type1():\n",
    "    with open(\"output/type_1.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_type2():\n",
    "    with open(\"output/type_2.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def save_type1(x):\n",
    "    with open(\"output/type_1.json\", \"w\") as f:\n",
    "        json.dump(x, f, indent=4)\n",
    "        \n",
    "def save_type2(x):\n",
    "    with open(\"output/type_2.json\", \"w\") as f:\n",
    "        json.dump(x, f, indent=4)\n",
    "\n",
    "def item_exist(x, data):\n",
    "    for item in data:\n",
    "        if item[\"id\"] == x[\"id\"]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def update_data_type1(x, data: list):\n",
    "\n",
    "    data_type2 = load_type2()\n",
    "    if item_exist(x, data_type2):\n",
    "        return\n",
    "    \n",
    "    if not item_exist(x, data):\n",
    "        data.append(x)\n",
    "\n",
    "def update_data_type2(x, data: list):\n",
    "\n",
    "    if not item_exist(x, data):\n",
    "        data.append(x)\n",
    "\n",
    "with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search.json\", \"r\") as f:\n",
    "    data_search = json.load(f)\n",
    "try:\n",
    "    with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"r\") as f:\n",
    "        data_search_llm = json.load(f)\n",
    "except:\n",
    "    pass\n",
    "    # data_search_llm = [{\n",
    "    #     \"claim\": i[\"claim\"],\n",
    "    #     \"claimant\": i[\"claimant\"],\n",
    "    #     \"label\": i[\"label\"],\n",
    "    #     \"date\": i[\"date\"],\n",
    "    # } for i in data_search]\n",
    "    # with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/data/train_{search_engine}_search_llm.json\", \"w\") as f:\n",
    "    #     json.dump(data_search_llm, f, indent=4)\n",
    "\n",
    "def save_diff(x, model_name, diff_version):\n",
    "    with open(f\"output/diff_{model_name}_v{diff_version}.json\", \"w\") as f:\n",
    "        json.dump(x, f, indent=4)\n",
    "\n",
    "def load_diff(model_name, diff_version):\n",
    "    try:\n",
    "        with open(f\"output/diff_{model_name}_v{diff_version}.json\", \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except:\n",
    "        data_init = [{\"claim\": i[\"claim\"], \"label\": int(i[\"label\"])} for i in data_search_llm]\n",
    "        with open(f\"output/diff_{model_name}_v{diff_version}.json\", \"w\") as f:\n",
    "            json.dump(data_init, f, indent=4)\n",
    "        return data_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr Mikovits, an established scientist, revealed that Dr Anthony Fauci was paid to cover up the extent of the problem caused by COVID-19. Also she revealed that SARS-CoV-2 was created in a lab and that influenza vaccines increase COVID-19 mortality by 36%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for item in data_search:\n",
    "    claim = item[\"claim\"]\n",
    "    title = item[f\"{search_engine}_search_results\"][\"web\"][\"results\"][0][\"title\"]\n",
    "    url = item[f\"{search_engine}_search_results\"][\"web\"][\"results\"][0][\"url\"]\n",
    "    check_list = [\"poynter\"]\n",
    "\n",
    "    ok = False\n",
    "    for site in check_list:\n",
    "        if site in url:\n",
    "            ok = True\n",
    "            break\n",
    "    if not ok:\n",
    "        continue\n",
    "    cnt += 1\n",
    "\n",
    "    print(claim)\n",
    "    break\n",
    "cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Summary:\n",
      "\n",
      "Information 1, published on 2020-02-11, provides guidelines on what to do if you have been around someone with COVID-19. It includes information on symptoms, testing, and daily activities.\n",
      "\n",
      "Information 2, published on 2020-05-27, offers guidance for close contacts of people with COVID-19. It advises daily LFD tests for 7 days if you have been in close contact with an infected person. It also provides information on when to end isolation and how to protect immunocompromised individuals.\n",
      "\n",
      "Information 3, with no publication date, explains how to get tested for COVID-19, when to test, and what to expect.\n",
      "\n",
      "Information 4, with no publication date, provides details on what to do if you are a close contact to someone with COVID-19, including seeking medical care and considering contacting a healthcare provider.\n",
      "\n",
      "Information 5, with no publication date, defines close contacts based on exposure risks and advises contacting a healthcare provider for treatment options.\n",
      "\n",
      "Restated CLAIM: As of March 19, 2020, it is possible to contract the coronavirus without having direct contact with an infected person.\n",
      "\n",
      "Reasoning and Evidence:\n",
      "\n",
      "The claim is actually incorrect based on the available information. The earliest publication date is 2020-02-11, which is before the claim's publication date. None of the provided information supports the claim that it is possible to contract the coronavirus without having direct contact with an infected person. In fact, Information 2, published on 2020-05-27, specifically states that if you have had close contact with someone who has tested positive for COVID-19, you are at higher risk of becoming infected yourself. Therefore, the claim is FALSE based on the available information and current scientific understanding of COVID-19 transmission.\n"
     ]
    }
   ],
   "source": [
    "s = \"Information Summary:\\n\\nInformation 1, published on 2020-02-11, provides guidelines on what to do if you have been around someone with COVID-19. It includes information on symptoms, testing, and daily activities.\\n\\nInformation 2, published on 2020-05-27, offers guidance for close contacts of people with COVID-19. It advises daily LFD tests for 7 days if you have been in close contact with an infected person. It also provides information on when to end isolation and how to protect immunocompromised individuals.\\n\\nInformation 3, with no publication date, explains how to get tested for COVID-19, when to test, and what to expect.\\n\\nInformation 4, with no publication date, provides details on what to do if you are a close contact to someone with COVID-19, including seeking medical care and considering contacting a healthcare provider.\\n\\nInformation 5, with no publication date, defines close contacts based on exposure risks and advises contacting a healthcare provider for treatment options.\\n\\nRestated CLAIM: As of March 19, 2020, it is possible to contract the coronavirus without having direct contact with an infected person.\\n\\nReasoning and Evidence:\\n\\nThe claim is actually incorrect based on the available information. The earliest publication date is 2020-02-11, which is before the claim's publication date. None of the provided information supports the claim that it is possible to contract the coronavirus without having direct contact with an infected person. In fact, Information 2, published on 2020-05-27, specifically states that if you have had close contact with someone who has tested positive for COVID-19, you are at higher risk of becoming infected yourself. Therefore, the claim is FALSE based on the available information and current scientific understanding of COVID-19 transmission.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加related url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = load_train()\n",
    "\n",
    "# for item in data_train:\n",
    "#     related_url = \"\"\n",
    "#     article_id = item[\"related_articles\"][-1]\n",
    "#     with open(f\"/home/hanlv/workspace/data/machine_learning/dataset/research/misinformation_dataset/COVMIS-main/articles/{article_id}.txt\", \"r\") as f:\n",
    "#         lines = f.readlines()\n",
    "    \n",
    "#     s = \"\"\n",
    "#     now = len(lines) - 1\n",
    "#     while now >=0 and lines[now].strip == \"\":\n",
    "#         now -= 1\n",
    "\n",
    "#     s = lines[now]\n",
    "#     st = s.find(\"article_url:\")\n",
    "#     if st != -1:\n",
    "#         related_url = s[st + len(\"article_url:\"):].strip()\n",
    "#     item[\"related_url\"] = related_url\n",
    "\n",
    "\n",
    "# # with open(\"covmis_data/train.json\", \"w\") as f:\n",
    "# #     json.dump(data_train, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 154, 763)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_data = load_diff(\"llama3\", 1)\n",
    "data_train = load_train()\n",
    "data_type1 = load_type1()\n",
    "data_type2 = load_type2()\n",
    "\n",
    "claim_dict = {}\n",
    "for item in diff_data:\n",
    "    if item[\"match2\"].lower() == \"no\":\n",
    "        claim_dict[item[\"claim\"].strip()] = 1\n",
    "\n",
    "cnt = 0\n",
    "cnt2 = 0\n",
    "for i, item in enumerate(data_search):\n",
    "    claim = item[\"claim\"]\n",
    "    if int(data_train[i][\"label\"]) == 1:\n",
    "        continue\n",
    "    # ok = False\n",
    "    for search_result_id in range(2):\n",
    "        if len(item[f\"{search_engine}_search_results\"][\"web\"][\"results\"]) == search_result_id:\n",
    "            break\n",
    "        title_bak = item[f\"{search_engine}_search_results\"][\"web\"][\"results\"][search_result_id][\"title\"]\n",
    "        title = title_bak\n",
    "        url = item[f\"{search_engine}_search_results\"][\"web\"][\"results\"][search_result_id][\"url\"]\n",
    "        check_list = [\n",
    "            \"factcheck.afp.com\", \"reuters.com\", \n",
    "            \"africacheck.org\"\n",
    "        ]\n",
    "\n",
    "        ok = False\n",
    "        for site in check_list:\n",
    "            if site in url:\n",
    "                ok = True\n",
    "                break\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        # cnt += 1\n",
    "        pos_st = title.find(claim.split(' ')[0])\n",
    "        if pos_st == -1:\n",
    "            continue\n",
    "        pos_en = len(title)\n",
    "        if title.endswith(\" ...\"):\n",
    "            pos_en -= 4\n",
    "        elif title.endswith(\"...\"):\n",
    "            pos_en -= 3 \n",
    "\n",
    "        title = title[pos_st : pos_en]\n",
    "        pos_en = len(title)\n",
    "\n",
    "        # [\"| Reuters\", \"| Fact Check\", \"| Fact\", \"|\"]\n",
    "        pos_verical_bar = title.rfind(\"|\")\n",
    "        if pos_verical_bar != -1:\n",
    "            pos_en = pos_verical_bar\n",
    "        # elif \"africacheck.org\" in url:\n",
    "        #     pos_verical_bar = title.rfind(\"-\")\n",
    "        #     if pos_verical_bar != -1:\n",
    "        #         pos_en = pos_verical_bar\n",
    "\n",
    "        if len(title[:pos_en].split()) >= 5 and title[:pos_en].strip() in claim:\n",
    "            if claim_dict.get(claim.strip()) is not None:\n",
    "                cnt += 1\n",
    "                # print(claim)\n",
    "                if data_train[i][\"label\"] == 0 and not item_exist(data_train[i], data_type2):\n",
    "                    data_train[i][\"label\"] = 2\n",
    "                    update_data_type1(data_train[i], data_type1)\n",
    "                    # print(claim)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                cnt2 += 1\n",
    "                \n",
    "                if data_train[i][\"label\"] == 0:\n",
    "                    \n",
    "                    if not title_bak.lower().startswith(\"false claim\"):\n",
    "                        if (title_bak.lower().startswith(\"fact check:\") and \"reuters.com\" in url) or \\\n",
    "                            (\"africacheck.org\" in url):\n",
    "                            data_train[i][\"label\"] = 2\n",
    "                            update_data_type1(data_train[i], data_type1)\n",
    "                            # print(claim)\n",
    "                        else:\n",
    "                            pass\n",
    "                else:\n",
    "                    pass\n",
    "            break\n",
    "# Covid-19 not caused by bacteria, aspirin not a cure - Africa Check\n",
    "cnt, cnt2, cnt + cnt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1285, 931)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type1 = load_type1()\n",
    "data_type2 = load_type2()\n",
    "\n",
    "\n",
    "def get_error_labels(data_type):\n",
    "    error_cnt = 0\n",
    "    tot_cnt = 0\n",
    "    data_bak = load_train_bak()\n",
    "    for item in data_type:\n",
    "        if item[\"label\"] == 1:\n",
    "            continue\n",
    "        for i in data_bak:\n",
    "            if i[\"id\"] == item[\"id\"] and i[\"label\"] != item[\"label\"]:\n",
    "                error_cnt += 1\n",
    "                break\n",
    "        tot_cnt += 1\n",
    "        \n",
    "    return error_cnt, tot_cnt\n",
    "print(len(data_type2))\n",
    "get_error_labels(data_type1)[1] + get_error_labels(data_type2)[1], \\\n",
    "    get_error_labels(data_type1)[0] + get_error_labels(data_type2)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9236384514435696"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (12192 - 931) / 12192\n",
    "\n",
    "99 / 92.5 * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_type1(data_type1)\n",
    "\n",
    "# with open(\"covmis_data/train.json\", \"w\") as f:\n",
    "#     json.dump(data_train, f, indent=4)\n",
    "\n",
    "# len(data_type1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
